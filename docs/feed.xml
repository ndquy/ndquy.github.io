

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://ndquy.github.io/</id>
  <title>Quy's blog</title>
  <subtitle>Chia sẻ kiến thức công nghệ lập trình và ứng dụng machine learning, khai phá dữ liệu, kỹ thuật lập trình.</subtitle>
  <updated>2021-09-09T16:40:33+08:00</updated>
  <author>
    <name>Nguyễn Đình Quý</name>
    <uri>https://ndquy.github.io/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="https://ndquy.github.io/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="vi-VI"
    href="https://ndquy.github.io/"/>
  <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator>
  <rights> © 2021 Nguyễn Đình Quý </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>\[Tản mạn\] Đánh giá độ chính xác các bộ kit xét nghiệm thế nào?</title>
    <link href="https://ndquy.github.io/posts/danh-gia-xet-nghiem-covid-19/" rel="alternate" type="text/html" title="\[Tản mạn\] Đánh giá độ chính xác các bộ kit xét nghiệm thế nào?" />
    <published>2021-09-09T11:48:00+08:00</published>
  
    <updated>2021-09-09T11:48:00+08:00</updated>
  
    <id>https://ndquy.github.io/posts/danh-gia-xet-nghiem-covid-19/</id>
    <content src="https://ndquy.github.io/posts/danh-gia-xet-nghiem-covid-19/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Hôm trước có chủ tịch tên là NTQ của một tập đoàn công nghệ nào đấy là BK** (Mình lhoong tiện nói tên) phát triển công nghệ giúp tìm ra người nhiễm Covid-19 thông qua dung dịch nước muối sinh lý bảo là: “Kết quả ban đầu được ghi nhận là khả quan với tỷ lệ nhận diện trên 90%”. Mà không nói rõ tỷ lệ này là tỷ lệ gì. Hôm nay mọi người cùng tìm hiểu thử độ chính xác của các bộ kit xét nghiệm được x...
    </summary>
  

  </entry>

  
  <entry>
    <title>15. Thuật toán phân cụm K-Means</title>
    <link href="https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" rel="alternate" type="text/html" title="15. Thuật toán phân cụm K-Means" />
    <published>2021-09-09T11:47:00+08:00</published>
  
    <updated>2021-09-09T15:46:28+08:00</updated>
  
    <id>https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/</id>
    <content src="https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Thuật toán phân cụm K-Means là một trong những thuật toán phân cụm dữ liệu dựa trên học không giám sát được sử dụng nhiều trong các học máy nói chung và trong khai phá dữ liệu nói riêng.
Nhắc lại về học có giám sát và không giám sát
Học có giám sát
Trong học máy, lớp các thuật toán học có giám sát Supervised learning là việc học các xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${{x_1, x_...
    </summary>
  

  </entry>

  
  <entry>
    <title>14. Kỹ thuật data augmentation trong NLP với Tiếng Việt</title>
    <link href="https://ndquy.github.io/posts/ky-thuat-tang-cuong-du-lieu-nlp/" rel="alternate" type="text/html" title="14. Kỹ thuật data augmentation trong NLP với Tiếng Việt" />
    <published>2021-05-08T16:47:00+08:00</published>
  
    <updated>2021-05-09T14:12:56+08:00</updated>
  
    <id>https://ndquy.github.io/posts/ky-thuat-tang-cuong-du-lieu-nlp/</id>
    <content src="https://ndquy.github.io/posts/ky-thuat-tang-cuong-du-lieu-nlp/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Tăng cường dữ liệu (Data Augmentation) là một khái niệm khá phổ biến trong deep learning mà chắc hẳn ai đang nghiên cứu cũng đã từng nghe hoặc sử dụng đến.
Nói đơn giản hơn, Data Augmentation là kỹ thuật tạo ra thêm dữ liệu để bổ sung cho tập dữ liệu để giúp mô hình khái quát tốt hơn.
Các kỹ thuật data augmentation được sử dụng nhiều trong thị giác máy tính, thuật toán supervised learning… Tuy ...
    </summary>
  

  </entry>

  
  <entry>
    <title>13. Xác định ý định câu hỏi trong hệ thống hỏi đáp</title>
    <link href="https://ndquy.github.io/posts/intent-classification/" rel="alternate" type="text/html" title="13. Xác định ý định câu hỏi trong hệ thống hỏi đáp" />
    <published>2021-04-14T16:47:00+08:00</published>
  
    <updated>2021-05-09T14:02:26+08:00</updated>
  
    <id>https://ndquy.github.io/posts/intent-classification/</id>
    <content src="https://ndquy.github.io/posts/intent-classification/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Mục tiêu bài viết

Phân tích câu hỏi là pha đầu tiên trong kiến trúc chung của một hệ thống hỏi đáp, có
nhiệm vụ tìm ra các thông tin cần thiết làm đầu vào cho quá trình xử lý của các pha sau
(trích chọn tài liệu, trích xuất câu trả lời, …). Vì vậy phân tích câu hỏi có vai trò hết sức
quan trọng, ảnh hưởng trực tiếp đến hoạt động của toàn bộ hệ thống. Nếu phân tích câu hỏi không tốt thì sẽ khôn...
    </summary>
  

  </entry>

  
  <entry>
    <title>12. Các phương pháp đánh giá mô hình phân lớp phần 1</title>
    <link href="https://ndquy.github.io/posts/Phan-lop-danh-gia-he-thong-phan-lop/" rel="alternate" type="text/html" title="12. Các phương pháp đánh giá mô hình phân lớp phần 1" />
    <published>2021-04-10T16:47:00+08:00</published>
  
    <updated>2021-04-10T16:47:00+08:00</updated>
  
    <id>https://ndquy.github.io/posts/Phan-lop-danh-gia-he-thong-phan-lop/</id>
    <content src="https://ndquy.github.io/posts/Phan-lop-danh-gia-he-thong-phan-lop/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Trong bài viết này mình sẽ nói đến bài toán phân lớp và các phương pháp đánh giá 1 mô hình phân lớp.

Bài toán phân lớp

Mình sẽ sử dụng bộ dữ liệu MNIST, gồm 70.000 ảnh nhỏ của các số viết tay bởi người ở US. Mỗi ảnh được đánh nhãn với số tương ứng. Tập dữ liệu này được dùng cực kì phổ biến trong huấn luyện các thuật toán và thường được gọi là bộ dữ liệu “Hello World” trong Machine learning. N...
    </summary>
  

  </entry>

</feed>


