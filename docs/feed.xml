

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/</id>
  <title>Quy's blog</title>
  <subtitle>Chia sẻ kiến thức công nghệ lập trình và ứng dụng machine learning cơ bản và nâng cao.</subtitle>
  <updated>2021-04-03T17:44:19+08:00</updated>
  <author>
    <name>Nguyễn Đình Quý</name>
    <uri>/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en-US"
    href="/"/>
  <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator>
  <rights> © 2021 Nguyễn Đình Quý </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>6. Bài toán phân lớp và các phương pháp đánh giá</title>
    <link href="/posts/bai-toan-phan-lop-va-danh-gia/" rel="alternate" type="text/html" title="6. Bài toán phân lớp và các phương pháp đánh giá" />
    <published>2021-04-03T05:46:00+08:00</published>
  
    <updated>2021-04-03T05:46:00+08:00</updated>
  
    <id>/posts/bai-toan-phan-lop-va-danh-gia/</id>
    <content src="/posts/bai-toan-phan-lop-va-danh-gia/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Trong bài viết này mình sẽ nói đến bài toán phân lớp và các phương pháp đánh giá 1 hệ thống phân lớp.

Mình sẽ sử dụng bộ dữ liệu MNIST, gồm 70.000 ảnh nhỏ của các số viết tay bởi người ở US. Mỗi ảnh được đánh nhãn với số tương ứng. Tập dữ liệu này được dùng cực kì phổ biến trong huấn luyện các thuật toán và thường được gọi là bộ dữ liệu “Hello World” trong Machine learning. Nói chung là ai học...
    </summary>
  

  </entry>

  
  <entry>
    <title>4. Gradient Descent</title>
    <link href="/posts/gradient-descent-2/" rel="alternate" type="text/html" title="4. Gradient Descent" />
    <published>2021-04-03T05:45:00+08:00</published>
  
    <updated>2021-04-03T16:56:27+08:00</updated>
  
    <id>/posts/gradient-descent-2/</id>
    <content src="/posts/gradient-descent-2/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Bài trước mình đã giới thiệu mọi người cách để huấn luyện mô hình học máy, trong đó mục đích của việc huấn luyện là để tìm ra các tham số mà tại đó hàm chi phí (hàm mất mát) đạt giá trị nhỏ nhất.

Trong toán tối ưu, việc tìm ra cực trị của hàm số rất phổ biến. Có nhiều phương pháp để tìm cực trị hàm số, trong đó cách phổ biến nhất là tìm đạo hàm rồi giải phương trình đạo hàm bằng 0, các nghiệm ...
    </summary>
  

  </entry>

  
  <entry>
    <title>5. Hồi quy Logistic</title>
    <link href="/posts/hoi-quy-logistic/" rel="alternate" type="text/html" title="5. Hồi quy Logistic" />
    <published>2021-04-03T03:46:00+08:00</published>
  
    <updated>2021-04-03T17:42:32+08:00</updated>
  
    <id>/posts/hoi-quy-logistic/</id>
    <content src="/posts/hoi-quy-logistic/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Như chúng ta đã thảo luận từ các bài trước, một vài thuật toán hồi quy có thể được sử dụng để phân lớp (và ngược lại) đều cho kết quả khá tốt. Logistic Regression (hay còn gọi là Logit Regression) được sử dụng phổ biến để ước lượng xác suất 1 điểm dữ liệu có thể thuộc về 1 lớp nào đó (ví dụ tính xác suất để 1 email là spam). Nếu xác suất &amp;gt; 50% thì mô hình dự đoán có thể khẳng định được điểm ...
    </summary>
  

  </entry>

  
  <entry>
    <title>3. Softmax Regression</title>
    <link href="/posts/softmax-regression/" rel="alternate" type="text/html" title="3. Softmax Regression" />
    <published>2021-04-02T05:45:00+08:00</published>
  
    <updated>2021-04-03T16:19:04+08:00</updated>
  
    <id>/posts/softmax-regression/</id>
    <content src="/posts/softmax-regression/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Softmax regression (hay còn gọi là multinomial logistic regression) là dạng của hồi quy logistic cho trường hợp cần phân loại nhiều lớp. Trong hồi quy logistic chúng ta giả sử rằng các nhãn là các giá trị nhị phân $ y^{(i)} \in {0,1}$. Softmax regression cho phép chúng ta thực hiện phân loại $ y^{(i)} \in {1,\ldots,K} $ với K là số lớp cần dự đoán.

Định nghĩa mô hình

Chúng ta có tập dữ liệu h...
    </summary>
  

  </entry>

  
  <entry>
    <title>2. Huấn luyện mô hình Linear Regression</title>
    <link href="/posts/linear-regression-part1/" rel="alternate" type="text/html" title="2. Huấn luyện mô hình Linear Regression" />
    <published>2021-04-02T05:45:00+08:00</published>
  
    <updated>2021-04-03T16:19:04+08:00</updated>
  
    <id>/posts/linear-regression-part1/</id>
    <content src="/posts/linear-regression-part1/" />
    <author>
      <name>Nguyễn Đình Quý</name>
    </author>

  
    
    <category term="Machine Learning" />
    
  

  
    <summary>
      





      Trong các bài trước chúng ta đã xử lý một số bài toán machine learning bằng 1 số thuật toán, tuy nhiên chúng ta mới chỉ coi chúng như các hộp đen. Thậm chí chúng ta không biết gì về cách thực hiện của các thuật toán đó nhưng vẫn có thể  áp dụng, thậm chí tối ưu và cải thiện.

Tuy nhiên nếu biết được chính xác những gì thuật toán làm việc sẽ giúp chúng ta tìm được ra mô hình phù hợp với các bộ s...
    </summary>
  

  </entry>

</feed>


