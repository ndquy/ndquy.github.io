<!DOCTYPE html>



<html lang="vi-VI" 
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  
    <meta name="pv-cache-enabled" content="false">

    
  

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Các phương pháp scale dữ liệu trong machine learning" />
<meta name="author" content="Quy Nguyen" />
<meta property="og:locale" content="vi_VI" />
<meta name="description" content="Trong các thuật toán machine learning nói chung, và trong deep learning nói riêng, các mô hình học cách dự đoán đầu ra từ đầu vào thông qua các ví dụ trong tập dữ liệu huấn luyện." />
<meta property="og:description" content="Trong các thuật toán machine learning nói chung, và trong deep learning nói riêng, các mô hình học cách dự đoán đầu ra từ đầu vào thông qua các ví dụ trong tập dữ liệu huấn luyện." />
<link rel="canonical" href="https://ndquy.github.io/posts/cac-phuong-phap-scaling/" />
<meta property="og:url" content="https://ndquy.github.io/posts/cac-phuong-phap-scaling/" />
<meta property="og:site_name" content="Quy’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-04-06T16:47:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Các phương pháp scale dữ liệu trong machine learning" />
<meta name="twitter:site" content="@dinhquy94" />
<meta name="twitter:creator" content="@Quy Nguyen" />
<meta name="google-site-verification" content="google_meta_tag_verification" />
<script type="application/ld+json">
{"description":"Trong các thuật toán machine learning nói chung, và trong deep learning nói riêng, các mô hình học cách dự đoán đầu ra từ đầu vào thông qua các ví dụ trong tập dữ liệu huấn luyện.","url":"https://ndquy.github.io/posts/cac-phuong-phap-scaling/","headline":"Các phương pháp scale dữ liệu trong machine learning","datePublished":"2021-04-06T16:47:00+08:00","dateModified":"2021-04-07T10:55:48+08:00","author":{"@type":"Person","name":"Quy Nguyen"},"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ndquy.github.io/posts/cac-phuong-phap-scaling/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <title>11. Các phương pháp scale dữ liệu trong machine learning | Quy's blog
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://www.favicon-generator.org/
-->



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">
<link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon">

<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png">
<link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png">
<link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png">

<link rel="icon" type="image/png" sizes="192x192"  href="/assets/img/favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

<link rel="manifest" href="/assets/img/favicons/manifest.json">
<meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'>
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">


  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">

  <!-- GA -->
  

  <!-- jsDelivr CDN -->
  <link rel="preconnect" href="cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="cdn.jsdelivr.net">

  <!-- Bootstrap -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous">

  <!-- Font Awesome -->
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"
    integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ="
    crossorigin="anonymous">

  <!--
  CSS selector for site.
-->

<link rel="stylesheet" href="/assets/css/style.css">


  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">



  <!-- JavaScripts -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  <script defer
    src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script>

  <!--
  JS selector for site.
-->


  





<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
  // see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options>
  MathJax = {
    tex: {
      inlineMath: [
        ['$','$'],
        ['\\(','\\)']
      ],
      displayMath: [
        ['$$', '$$'],
        ['\\[', '\\]']
      ]
    },

  };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>





</head>


  <body data-spy="scroll" data-target="#toc">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">

  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" alt="avatar" class="mx-auto">
        
        <img src="/assets/img/blog/quynd_avarta.jpg" alt="avatar" onerror="this.style.display='none'">
      </a>
    </div>

    <div class="site-title mt-3">
      <a href="/">Quy's blog</a>
    </div>

    <div class="site-subtitle font-italic">Lập trình, Machine learning và Khoa học dữ liệu</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME PAGE</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i>
        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i>
        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center">

    
      

      
      <a href="https://github.com/dinhquy94" aria-label="github"
        class="order-3"
        target="_blank" rel="noopener">
        <i class="fab fa-github-alt"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/dinhquy94" aria-label="twitter"
        class="order-4"
        target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['dinhquy94','gmail.com'].join('@')" aria-label="email"
        class="order-5"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        class="order-6"
        >
        <i class="fas fa-rss"></i>
      </a>
      

    

    
      
        <span class="icon-border order-2"></span>
      

      <span id="mode-toggle-wrapper" class="order-1">
        <!--
  Switch the mode between dark and light.
-->

<i class="mode-toggle fas fa-adjust"></i>

<script type="text/javascript">

  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      var self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addListener(function() {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }

          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.updateMermaid();
      });

    } /* constructor() */


    setDark() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_KEY);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer) ) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    updateMermaid() {
      if (typeof mermaid !== "undefined") {
        let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default");
        let config = { theme: expectedTheme };

        /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $(".mermaid").each(function() {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr("data-processed");
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, ".mermaid");
      }
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }

        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }

      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.updateMermaid();

    } /* flipMode() */

  } /* ModeToggle */

  let toggle = new ModeToggle();

  $(".mode-toggle").click(function() {

    toggle.flipMode();

  });

</script>

      </span>
    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper" class="row justify-content-center topbar-down">
  <div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between">
    <span id="breadcrumb">

    

    

      

        
          

        

      

        
        <span>
          
          
          <a href="/">
            Posts
          </a>
        </span>

        

      

        
          <span>11. Các phương pháp scale dữ liệu trong machine learning</span>

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" placeholder="Search...">
      <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i>
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper">
      <div id="main">

        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->


<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->


<!-- Add attribute 'hide-bullet' to the checkbox list -->




  

  

  <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->
  
  

  

  



<!-- return -->
<div class="row">

  <div id="post-wrapper" class="col-12 col-lg-11 col-xl-8">

    <div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

      <h1 data-toc-skip>11. Các phương pháp scale dữ liệu trong machine learning</h1>

      <div class="post-meta text-muted d-flex flex-column">
        <!-- Published date and author -->
        <div>
          <span class="semi-bold">
            Quy Nguyen
          </span>
          <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago "
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Tue, Apr  6, 2021,  4:47 PM +0800"
  

  
  prep="on" >

  
  

  
    Apr  6
  

  <i class="unloaded">2021-04-06T16:47:00+08:00</i>

</span>

        </div>

        <div>
          <!-- lastmod -->
          
          <span>
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago lastmod"
  
    data-toggle="tooltip"
    data-placement="bottom"
    title="Wed, Apr  7, 2021,  9:55 AM +0700"
  

  prefix="Updated "
   >

  
  

  
    Apr  7
  

  <i class="unloaded">2021-04-07T10:55:48+08:00</i>

</span>

          </span>
          

          <!-- read time -->
          <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->


<!-- words per minute  -->







<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4476 words">24 min</span>


          <!-- page views -->
          

        </div>

      </div> <!-- .post-meta -->

      <div class="post-content">

        

        <p>Trong các thuật toán machine learning nói chung, và trong deep learning nói riêng, các mô hình học cách dự đoán đầu ra từ đầu vào thông qua các ví dụ trong tập dữ liệu huấn luyện.</p>

<p>Các điểm dữ liệu đôi khi được đo đạc với những đơn vị khác nhau, m và feet chẳng hạn. Hoặc có hai thành phần (của vector dữ liệu) chênh lệch nhau quá lớn, một thành phần có khoảng giá trị từ 0 đến 1000, thành phần kia chỉ có khoảng giá trị từ 0 đến 1 chẳng hạn. Lúc này, chúng ta cần chuẩn hóa dữ liệu trước khi thực hiện các bước tiếp theo. (theo https://machinelearningcoban.com/general/2017/02/06/featureengineering)</p>

<p>Các trọng số của mô hình được khởi tạo từ các giá trị ngẫu nhiên nhỏ và được cập nhật bằng thuật toán tối ưu trong quá trình backward, việc cập nhật dựa trên lỗi dự đoán (loss) trong quá trình huấn luyện.</p>

<p>Vì các trọng số nhỏ của mô hình nhỏ và được cập nhật dựa vào lỗi dự đoán nên việc scale giá trị của đầu vào X và đầu ra Y của tập dữ liệu huấn  luyện là một yếu tố quan trọng.
Nếu đầu vào không được scaling có thể dẫn đến quá trình huấn luyện không ổn định. Ngoài ra nếu đầu ra Y không được scale trong các bài toán regression có thể dẫn đến exploding gradient khiến thuật toán không chạy được.</p>

<p>Scaling có thể tạo ra sự khác biệt giữa một mô hình kém và một mô hình tốt.</p>

<p>Bước tiền xử lý dữ liệu liên quan đến kỹ thuật normalization và standardization để rescale lại input và output trước khi huấn luyện mô hình.</p>

<p>Trong bài viết này, chúng ta sẽ tìm hiểu các để cải thiện một mô hình sao cho hiệu quả và ổn định bằng việc scale dữ liệu.</p>

<p>Mục tiêu bài viết</p>

<ul>
  <li>Data scaling là một bước cần được thực hiện trong quá trình tiền xử lý khi cài đặt với mô hình mạng nơ ron</li>
  <li>Thực hiện được scale data bằng kỹ thuật normalization hoặc standardization.</li>
  <li>Áp dụng standardization và normalization để cải thiện mô hình Multilayer Perceptron với bài toán regression sau đó đưa ra đánh giá.</li>
</ul>

<h1 id="scale-các-biến-đầu-vào">Scale các biến đầu vào</h1>

<p>Các biến đầu vào là các biến đưa vào mạng neuron để dự đoán.</p>

<p>Một nguyên tắc chung là các biến đầu vào phải có giá trị nhỏ, có thể nằm trong khoảng 0-1 hoặc được chuẩn hóa với giá trị trung bình bằng 0 và độ lệch chuẩn (standard deviation) bằng 1. Các biến đầu vào có cần phải scaling hay không phụ thuộc vào từng bài toán cụ thể và từng biến cụ thể.</p>

<p>Nếu phân bố các giá trị của biến là phân bố chuẩn thì biến nên được standardization, nếu không dữ liệu nên được normalization. Điều này áp dụng khi phạm vi giá trị lớn (10, 100…) hoặc nhỏ (0.01, 0.0001).</p>

<p>Nếu giá trị của biến nhỏ (gần trong khoảng 0-1) và phân phối bị giới hạn (ví dụ độ lệch chuẩn gần với 1) thì chúng ta không cần phải scale dữ liệu.</p>

<p>Các bài toán có thể phức tạp hoặc không rõ ràng nên ta không xác định được việc sử dụng kỹ thuật nào để scale dữ liệu là tốt nhất. Vì thế nên thường thì mình hay thử nghiệm scale dữ liệu và không scale có khác biệt nhau thế nào bằng việc cho mô hình chạy rồi tiến hành đánh giá.</p>

<h1 id="scale-biến-đầu-ra">Scale biến đầu ra</h1>

<p>Biến đầu ra Y là biến được dự đoán bởi mô hình.</p>

<p>Chúng ta cần đảm bảo là giá trị của Y phải khớp với phạm vi biểu diễn của hàm kích hoạt (activation function) trong lớp output của mô hình mạng nơ-ron.</p>

<p>Nếu đầu ra của activation function thuộc vào miền [0, 1] thì giá trị biến đầu ra Y cũng phải nằm trong miền giá trị này. Tuy nhiên chúng ta nên chọn hàm kích hoạt phù hợp với phân bố của đầu ra Y hơn là đưa Y về miền giá trị của hàm kích hoạt.</p>

<p>Ví dụ nếu bài toán của bạn là regression thì đầu ra sẽ là một giá trị số thực. Mô hình tốt nhất cho bài toán này đó là lựa chọn hàm kích hoạt tuyến tính (linear activation). Nếu đầu ra có phân bố chuẩn thì chúng ta có thể standardize biến đầu ra. Nếu không thì đầu ra Y có thể được normalize.</p>

<h1 id="các-phương-pháp-data-scaling">Các phương pháp data scaling</h1>

<p>Có 2 cách để scale dữ liệu đó là normalization và standardization tạm dịch là Bình thường hóa dữ liệu và Chuẩn hóa dữ liệu</p>

<p>Cả 2 cách này đều được cung cấp trong thư viện scikit-learn</p>

<h2 id="data-normalization">Data Normalization</h2>

<p>Normalization là phương pháp scale dữ liệu từ miền giá trị bất kì sang miền giá trị nằm trong khoảng 0 đến 1.</p>

<p>Phương pháp này yêu cầu chúng ta cần xác định được giá trị lớn nhất (max) và giá trị nhỏ nhất (min) của dữ liệu.</p>

<p>Giá trị được normalize theo công thức sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>y = (x - min) / (max - min)
</pre></td></tr></tbody></table></code></div></div>
<p>y là biến sau normalize, x là biến trước normalize.</p>

<p>Để normalize dữ liệu, ta cần normalize từng thuộc tính (feature) của dữ liệu. Công thức trên áp dụng đối với từng feature.</p>

<p>Trong đó x là giá trị cần được normalize, maximum và minium là giá trị lớn nhất và nhỏ nhất của trong tất cả các quan sát của feature trong tập dữ liệu.</p>

<p>Ví dụ với một tập dữ liệu bất kỳ, chúng ta xác định được giá trị lớn nhất của 1 feature là 30, giá trị nhỏ nhất là -10. Như vậy, với 1 giá trị bất kỳ là 18.8, ta có thể normalize như sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>y = (x - min) / (max - min)
y = (18.8 - (-10)) / (30 - (-10))
y = 28.8 / 40
y = 0.72
</pre></td></tr></tbody></table></code></div></div>

<p>Bạn có thể thấy nếu giá trị x nằm ngoài giới hạn của giá trị minimum và maximum, giá trị kết quả sẽ không nằm trong phạm vi 0 và 1.
Nếu đã xác định giá trị max và min cho trước, một điểm dữ liệu nào đó nằm ngoài khoảng max và min đó ta có thể loại bỏ khỏi tập dữ liệu.</p>

<p>Bạn có thể thực hiện normalize dữ liệu sử dụng thư viện scikit-learn với MinMaxScaler.</p>

<p>Các bước như sau:</p>

<ul>
  <li>Fit biến scaler sử dụng tập dữ liệu huấn luyện. Để normalize thì dữ liệu huấn luyện cần phải được xác định giá trị max và min. Để thực hiện chúng ta gọi hàm fit().</li>
  <li>Tiến hành scale dữ liệu bằng cách gọi hàm transform().</li>
  <li>Áp dụng lại bộ scaler để sử dụng cho việc dự đoán về sau.</li>
</ul>

<p>Bộ scaler MinMaxScaler sẽ đưa các biến về miền giá trị [0, 1], sử dụng tham số <code class="language-plaintext highlighter-rouge">feature_range</code> để đưa vào giá trị min và max nếu bạn muốn.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="c1"># create scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Để đảo ngược miền giá trị sau khi scale về miền giá trị gốc giúp thuận tiện cho việc báo cáo hay vẽ biểu đồ, bạn có thể gọi hàm <code class="language-plaintext highlighter-rouge">inverse_transform</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="c1"># Ví dụ về scale sử dụng MinMaxScaler
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1"># Load dữ liệu
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># tạo bộ scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="c1"># fit scaler vào data
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># Thực hiện scale
</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># quay lại miền giá trị cũ
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">normalized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Bạn cũng có thể thực hiện trong một bước duy nhất bằng cách sử dụng hàm fit_transform (); ví dụ:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="c1"># Ví dụ về scale sử dụng MinMaxScaler
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># tạo bộ scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="c1"># fit và transform đồng thời
</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># quay lại miền giá trị cũ
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">normalized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="data-standardization">Data Standardization</h2>

<p>Chuẩn hóa dữ liệu là việc scale dữ liệu về một phân bố trong đó giá trị trung bình của các quan sát bằng 0 và độ lệch chuẩn = 1. Kỹ thuật này còn được gọi là “whitening.”.
Nhờ việc chuẩn hóa, các thuật toán như linear regression, logistic regression được cải thiện.</p>

<p>Công thức chuẩn hóa như sau:</p>

\[x’ = \frac{x - \bar{x}}{\sigma}\]

<p>với $\bar{x}$ và $\sigma$ lần lượt là kỳ vọng và phương sai (standard deviation) của thành phần đó trên toàn bộ training data.</p>

<p>(theo https://machinelearningcoban.com/general/2017/02/06/featureengineering/)</p>

<p>Giống như normalization, standardization có thể có hiệu quả và thậm chí bắt buộc nếu giá trị dữ liệu đầu vào thuộc vào các miền giá trị khác nhau.</p>

<p>Standardization giả định các quan sát có phân phối Gaussian (dạng hình chuông). Nếu phân phối dữ liệu không có dạng phân phối chuẩn thì việc áp dụng standardize cũng không hiệu quả.</p>

<p>Để thực hiện standardize dữ liệu, chúng ta cần tính được giá trị trung bình và độ lệch chuẩn dựa trên các quan sát.</p>

<p>Công thức chuẩn hóa:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>y = (x - mean) / standard_deviation
</pre></td></tr></tbody></table></code></div></div>

<p>Trong đó mean được tính như sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>mean = sum(x) / count(x)
</pre></td></tr></tbody></table></code></div></div>

<p>Để tính độ lệch chuẩn (standard_deviation):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">standard_deviation</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span> <span class="nb">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="p">)</span> <span class="o">/</span> <span class="n">count</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Giả sử giá trị trung bình là 10, độ lệch chuẩn là 5, Với giá trị 20.7 sẽ được chuẩn hóa như sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>y = (x - mean) / standard_deviation
y = (20.7 - 10) / 5
y = (10.7) / 5
y = 2.14
</pre></td></tr></tbody></table></code></div></div>

<p>Chúng ta có thể chuẩn hóa dữ liệu bằng thư viện scikit-learn với StandardScaler:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="c1"># demonstrate data standardization with sklearn
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># create scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit scaler on data
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># apply transform
</span><span class="n">standardized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># inverse transform
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">standardized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Hoặc sử dụng hàm <code class="language-plaintext highlighter-rouge">fit_transform</code> như sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="c1"># demonstrate data standardization with sklearn
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># create scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit and transform in one step
</span><span class="n">standardized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># inverse transform
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">standardized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h1 id="thử-nghiệm-với-bài-toán-sử-dụng-mô-hình-hồi-quy">Thử nghiệm với bài toán sử dụng mô hình hồi quy</h1>

<p>Một bài toán sử dụng mô hình dự báo hồi quy thường liên quan đến việc dự đoán một đại lượng có giá trị thực. Ví dụ bài toán dự đoán giá nhà, dự đoán giá cổ phiếu…</p>

<p>Trong phần này, chúng ta sẽ khảo sát các loss function phù hợp cho các bài toán regression.</p>

<p>Để tạo dữ liệu demo cho bài toán regression, mình sẽ sử dụng hàm make_regression() có sẵn trong thư viện của scikit-learn. Hàm này sẽ tạo dữ liệu mẫu với các biến đầu vào, nhiễu và các thuộc tính khác…</p>

<p>Chúng ta sẽ sử dụng hàm này để tạo ra dữ liệu gồm 20 features, 10 features có ý nghĩa về mặt dữ liệu và 10 features không có ý nghĩa. Mình sẽ tạo 1,000 điểm dữ liệu ngẫu nhiên cho bài toán. Tham số random_state sẽ đảm bảo cho chúng ta các dữ liệu là như nhau mỗi lần chạy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Các biến đầu vào đều dưới dạng phân phối Gaussian. Tương tự với biến đầu ra.</p>

<p>Mình sẽ vẽ thử biểu đồ các biến đầu vào:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="c1"># regression predictive modeling problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># histograms of input variables
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># histogram of target variable
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Chạy thử đoạn code trên sẽ cho chúng ta 2 kết quả như sau:</p>

<ul>
  <li>Đầu tiên là phân bố của 2 biến trong số 12 biến:</li>
</ul>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/Histograms-of-Two-of-the-Twenty-Input-Variables-for-the-Regression-Problem.webp" alt="Phân bố của 2 biến trong số 12 biến" />
<em>Phân bố của 2 biến trong số 12 biến</em></p>

<ul>
  <li>Thứ 2 là phân bố của biến mục tiêu. Mặc dù miền giá trị rộng hơn nhưng phân bố vẫn dưới dạng phân bố chuẩn.</li>
</ul>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/Histogram-of-the-Target-Variable-for-the-Regression-Problem.webp" alt="Phân bố của biến mục tiêu" />
<em>Phân bố của biến mục tiêu</em></p>

<p>Như vậy chúng ta sẽ sử dụng mô hình để tiến hành các thử nghiệm và đánh giá.</p>

<h2 id="mlp-với-dữ-liệu-chưa-được-rescale">MLP với dữ liệu chưa được rescale</h2>

<p>Để demo việc tìm hiểu về sự ảnh hưởng của scaling, mình sẽ sử dụng một model đơn giản đó là Multilayer Perceptron (MLP).</p>

<p>Model sẽ gồm đầu vào là 20 features, mô hình sẽ có 1 lớp ẩn với 25 nodes, sau đó sử dụng hàm kích hoạt ReLU.
Đầu ra sẽ gồm 1 node tương ứng với giá trị đầu ra muốn dự đoán, cuối cùng sẽ là một hàm kích hoạt tuyến tính .</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="c1"># define model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Mình sẽ fit mô hình này với thuật toán tối ưu stochastic gradient descent và sử dụng learning rate là 0.01, momentum  0.9</p>

<p>Việc huấn luyện sẽ thực hiện qua 100 epochs và sử dụng tập testing để đánh giá mô hình sau mỗi epoch. Cuối cùng ta có thể vẽ lại được learning curves sau khi thực hiện xong.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span><span class="c1"># fit model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Hàm lỗi MSE (mean squared error) được tính toán trên tập huấn luyện và tập kiểm tra để xác định xem mô hình học thế nào.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="c1"># đánh giá mô hình
</span><span class="n">train_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Sau đó mình sẽ tiến hành vẽ lại biểu đồ thể hiện lỗi MSE trong quá trình huấn luyện dựa trên tập train và tập test thông qua mỗi epoch.
Việc đánh giá kết quả huấn luyện dựa trên biểu đồ sẽ giúp chúng ta dễ dàng tìm hiều hơn về các thử nghiệm.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="c1"># plot loss during training
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Mean Squared Error'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Code hoàn chỉnh như sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td><td class="rouge-code"><pre><span class="c1"># mlp with unscaled data for the regression problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># split into train and test
</span><span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
<span class="c1"># define model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
<span class="c1"># compile model
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
<span class="c1"># fit model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># evaluate the model
</span><span class="n">train_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Train: %.3f, Test: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_mse</span><span class="p">,</span> <span class="n">test_mse</span><span class="p">))</span>
<span class="c1"># plot loss during training
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Mean Squared Error'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Sau khi chạy code, chúng ta sẽ có giá trị MSE trên tập train và tập test.</p>

<p>Trong trường hợp này, mô hình không học được gì cả, dẫn đến giá trị dự đoán là NaN.
Các trọng số của mô hình bị explode trong quá trình huấn luyện do giá trị mất mát lớn ảnh hưởng đến việc cập nhật trọng bằng Gradient descent.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Train: nan, Test: nan
</pre></td></tr></tbody></table></code></div></div>

<p>Như vậy việc scale dữ liệu là hoàn toàn cần thiết khi xây dựng mô hình.</p>

<p>Do giá trị lỗi là NaN nên trong trường hợp này ta không thể vẽ được đồ thị hàm lỗi.</p>

<h2 id="mlp-với-việc-scale-biến-mục-tiêu">MLP với việc scale biến mục tiêu</h2>

<p>Chúng ta sẽ tiến hành cập nhật lại mô hình bằng cách scale lại biến đầu ra y của tập dữ liệu.</p>

<p>Khi đưa biến mục tiêu về cùng miền giá trị sẽ làm giảm kích thước gradient để cập nhật lại trọng số. Điều này sẽ làm mô hình và quá trình huấn luyện ổn định hơn.</p>

<p>Với biến mục tiêu có phân phối Gausian, chúng ta sẽ sử dụng phương pháp thay đổi tỉ lệ giá trị của biến bằng kỹ thuật standardize.
Chúng ta cần tính giá trị trung bình (mean) và độ lệch chuẩn (std) của biến để áp dụng phương pháp này.</p>

<p>Thư viện scikit-learn cần đầu vào dữ liệu là 1 ma trận 2 chiều gồm các dòng và các cột. Vì vậy biến mục tiêu Y từ ma trận 1D phải được reshape về 2D.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="c1"># reshape 1d arrays to 2d arrays
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Sau đó áp dụng StandardScaler vào để scale lại biến:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="c1"># created scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit scaler on training dataset
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform training dataset
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform test dataset
</span><span class="n">testy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Sau đó tương tự như phần trên, chúng ta sẽ tiến hành phân tích lỗi MSE thông qua đồ thị biểu diễn lỗi trong quá trình huấn luyện</p>

<p>Code thực hiện như sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre></td><td class="rouge-code"><pre><span class="c1"># mlp with scaled outputs on the regression problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># split into train and test
</span><span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
<span class="c1"># reshape 1d arrays to 2d arrays
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># created scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit scaler on training dataset
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform training dataset
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform test dataset
</span><span class="n">testy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
<span class="c1"># define model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
<span class="c1"># compile model
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
<span class="c1"># fit model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># evaluate the model
</span><span class="n">train_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Train: %.3f, Test: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_mse</span><span class="p">,</span> <span class="n">test_mse</span><span class="p">))</span>
<span class="c1"># plot loss during training
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Loss / Mean Squared Error'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Sau khi chạy, kết quả sẽ in ra giá trị MSE trên tập train và tập test</p>

<blockquote>
  <p>Chú ý khi chạy, kết quả có thể khác nhau do thuật toán khởi tạo ngẫu nhiên. Chúng ta nên chạy nhiều lần và lấy giá trị trung bình</p>
</blockquote>

<p>Kết quả in ra sẽ là:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Train: 0.003, Test: 0.007
</pre></td></tr></tbody></table></code></div></div>

<p>Biểu đồ đường thể hiện giá trị MSE trong quá trình huấn luyện của tập train (màu xanh) và tập test (màu cam)</p>

<p>Trong trường hợp này chúng ta có thể thấy mô hình nhanh chóng học được dữ liệu.
Kết quả độ lỗi trên tập test và tập train khá tốt và gần nhau chứng tỏ mô hình không bị underfit hay overfit.</p>

<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/Line-Plot-of-Mean-Squared-Error-on-the-Train-a-Test-Datasets-For-Each-Training-Epoch.webp" alt="Biểu đồ đường Mean Squared Error dựa trên tập huấn luyện và kiểm tra" />
<em>Biểu đồ đường Mean Squared Error dựa trên tập huấn luyện và kiểm tra</em></p>

<h2 id="perceptron-nhiều-lớp-với-việc-scale-biến-đầu-vào">Perceptron nhiều lớp với việc scale biến đầu vào</h2>

<p>Chúng ta nhận thấy việc scale dữ liệu làm ổn định quá trình huấn luyện và khớp với mô hình sau khi scale biến mục tiêu sang miền giá trị 0-1.</p>

<p>Ngoài ra chúng ta có thể cải thiện chất lượng mô hình bằng cách scale lại các biến đầu vào.</p>

<p>Mình sẽ so sánh hiệu quả của mô hình đối với việc không scale dữ liệu và scale dữ liệu bằng lần lượt 2 phương pháp standardize and normalize các biến đầu vào</p>

<p>Hàm get_dataset() dưới đây sẽ tiến hành tạo dữ liệu, scale và chia thành 2 tập dành cho testing và training:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="rouge-code"><pre>
<span class="c1"># prepare dataset with input and output scalers, can be none
</span><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">):</span>
	<span class="c1"># generate dataset
</span>	<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
	<span class="c1"># split into train and test
</span>	<span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
	<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
	<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
	<span class="c1"># scale inputs
</span>	<span class="k">if</span> <span class="n">input_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># fit scaler
</span>		<span class="n">input_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">output_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># reshape 1d arrays to 2d arrays
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="c1"># fit scaler on training dataset
</span>		<span class="n">output_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Tiếp theo mình sẽ định nghĩa hàm để fit MLP model vào tập dữ liệu tương ứng và trả về giá trị MSE trên tập test.</p>

<p>Hàm evaluate_model() được viết như sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="c1"># fit and evaluate mse of model on test set
</span><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">):</span>
	<span class="c1"># define model
</span>	<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
	<span class="c1"># compile model
</span>	<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
	<span class="c1"># fit model
</span>	<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="c1"># evaluate the model
</span>	<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">test_mse</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Neural network được huấn luyện dựa trên thuật toán stochastic. Vì vậy  nên với cùng 1 dữ liệu, kết quả thực hiện có thể khác nhau. Như vậy để đánh giá chính xác chúng ta cần lặp lại nhiều lần sau đó lấy giá trị trung bình.</p>

<p>Hàm repeated_evaluation() sẽ thực hiện 30 lần sau đó trả về danh sách các giá trị MSE của mỗi lần chạy</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c1"># evaluate model multiple times with given input and output scalers
</span><span class="k">def</span> <span class="nf">repeated_evaluation</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
	<span class="c1"># get dataset
</span>	<span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">)</span>
	<span class="c1"># repeated evaluation of model
</span>	<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
	<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
		<span class="n">test_mse</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">)</span>
		<span class="k">print</span><span class="p">(</span><span class="s">'&gt;%.3f'</span> <span class="o">%</span> <span class="n">test_mse</span><span class="p">)</span>
		<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">results</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Cuối cùng chúng ta có thể thực nghiệm và đánh giá với cùng 1 model dựa trên 3 cách</p>

<ul>
  <li>Không thực hiện scale đầu vào, chuẩn hóa biến đầu ra.</li>
  <li>Normalize đầu vào, chuẩn hóa biến đầu ra.</li>
  <li>Chuẩn hóa đầu vào, chuẩn hóa biến đầu ra.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="c1"># unscaled inputs
</span><span class="n">results_unscaled_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># normalized inputs
</span><span class="n">results_normalized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># standardized inputs
</span><span class="n">results_standardized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># summarize results
</span><span class="k">print</span><span class="p">(</span><span class="s">'Unscaled: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Normalized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Standardized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">)))</span>
<span class="c1"># plot results
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">results_unscaled_inputs</span><span class="p">,</span> <span class="n">results_normalized_inputs</span><span class="p">,</span> <span class="n">results_standardized_inputs</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'unscaled'</span><span class="p">,</span> <span class="s">'normalized'</span><span class="p">,</span> <span class="s">'standardized'</span><span class="p">]</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Code hoàn chỉnh như sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
</pre></td><td class="rouge-code"><pre><span class="c1"># compare scaling methods for mlp inputs on regression problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">mean</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">std</span>

<span class="c1"># prepare dataset with input and output scalers, can be none
</span><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">):</span>
	<span class="c1"># generate dataset
</span>	<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
	<span class="c1"># split into train and test
</span>	<span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
	<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
	<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
	<span class="c1"># scale inputs
</span>	<span class="k">if</span> <span class="n">input_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># fit scaler
</span>		<span class="n">input_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">output_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># reshape 1d arrays to 2d arrays
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="c1"># fit scaler on training dataset
</span>		<span class="n">output_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span>

<span class="c1"># fit and evaluate mse of model on test set
</span><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">):</span>
	<span class="c1"># define model
</span>	<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
	<span class="c1"># compile model
</span>	<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
	<span class="c1"># fit model
</span>	<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="c1"># evaluate the model
</span>	<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">test_mse</span>

<span class="c1"># evaluate model multiple times with given input and output scalers
</span><span class="k">def</span> <span class="nf">repeated_evaluation</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
	<span class="c1"># get dataset
</span>	<span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">)</span>
	<span class="c1"># repeated evaluation of model
</span>	<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
	<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
		<span class="n">test_mse</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">)</span>
		<span class="k">print</span><span class="p">(</span><span class="s">'&gt;%.3f'</span> <span class="o">%</span> <span class="n">test_mse</span><span class="p">)</span>
		<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">results</span>

<span class="c1"># unscaled inputs
</span><span class="n">results_unscaled_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># normalized inputs
</span><span class="n">results_normalized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># standardized inputs
</span><span class="n">results_standardized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># summarize results
</span><span class="k">print</span><span class="p">(</span><span class="s">'Unscaled: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Normalized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Standardized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">)))</span>
<span class="c1"># plot results
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">results_unscaled_inputs</span><span class="p">,</span> <span class="n">results_normalized_inputs</span><span class="p">,</span> <span class="n">results_standardized_inputs</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'unscaled'</span><span class="p">,</span> <span class="s">'normalized'</span><span class="p">,</span> <span class="s">'standardized'</span><span class="p">]</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>
<p>Sau khi chạy, code sẽ in ra giá trị lỗi MSE qua mỗi lần chạy.</p>

<p>Sau khi một trong số ba bộ tham số được đánh giá 30 lần, các lỗi trung bình cho mỗi cấu hình được in ra.</p>

<blockquote>
  <p>Chú ý khi chạy, kết quả có thể khác nhau do thuật toán khởi tạo ngẫu nhiên. Chúng ta nên chạy nhiều lần và lấy giá trị trung bình</p>
</blockquote>

<p>Trong trường hợp này chúng ta có thể thấy rằng việc scale biến đầu vào sẽ làm mô hình tốt hơn. Hơn nữa việc normalize các biến đầu vào cho kết quả tốt hơn standardize. Điều này có thể do việc lựa chọn activation function là linear</p>

<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="p">...</span>
<span class="o">&gt;</span><span class="mf">0.010</span>
<span class="o">&gt;</span><span class="mf">0.012</span>
<span class="o">&gt;</span><span class="mf">0.005</span>
<span class="o">&gt;</span><span class="mf">0.008</span>
<span class="o">&gt;</span><span class="mf">0.008</span>
<span class="n">Unscaled</span><span class="p">:</span> <span class="mf">0.007</span> <span class="p">(</span><span class="mf">0.004</span><span class="p">)</span>
<span class="n">Normalized</span><span class="p">:</span> <span class="mf">0.001</span> <span class="p">(</span><span class="mf">0.000</span><span class="p">)</span>
<span class="n">Standardized</span><span class="p">:</span> <span class="mf">0.008</span> <span class="p">(</span><span class="mf">0.004</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h1 id="further-reading">Further Reading</h1>

<h3 id="posts">Posts</h3>

<ul>
  <li><a href="https://machinelearningmastery.com/how-to-scale-data-for-long-short-term-memory-networks-in-python/">How to Scale Data for Long Short-Term Memory Networks in Python</a></li>
  <li><a href="https://machinelearningmastery.com/scale-machine-learning-data-scratch-python/">How to Scale Machine Learning Data From Scratch With Python</a></li>
  <li><a href="https://machinelearningmastery.com/normalize-standardize-time-series-data-python/">How to Normalize and Standardize Time Series Data in Python</a></li>
  <li><a href="https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/">How to Prepare Your Data for Machine Learning in Python with Scikit-Learn</a></li>
</ul>

<h3 id="books">Books</h3>

<ul>
  <li>Section 8.2 Input normalization and encoding, <a href="https://amzn.to/2S8qdwt">Neural Networks for Pattern Recognition</a>, 1995.</li>
</ul>

<h3 id="api">API</h3>

<ul>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html">sklearn.datasets.make_regression API</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">sklearn.preprocessing.MinMaxScaler API</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">sklearn.preprocessing.StandardScaler API</a></li>
</ul>

<h3 id="articles">Articles</h3>

<ul>
  <li><a href="ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std">Should I normalize/standardize/rescale the data? Neural Nets FAQ</a></li>
</ul>



      </div>

      <div class="post-tail-wrapper text-muted">

        <!-- categories -->
        
        <div class="post-meta mb-3">
          <i class="far fa-folder-open fa-fw mr-1"></i>
          
            <a href='/categories/machine-learning/'>Machine Learning</a>
        </div>
        

        <!-- tags -->
        
        <div class="post-tags">
          <i class="fa fa-tags fa-fw mr-1"></i>
          
          <a href="/tags/machine-learning/"
            class="post-tag no-text-decoration" >Machine learning</a>
          
          </div>
        

        <div class="post-tail-bottom
          d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
          
          <div class="license-wrapper">
            This post is licensed under
            <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
            by the author.
          </div>
          

          <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=11. Các phương pháp scale dữ liệu trong machine learning - Quy's blog&url=https://ndquy.github.io/posts/cac-phuong-phap-scaling/" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=11. Các phương pháp scale dữ liệu trong machine learning - Quy's blog&u=https://ndquy.github.io/posts/cac-phuong-phap-scaling/" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://telegram.me/share?text=11. Các phương pháp scale dữ liệu trong machine learning - Quy's blog&url=https://ndquy.github.io/posts/cac-phuong-phap-scaling/" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i class="fa-fw fas fa-link small" onclick="copyLink()"
        data-toggle="tooltip" data-placement="top" title="Copy link"></i>

  </span>
</div>


        </div><!-- .post-tail-bottom -->

      </div><!-- div.post-tail -->

    </div> <!-- .post -->


  </div> <!-- #post-wrapper -->

  

  

  <!--
  The Pannel on right side (Desktop views)
-->

<div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down">

  <div class="access">

  














  

    <div id="access-lastmod" class="post">
      <span>Recent Update</span>
      <ul class="post-content pl-0 pb-1 ml-1 mt-2">

      
        
        
        
        <li><a href="/posts/thuat-toan-phan-cum-kmeans/">15. Thuật toán phân cụm K-Means</a></li>
      
        
        
        
        <li><a href="/posts/danh-gia-xet-nghiem-covid-19/">Tản mạn - Đánh giá độ chính xác các bộ kit xét nghiệm thế nào?</a></li>
      
        
        
        
        <li><a href="/posts/ky-thuat-tang-cuong-du-lieu-nlp/">14. Kỹ thuật data augmentation trong NLP với Tiếng Việt</a></li>
      
        
        
        
        <li><a href="/posts/intent-classification/">13. Xác định ý định câu hỏi trong hệ thống hỏi đáp</a></li>
      
        
        
        
        <li><a href="/posts/cac-phuong-phap-scaling/">11. Các phương pháp scale dữ liệu trong machine learning</a></li>
      

      </ul>
    </div> <!-- #access-lastmod -->

  

  















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  
    <div id="access-tags">
      <span>Trending Tags</span>
      <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

      
        
        <a class="post-tag" href="/tags/machine-learning/">Machine learning</a>
      
        
        <a class="post-tag" href="/tags/google-analytics/">google analytics</a>
      
        
        <a class="post-tag" href="/tags/pageviews/">pageviews</a>
      
        
        <a class="post-tag" href="/tags/queue/">queue</a>
      
        
        <a class="post-tag" href="/tags/redis/">redis</a>
      
        
        <a class="post-tag" href="/tags/writing/">writing</a>
      

      </div>
    </div>
  
  </div> <!-- .access -->

  
    <!-- BS-toc.js will be loaded at medium priority -->
    <script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>
    <div id="toc-wrapper" class="pl-0 pr-4 mb-5">
      <span class="pl-3 pt-2 mb-2">Contents</span>
      <nav id="toc" data-toggle="toc"></nav>
    </div>
  

</div> <!-- #panel-wrapper -->


</div> <!-- .row -->

<div class="row">
  <div class="col-12 col-lg-11 col-xl-8">
    <div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">

    <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->






  <div id="related-posts" class="mt-5 mb-2 mb-sm-4">
    <h3 class="pt-2 mt-1 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/gioi-thieu-machine-learning/">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Apr  1
  

  <i class="unloaded">2021-04-01T14:32:00+08:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>1. Phân loại các thuật toán Machine Learning</h3>
            <div class="text-muted small">
              <p>
                





                Phân loại các thuật toán

Có rất nhiều loại thuật toán về Machine Learning, thông thường chúng được phân ra làm các loại với tiêu chí như sau:

  Quá trình huấn luyện có cần sự giám sát của con ngư...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/loss-function-p2/">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Apr  4
  

  <i class="unloaded">2021-04-04T16:47:00+08:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>8. Loss function P2 - hàm mất mát cho bài toán binary classification</h3>
            <div class="text-muted small">
              <p>
                





                Phân lớp nhị phân là bài toán mà biến đầu ra (y) chỉ nhận một trong hai giá trị là 1 trong 2 nhãn.

Bài toán thường dưới dạng bài toán dự đoán giá trị 0 hoặc 1 cho lớp đầu tiên hoặc lớp thứ hai và ...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/loss-function-p3/">
          <div class="card-body">
            <!--
  Date format snippet
  See: /assets/js/_utils/timeage.js
-->





<span class="timeago small"
  

  
   >

  
  

  
    Apr  4
  

  <i class="unloaded">2021-04-04T16:47:00+08:00</i>

</span>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>9. Loss function P3 - hàm mất mát cho bài toán multi-class classification</h3>
            <div class="text-muted small">
              <p>
                





                Phân đa lớp là những bài toán mà mô hình dự đoán trong đó các đầu vào được chỉ định là một trong nhiều hơn hai lớp.

Mô hình dự đoán một giá trị số nguyên, trong đó mỗi lớp được gán một giá trị số ...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->



    <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/okapi-bm-25-tim-kiem-tieng-viet/" class="btn btn-outline-primary"
    prompt="Older">
    <p>10. Áp dụng Okapi BM25 vào tìm kiếm thông tin dựa trên Tiếng Việt</p>
  </a>
  

  
  <a href="/posts/Phan-lop-danh-gia-he-thong-phan-lop/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>12. Các phương pháp đánh giá mô hình phân lớp phần 1</p>
  </a>
  

</div>


    

    </div> <!-- #post-extend-wrapper -->

  </div> <!-- .col-* -->

</div> <!-- .row -->



  <!--
  image lazy load: https://github.com/ApoorvSaxena/lozad.js
-->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>

<script type="text/javascript">
  const imgs = document.querySelectorAll('.post-content img');
  const observer = lozad(imgs);
  observer.observe();
</script>




        <!--
  The Footer
-->

<footer class="d-flex w-100 justify-content-center">
  <div class="d-flex justify-content-between align-items-center">
    <div class="footer-left">
      <p class="mb-0">
        © 2021
        <a href="https://twitter.com/username">Nguyễn Đình Quý</a>.
        
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
        
      </p>
    </div>

    <div class="footer-right">
      <p class="mb-0">
        Powered by
        <a href="https://jekyllrb.com" target="_blank" rel="noopener">STE</a>
        with
        <a href="https://github.com/cotes2020/jekyll-theme-chirpy"
          target="_blank" rel="noopener">DD</a>
        theme.
      </p>
    </div>

  </div> <!-- div.d-flex -->
</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      <h4 class="text-muted mb-4">Trending Tags</h4>

      















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



      
        
        <a class="post-tag" href="/tags/machine-learning/">Machine learning</a>
      
        
        <a class="post-tag" href="/tags/google-analytics/">google analytics</a>
      
        
        <a class="post-tag" href="/tags/pageviews/">pageviews</a>
      
        
        <a class="post-tag" href="/tags/queue/">queue</a>
      
        
        <a class="post-tag" href="/tags/redis/">redis</a>
      
        
        <a class="post-tag" href="/tags/writing/">writing</a>
      

    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="https://ndquy.github.io{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No result founds.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


  </body>

</html>

