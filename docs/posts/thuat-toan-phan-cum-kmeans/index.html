<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Thuat Toan Phan Cum Kmeans" /><meta property="og:locale" content="en_US" /><meta name="description" content="title: 15. Thuật toán phân cụm K-Means author: Quy Nguyen date: 2021-09-09 10:47:00 +0700 categories: [Machine Learning] tags: [Machine learning] math: true — Thuật toán phân cụm K-Means là một trong những thuật toán phân cụm dữ liệu dựa trên học không giám sát được sử dụng nhiều trong các học máy nói chung và trong khai phá dữ liệu nói riêng. Nhắc lại về học có giám sát và không giám sát Học có giám sát Trong học máy, lớp các thuật toán học có giám sát Supervised learning là việc học các xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${{x_1, x_2, …, x_N}; {y_1, y_2,…, y_N}}$ sao cho $y_i ≅ f(x_i )$ với mọi i. Để thực hiện điều này tập dữ liệu huấn luyện gồm các điểm dữ liệu trong đó mỗi điểm dữ liệu có chứa nhãn tương ứng. Học không giám sát Học cách xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${x_1, x_2, …, x_N}$. Các dữ liệu trong tập dữ liệu dùng để huấn luyện không có nhãn. Các thuật toán phân cụm dựa trên tập dữ liệu chính là cách xác định cấu trúc ẩn trong tập dữ liệu đó." /><meta property="og:description" content="title: 15. Thuật toán phân cụm K-Means author: Quy Nguyen date: 2021-09-09 10:47:00 +0700 categories: [Machine Learning] tags: [Machine learning] math: true — Thuật toán phân cụm K-Means là một trong những thuật toán phân cụm dữ liệu dựa trên học không giám sát được sử dụng nhiều trong các học máy nói chung và trong khai phá dữ liệu nói riêng. Nhắc lại về học có giám sát và không giám sát Học có giám sát Trong học máy, lớp các thuật toán học có giám sát Supervised learning là việc học các xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${{x_1, x_2, …, x_N}; {y_1, y_2,…, y_N}}$ sao cho $y_i ≅ f(x_i )$ với mọi i. Để thực hiện điều này tập dữ liệu huấn luyện gồm các điểm dữ liệu trong đó mỗi điểm dữ liệu có chứa nhãn tương ứng. Học không giám sát Học cách xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${x_1, x_2, …, x_N}$. Các dữ liệu trong tập dữ liệu dùng để huấn luyện không có nhãn. Các thuật toán phân cụm dựa trên tập dữ liệu chính là cách xác định cấu trúc ẩn trong tập dữ liệu đó." /><link rel="canonical" href="https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" /><meta property="og:url" content="https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" /><meta property="og:site_name" content="Quy’s blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-08-08T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Thuat Toan Phan Cum Kmeans" /><meta name="twitter:site" content="@dinhquy94" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"title: 15. Thuật toán phân cụm K-Means author: Quy Nguyen date: 2021-09-09 10:47:00 +0700 categories: [Machine Learning] tags: [Machine learning] math: true — Thuật toán phân cụm K-Means là một trong những thuật toán phân cụm dữ liệu dựa trên học không giám sát được sử dụng nhiều trong các học máy nói chung và trong khai phá dữ liệu nói riêng. Nhắc lại về học có giám sát và không giám sát Học có giám sát Trong học máy, lớp các thuật toán học có giám sát Supervised learning là việc học các xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${{x_1, x_2, …, x_N}; {y_1, y_2,…, y_N}}$ sao cho $y_i ≅ f(x_i )$ với mọi i. Để thực hiện điều này tập dữ liệu huấn luyện gồm các điểm dữ liệu trong đó mỗi điểm dữ liệu có chứa nhãn tương ứng. Học không giám sát Học cách xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${x_1, x_2, …, x_N}$. Các dữ liệu trong tập dữ liệu dùng để huấn luyện không có nhãn. Các thuật toán phân cụm dựa trên tập dữ liệu chính là cách xác định cấu trúc ẩn trong tập dữ liệu đó.","headline":"Thuat Toan Phan Cum Kmeans","dateModified":"2021-09-09T12:32:07+08:00","datePublished":"2021-08-08T00:00:00+08:00","url":"https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/","mainEntityOfPage":{"@type":"WebPage","@id":"https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title>Thuat Toan Phan Cum Kmeans | Quy's blog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/blog/quynd_avarta.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Quy's blog</a></div><div class="site-subtitle font-italic">Lập trình, Machine learning và Khoa học dữ liệu</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME PAGE</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/dinhquy94" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/dinhquy94" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['dinhquy94','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Thuat Toan Phan Cum Kmeans</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Thuat Toan Phan Cum Kmeans</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Nguyễn Đình Quý </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Aug 8, 2021, 12:00 AM +0800" prep="on" > Aug 8 <i class="unloaded">2021-08-08T00:00:00+08:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, Sep 9, 2021, 11:32 AM +0700" prefix="Updated " > Sep 9 <i class="unloaded">2021-09-09T12:32:07+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2308 words">12 min</span></div></div><div class="post-content"><hr /><p>title: 15. Thuật toán phân cụm K-Means<br /> author: Quy Nguyen<br /> date: 2021-09-09 10:47:00 +0700<br /> categories: [Machine Learning]<br /> tags: [Machine learning]<br /> math: true —<br /> Thuật toán phân cụm K-Means là một trong những thuật toán phân cụm dữ liệu dựa trên học không giám sát được sử dụng nhiều trong các học máy nói chung và trong khai phá dữ liệu nói riêng.</p><h1 id="nhắc-lại-về-học-có-giám-sát-và-không-giám-sát">Nhắc lại về học có giám sát và không giám sát</h1><h2 id="học-có-giám-sát">Học có giám sát</h2><p>Trong học máy, lớp các thuật toán học có giám sát Supervised learning là việc học các xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${{x_1, x_2, …, x_N}; {y_1, y_2,…, y_N}}$ sao cho $y_i ≅ f(x_i )$ với mọi i.<br /> Để thực hiện điều này tập dữ liệu huấn luyện gồm các điểm dữ liệu trong đó mỗi điểm dữ liệu có chứa nhãn tương ứng.</p><h2 id="học-không-giám-sát">Học không giám sát</h2><p>Học cách xác định hàm y = f(x) từ tập dữ liệu huấn luyện gồm ${x_1, x_2, …, x_N}$. Các dữ liệu trong tập dữ liệu dùng để huấn luyện không có nhãn.<br /> Các thuật toán phân cụm dựa trên tập dữ liệu chính là cách xác định cấu trúc ẩn trong tập dữ liệu đó.</p><h1 id="ví-dụ-về-học-không-giám-sát">Ví dụ về học không giám sát</h1><p>Học không giám sát nhằm phân dữ liệu thành một số cụm cho trước. <br /> Ví dụ phổ biến cho thuật toán này đó là việc phân loại khách hàng. <br /> Giả sử ta có một tập dữ liệu mua hàng của các khách hàng, ta có thể đưa dữ liệu này vào thuật toán phân cụm để tiến hành phân loại khách hàng. <br /> Các khách hàng có những đặc điểm tương đồng về mặt thông tin hoặc dựa trên lịch sử mua hàng, hành vi mua hàng có thể phân thành các loại khách hàng khác nhau.<br /> Nói cách khác mỗi loại khách hàng sẽ có những đặc điểm chung giống nhau, và những đặc điểm đó được phát hiện thông qua thuật toán phân cụm mà chúng ta sẽ nghiên cứu ngay sau đây.<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/k-means-example.png" alt="Ví dụ về K-Means" /><br /> <em>Ví dụ về K-means</em></p><p>Ngoài ra có một ví dụ khác mà chúng ta cũng hay bắt gặp, đó là các mạng xã hội luôn tìm cách phân cụm những người có cùng sở thích, thói quen để đưa ra những gợi ý kết bạn hay tham gia một nhóm nào đó.<br /> Để xác định được những người có các điểm tương đồng trong mạng xã hội ta cần một thuật toán phân cụm.</p><h1 id="bài-toán-phân-cụm">Bài toán phân cụm</h1><p>Chúng ta sẽ xem xét lần lượt các nội dung liên quan đến bài toán phân cụm.</p><h2 id="khái-quát-bài-toán-phân-cụm--đầu-vào-tập-dữ-liệu-không-có-nhãn">Khái quát bài toán phân cụm: * <strong>Đầu vào</strong>: Tập dữ liệu không có nhãn</h2><ul><li><strong>Đầu ra</strong>: Các cụm dữ liệu đã được phân chia</ul><p>Như vậy mục tiêu của bài toán phân cụm là những cụm dữ liệu được phân chia bởi thuật toán. Chúng ta cùng xem xét đặc điểm của một cụm.</p><h2 id="một-cụm">Một cụm</h2><ul><li><strong>Trong một cụm thì các điểm dữ liệu thuộc về cụm đó phải giống nhau</strong> theo một ý nghĩa, việc xác định <em>thế nào là giống nhau</em> quyết định đầu ra của thuật toán này. Ví dụ như để xác định những khách hàng thuộc cùng một nhóm thì trước tiên ta cần phải xác định định nghĩa <em>thế nào là giống nhau</em>?<br /> Hai khách hàng tương đồng có thể được xem xét dựa trên các tiêu chí khác nhau, có thể dựa trên số lần mua hàng, số tiền mua hàng, hay giới tính, độ tuổi…<li><strong>Hai cụm dữ liệu là khác nhau</strong>: Điều này là cần thiết vì khi phân cụm các cụm phải là tách biệt nhau hoàn toàn, không có sự chồng lấp 2 cụm dữ liệu với nhau.<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/clusters.png" alt="Mục tiêu bài toán phân cụm" /></ul><h2 id="một-số-phương-pháp-phân-cụm-phổ-biến">Một số phương pháp phân cụm phổ biến</h2><ul><li><strong>Phân cụm dựa trên phân vùng</strong> (Partition-based clustering): Đây là phương pháp phổ biến và được sử dụng nhiều trong các bài toán phân cụm. Mục tiêu là phân dữ liệu thành các phân vùng khác nhau.<li><strong>Phân cụm thứ bậc</strong> (Hierarchical clustering): Ngoài việc phân thành các cụm lớn, phương pháp này còn phân các cụm lớn thành những cụm nhỏ hơn dưới dạng thứ bậc.<li>Mô hình hỗn hợp (Mixture models)<li>Phân cụm sâu (Deep clustering): Sử dụng mạng nơ-ron học sâu để phân cụm.</ul><h2 id="đánh-giá-chất-lượng-mô-hình-phân-cụm">Đánh giá chất lượng mô hình phân cụm</h2><p>Để đánh giá chất lượng mô hình phân cụm ta có thể đánh giá thông qua một số phương pháp như sau:</p><ul><li>Khoảng cách / sự khác biệt giữa hai cụm bất kỳ phải lớn. (khoảng cách giữa các cụm): Giữa các cụm phải được tách biệt nhau hoàn toàn và sự khác biệt giữa 2 cụm phải đủ lớn để phân biệt 2 cụm với nhau.<li>Chênh lệch giữa các điểm dữ liệu bên trong một cụm phải nhỏ. Chênh lệch ở đây thể hiện sự khác biệt với nhau về mặt tương đồng giữa 2 dữ liệu theo tiêu chí phân cụm.</ul><h1 id="thuật-toán-phân-cụm-k-means">Thuật toán phân cụm K-means</h1><p>Thuật toán phân cụm K-means được giới thiệu năm 1957 bởi Lloyd K-means và là phương pháp phổ biến nhất cho việc phân cụm, dựa trên việc phân vùng dữ liệu <br /> Biểu diễn dữ liệu: $D = {x_1, x_2, …, x_r }$, với $x_i$ là vector n chiều trong không gian Euclidean. K-means phân cụm D thành K cụm dữ liệu:</p><ul><li>Mỗi cụm dữ liệu có một điểm trung tâm gọi là centroid.<li>K là một hằng số cho trước.</ul><h2 id="các-bước-trong-thuật-toán-k-means">Các bước trong thuật toán K-Means</h2><ul><li><strong>Đầu vào</strong>: Cho tập dữ liệu D, với K là số cụm, phép đo khoảng cách giữa 2 điểm dữ liệu là d(x,y)<li><strong>Khởi tạo</strong>: Khởi tạo K điểm dữ liệu trong D làm các điểm trung tâm (centroid)<li><strong>Lặp lại</strong> các bước sau đến khi <strong>hội tụ</strong>:<ul><li><strong><em>Bước 1</em></strong>: Với mỗi điểm dữ liệu, gán điểm dữ liệu đó vào cluster có khoảng cách đến điểm trung tâm của cluster là nhỏ nhất.<li><strong><em>Bước 2:</em></strong> Với mỗi cluster, xác định lại điểm trung tâm của tất cả các điểm dữ liệu được gán vào cluster đó.</ul></ul><p>Sau đây là một số bước dưới dạng hình ảnh:<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/k-mean-step1.jpg" alt="Thuật toán k-means" /><br /> Tại bước này thuật toán sẽ khởi tạo <strong>k</strong> điểm dữ liệu trung tâm ban đầu, sau đó qua iteration 1 để thực hiện bước 1: gán các điểm dữ liệu vào cluster và bước 2: Xác định lại điểm trung tâm.<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/k-mean-step2.jpg" alt="Thuật toán k-means" /><br /> Các vòng lặp iteration 2 và iteration 3 tiếp tục thực hiện như vậy đến khi nào thuật toán hội tụ thì dừng lại.</p><h2 id="điều-kiện-hội-tụ-điều-kiện-dừng-thuật-toán">Điều kiện hội tụ (điều kiện dừng thuật toán)</h2><p>Ta sẽ xác định điều kiện dừng thuật toán theo một số cách như sau:</p><ul><li>Tại 1 vòng lặp: có ít các điểm dữ liệu được gán sang cluster khác hoặc<li>Điểm trung tâm (centroid) không thay đổi nhiều hoặc<li>Giá trị hàm mất mát không thay đổi nhiều:<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/k-mean-loss.jpg" alt="Thuật toán k-means" /></ul><p>Trong đó $C_i$ là cluster thứ i, $m_i$ là điểm trung tâm của cluster $C_i$ tương ứng.</p><p>Nhìn chung về điều kiện hội tụ có thể thấy mối liên hệ giữa các điều kiện là gần tương đồng như nhau. Khi có ít điểm dữ liệu được gán sang cluster khác có thể khiến điểm trung tâm không thay đổi nhiều và từ đó hàm mất mát cũng sẽ ít bị ảnh hưởng. Vậy nên chúng ta có thể sử dụng 1 trong 3 cách trên để xác định điều kiện dừng của thuật toán.</p><h2 id="xác-định-điểm-trung-tâm-của-cluster">Xác định điểm trung tâm của cluster</h2><p>Để xác định điểm trung tâm của cluster ta sử dụng công thức như sau:<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/k-mean-center_calculate.jpg" alt="Thuật toán k-means" /></p><p>Trong đó $C_i$ là cluster thứ i, $m_i$ là điểm trung tâm của cluster $C_i$ tương ứng.</p><h2 id="phép-đo-khoảng-cách">Phép đo khoảng cách</h2><p>Trong K-means để đánh giá mức độ giống nhau hay khoảng cách giữa 2 điểm dữ liệu ta có thể sử dụng các phép đo khoảng cách khác nhau. Ngoài khoảng cách Euclidean, tuỳ thuộc vào từng bài toán có thể sử dụng phương pháp đo khác (cosine, manhattan…)</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/euclid.jpg" alt="Thuật toán k-means - Phép đo euclid" /></p><p>Mọi phương pháp tính khoảng cách giữa 2 vector đều có thể được sử dụng. Mỗi cách tính khoảng cách thể hiện cách nhìn nhận về dữ liệu</p><ul><li>Có vô số cách tính khoảng cách<li>Cách tính khoảng cách nào là tốt? Câu trả lời phụ thuộc vào từng bài toán để đưa ra cách tính khoảng cách phù hợp.</ul><h1 id="một-số-ảnh-hưởng-đến-thuật-toán-k-means">Một số ảnh hưởng đến thuật toán K-means</h1><p>Chúng ta sẽ cùng nhau xem xét một số ảnh hưởng đến thuật toán K-means và phương pháp để xử lý.</p><h2 id="ảnh-hưởng-của-outlier">Ảnh hưởng của outlier</h2><h3 id="outlier-là-gì">Outlier là gì?</h3><p>Hiểu đơn giản thì Outliers là một hoặc nhiều cá thể khác hẳn đối với các thành viên còn lại của nhóm. Sự khác biệt này có thể dựa trên nhiều tiêu chí khác nhau như giá trị hay thuộc tính. Ví dụ về outlier có thể như là nhiễu trong các cảm biến hay lỗi trong quá trình nhập liệu của người dùng ảnh hưởng đến chất lượng của dữ liệu.</p><h3 id="xem-xét-ảnh-hường">Xem xét ảnh hường</h3><p>K-means nhạy cảm với các điểm outlier, ví dụ: Các điểm dữ liệu outlier ảnh hưởng lớn đến kết quả của việc phân cụm:</p><ul><li>Các điểm dữ liệu outlier có khoảng cách đến các điểm dữ liệu chuẩn rất lớn.<li>Phân bố của các điểm outliner rất khác so với các điểm dữ liệu chuẩn<li>Nhiễu hoặc lỗi của dữ liệu được thể hiện trong các điểm outlier</ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/oulier.jpg" alt="Thuật toán k-means - Ví dụ về oulier" /></p><h3 id="khắc-phục-outlier">Khắc phục outlier</h3><ul><li><strong>Outlier removal</strong>: Có thể loại bỏ các điểm dữ liệu xa đáng kể so với điểm trung tâm (centroid) của các cluster so với các điểm dữ liệu khác. Việc loại bỏ có thể được thực hiện trước hoặc trong khi phân cụm.<li><strong>Random sampling</strong>: Thay vì phân cụm toàn bộ tập dữ liệu, chúng ta sẽ lấy ngẫu nhiên tập con S từ tập dữ liệu huấn luyện. S được sử dụng để phân cụm, tập S lúc này sẽ có ít các điểm outlier hơn tập dữ liệu gốc. Sau khi phân cụm xong, tập dữ liệu còn lại sẽ được gán vào các cụm đã học được</ul><h2 id="ảnh-hưởng-của-việc-khởi-tạo-trung-tâm">Ảnh hưởng của việc khởi tạo trung tâm</h2><p>Chất lượng của K-means phụ thuộc vào việc khởi tạo các điểm centroid<br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/k-mean-problem1.jpg" alt="Thuật toán k-means " /></p><p><strong>Giải pháp 1</strong>: Lặp lại nhiều lần thuật toán K-means:</p><ul><li>Mỗi lần chạy lại thuật toán K-means sẽ khởi tạo các điểm centroid khác nhau<li>Sau quá trình học, tiến hành gộp các kết quả từ các lần chạy thành kết quả cuối cùng</ul><p><strong>Giải pháp 2</strong>: Thuật toán K-means++ : Để tìm ra cụm tốt nhất, chúng ta có thể lần lượt khởi tại các điểm trung tâm từ tập D tuần tự như sau:</p><ul><li>Lấy ngẫu nhiên điểm centroid đầu tiên m1<li>Lấy điểm centroid tiếp theo là điểm xa nhất so với m1<li>..<li>Lấy điểm centroid thứ i $(m_i)$ là điểm xa nhất so với ${ m_1,…, m_i-1}$<li>…<li>Bằng cách này K-means sẽ hội tụ về gần kết quả tối ưu (Arthur, D.; Vassilvitskii, 2007)</ul><h1 id="tổng-kết">Tổng kết</h1><h2 id="ưu-điểm-của-thuật-toán-k-means">Ưu điểm của thuật toán K-means:</h2><p>*Đơn giản</p><ul><li>Hiệu quả trong thực tế<li>Đảm bảo hội tụ trong thời gian đa thức [Manthey &amp; Röglin, JACM, 2011]<li>Linh hoạt trong việc lựa chọn phương pháp đo khoảng cách<h2 id="hạn-chế">Hạn chế:</h2><li>Việc lựa chọn các tính khoảng cách cho bài toán cụ thể khó.<li>Nhạy cảm với các điểm dữ liệu outlier</ul><h1 id="code-python">Code Python</h1><p>Load các thư viện cần thiết</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></table></code></div></div><p>Khởi tạo dữ liệu demo</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># Khởi tạo dữ liệu demo
</span><span class="n">means</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>  <span class="p">[</span><span class="mi">9</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>  <span class="p">[</span><span class="mi">3</span><span class="p">,</span>  <span class="mi">6</span><span class="p">]]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>  <span class="p">[</span><span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">]]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cov</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span><span class="nb">object</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cov</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">original_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">N</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">).</span><span class="n">T</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">kmeans_display</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">amax</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">X0</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">X1</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X0</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X0</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'b^'</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'go'</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'rs'</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">8</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">kmeans_display</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">original_label</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/kmeansimplement.png" alt="Thuật toán k-means " /> <em>Biểu diễn dữ liệu demo</em></p><p>Xây dựng các hàm cần thiết</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">init_centroids</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="c1"># pick k centroid randomly
</span>    <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">assign_labels</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="n">clusters</span> <span class="o">=</span> <span class="p">{}</span> 
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="n">clusters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">featureset</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span> 
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">featureset</span> <span class="o">-</span> <span class="n">centroid</span><span class="p">)</span> <span class="k">for</span> <span class="n">centroid</span> <span class="ow">in</span> <span class="n">centroids</span><span class="p">]</span>
    <span class="n">cluster</span> <span class="o">=</span> <span class="n">distances</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">distances</span><span class="p">))</span>
    <span class="n">clusters</span><span class="p">[</span><span class="n">cluster</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">featureset</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">clusters</span>
  
<span class="k">def</span> <span class="nf">update_centroids</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
  <span class="n">new_centroids</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">data_points</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">new_centroids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">average</span><span class="p">(</span><span class="n">data_points</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">new_centroids</span>

<span class="k">def</span> <span class="nf">has_converged</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="n">new_centers</span><span class="p">):</span>
    <span class="c1"># return True if two sets of centers are the same
</span>    <span class="k">return</span> <span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="nb">tuple</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">centers</span><span class="p">])</span> <span class="o">==</span> 
        <span class="nb">set</span><span class="p">([</span><span class="nb">tuple</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">new_centers</span><span class="p">]))</span>

</pre></table></code></div></div><p>Phần code triển khai thuật toán</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">3</span> 
<span class="n">centroids</span> <span class="o">=</span> <span class="n">init_centroids</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
  <span class="n">clusters</span> <span class="o">=</span> <span class="n">assign_labels</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">new_centroids</span> <span class="o">=</span> <span class="n">update_centroids</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">has_converged</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="n">new_centroids</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'convered'</span><span class="p">)</span>
    <span class="k">break</span>
  <span class="n">centroids</span> <span class="o">=</span> <span class="n">new_centroids</span>

<span class="n">X_</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">datapoints</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">datapoint</span> <span class="ow">in</span> <span class="n">datapoints</span><span class="p">:</span>
    <span class="n">X_</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">datapoint</span><span class="p">)</span>
    <span class="n">labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
</pre></table></code></div></div><p>Hiển thị kết quả</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">kmeans_display</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
</pre></table></code></div></div><p>Kết quả thuật toán</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/blog/kmeansimplement2.png" alt="Thuật toán k-means " /> <em>Biểu diễn kết quả phân cụm của thuật toán</em></p></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Thuat Toan Phan Cum Kmeans - Quy's blog&url=https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Thuat Toan Phan Cum Kmeans - Quy's blog&u=https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Thuat Toan Phan Cum Kmeans - Quy's blog&url=https://ndquy.github.io/posts/thuat-toan-phan-cum-kmeans/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/thuat-toan-phan-cum-kmeans/">Thuat Toan Phan Cum Kmeans</a><li><a href="/posts/ky-thuat-tang-cuong-du-lieu-nlp/">14. Kỹ thuật data augmentation trong NLP với Tiếng Việt</a><li><a href="/posts/intent-classification/">13. Xác định ý định câu hỏi trong hệ thống hỏi đáp</a><li><a href="/posts/cac-phuong-phap-scaling/">11. Các phương pháp scale dữ liệu trong machine learning</a><li><a href="/posts/cai-dat-queue-python-production/">Triển khai hàng đợi xử lý bằng python với Redis</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/google-analytics/">google analytics</a> <a class="post-tag" href="/tags/pageviews/">pageviews</a> <a class="post-tag" href="/tags/queue/">queue</a> <a class="post-tag" href="/tags/redis/">redis</a> <a class="post-tag" href="/tags/writing/">writing</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ky-thuat-tang-cuong-du-lieu-nlp/"><div class="card-body"> <span class="timeago small" > May 8 <i class="unloaded">2021-05-08T16:47:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>14. Kỹ thuật data augmentation trong NLP với Tiếng Việt</h3><div class="text-muted small"><p> Tăng cường dữ liệu (Data Augmentation) là một khái niệm khá phổ biến trong deep learning mà chắc hẳn ai đang nghiên cứu cũng đã từng nghe hoặc sử dụng đến. Nói đơn giản hơn, Data Augmentation là kỹ...</p></div></div></a></div><div class="card"> <a href="/posts/intent-classification/"><div class="card-body"> <span class="timeago small" > Apr 14 <i class="unloaded">2021-04-14T16:47:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>13. Xác định ý định câu hỏi trong hệ thống hỏi đáp</h3><div class="text-muted small"><p> Mục tiêu bài viết Phân tích câu hỏi là pha đầu tiên trong kiến trúc chung của một hệ thống hỏi đáp, có nhiệm vụ tìm ra các thông tin cần thiết làm đầu vào cho quá trình xử lý của các pha sau (tríc...</p></div></div></a></div><div class="card"> <a href="/posts/Phan-lop-danh-gia-he-thong-phan-lop/"><div class="card-body"> <span class="timeago small" > Apr 10 <i class="unloaded">2021-04-10T16:47:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>12. Các phương pháp đánh giá mô hình phân lớp phần 1</h3><div class="text-muted small"><p> Trong bài viết này mình sẽ nói đến bài toán phân lớp và các phương pháp đánh giá 1 mô hình phân lớp. Bài toán phân lớp Mình sẽ sử dụng bộ dữ liệu MNIST, gồm 70.000 ảnh nhỏ của các số viết tay bởi...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ky-thuat-tang-cuong-du-lieu-nlp/" class="btn btn-outline-primary" prompt="Older"><p>14. Kỹ thuật data augmentation trong NLP với Tiếng Việt</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://twitter.com/username">Nguyễn Đình Quý</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">STE</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">DD</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/google-analytics/">google analytics</a> <a class="post-tag" href="/tags/pageviews/">pageviews</a> <a class="post-tag" href="/tags/queue/">queue</a> <a class="post-tag" href="/tags/redis/">redis</a> <a class="post-tag" href="/tags/writing/">writing</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ndquy.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
