I"∏T<p>Trong c√°c thu·∫≠t to√°n machine learning n√≥i chung, v√† trong deep learning n√≥i ri√™ng, c√°c m√¥ h√¨nh h·ªçc c√°ch d·ª± ƒëo√°n ƒë·∫ßu ra t·ª´ ƒë·∫ßu v√†o th√¥ng qua c√°c v√≠ d·ª• trong t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán.</p>

<p>C√°c ƒëi·ªÉm d·ªØ li·ªáu ƒë√¥i khi ƒë∆∞·ª£c ƒëo ƒë·∫°c v·ªõi nh·ªØng ƒë∆°n v·ªã kh√°c nhau, m v√† feet ch·∫≥ng h·∫°n. Ho·∫∑c c√≥ hai th√†nh ph·∫ßn (c·ªßa vector d·ªØ li·ªáu) ch√™nh l·ªách nhau qu√° l·ªõn, m·ªôt th√†nh ph·∫ßn c√≥ kho·∫£ng gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1000, th√†nh ph·∫ßn kia ch·ªâ c√≥ kho·∫£ng gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1 ch·∫≥ng h·∫°n. L√∫c n√†y, ch√∫ng ta c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc khi th·ª±c hi·ªán c√°c b∆∞·ªõc ti·∫øp theo. (theo https://machinelearningcoban.com/general/2017/02/06/featureengineering)</p>

<p>C√°c tr·ªçng s·ªë c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c kh·ªüi t·∫°o t·ª´ c√°c gi√° tr·ªã ng·∫´u nhi√™n nh·ªè v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·∫±ng thu·∫≠t to√°n t·ªëi ∆∞u trong qu√° tr√¨nh backward, vi·ªác c·∫≠p nh·∫≠t d·ª±a tr√™n l·ªói d·ª± ƒëo√°n (loss) trong qu√° tr√¨nh hu·∫•n luy·ªán.</p>

<p>V√¨ c√°c tr·ªçng s·ªë nh·ªè c·ªßa m√¥ h√¨nh nh·ªè v√† ƒë∆∞·ª£c c·∫≠p nh·∫≠t d·ª±a v√†o l·ªói d·ª± ƒëo√°n n√™n vi·ªác scale gi√° tr·ªã c·ªßa ƒë·∫ßu v√†o X v√† ƒë·∫ßu ra Y c·ªßa t·∫≠p d·ªØ li·ªáu hu·∫•n  luy·ªán l√† m·ªôt y·∫øu t·ªë quan tr·ªçng.
N·∫øu ƒë·∫ßu v√†o kh√¥ng ƒë∆∞·ª£c scaling c√≥ th·ªÉ d·∫´n ƒë·∫øn qu√° tr√¨nh hu·∫•n luy·ªán kh√¥ng ·ªïn ƒë·ªãnh. Ngo√†i ra n·∫øu ƒë·∫ßu ra Y kh√¥ng ƒë∆∞·ª£c scale trong c√°c b√†i to√°n regression c√≥ th·ªÉ d·∫´n ƒë·∫øn exploding gradient khi·∫øn thu·∫≠t to√°n kh√¥ng ch·∫°y ƒë∆∞·ª£c.</p>

<p>Scaling c√≥ th·ªÉ t·∫°o ra s·ª± kh√°c bi·ªát gi·ªØa m·ªôt m√¥ h√¨nh k√©m v√† m·ªôt m√¥ h√¨nh t·ªët.</p>

<p>B∆∞·ªõc ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu li√™n quan ƒë·∫øn k·ªπ thu·∫≠t normalization v√† standardization ƒë·ªÉ rescale l·∫°i input v√† output tr∆∞·ªõc khi hu·∫•n luy·ªán m√¥ h√¨nh.</p>

<p>Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu c√°c ƒë·ªÉ c·∫£i thi·ªán m·ªôt m√¥ h√¨nh sao cho hi·ªáu qu·∫£ v√† ·ªïn ƒë·ªãnh b·∫±ng vi·ªác scale d·ªØ li·ªáu.</p>

<p>M·ª•c ti√™u b√†i vi·∫øt</p>

<ul>
  <li>Data scaling l√† m·ªôt b∆∞·ªõc c·∫ßn ƒë∆∞·ª£c th·ª±c hi·ªán trong qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω khi c√†i ƒë·∫∑t v·ªõi m√¥ h√¨nh m·∫°ng n∆° ron</li>
  <li>Th·ª±c hi·ªán ƒë∆∞·ª£c scale data b·∫±ng k·ªπ thu·∫≠t normalization ho·∫∑c standardization.</li>
  <li>√Åp d·ª•ng standardization v√† normalization ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh Multilayer Perceptron v·ªõi b√†i to√°n regression sau ƒë√≥ ƒë∆∞a ra ƒë√°nh gi√°.</li>
</ul>

<h1 id="scale-c√°c-bi·∫øn-ƒë·∫ßu-v√†o">Scale c√°c bi·∫øn ƒë·∫ßu v√†o</h1>

<p>C√°c bi·∫øn ƒë·∫ßu v√†o l√† c√°c bi·∫øn ƒë∆∞a v√†o m·∫°ng neuron ƒë·ªÉ d·ª± ƒëo√°n.</p>

<p>M·ªôt nguy√™n t·∫Øc chung l√† c√°c bi·∫øn ƒë·∫ßu v√†o ph·∫£i c√≥ gi√° tr·ªã nh·ªè, c√≥ th·ªÉ n·∫±m trong kho·∫£ng 0-1 ho·∫∑c ƒë∆∞·ª£c chu·∫©n h√≥a v·ªõi gi√° tr·ªã trung b√¨nh b·∫±ng 0 v√† ƒë·ªô l·ªách chu·∫©n (standard deviation) b·∫±ng 1. C√°c bi·∫øn ƒë·∫ßu v√†o c√≥ c·∫ßn ph·∫£i scaling hay kh√¥ng ph·ª• thu·ªôc v√†o t·ª´ng b√†i to√°n c·ª• th·ªÉ v√† t·ª´ng bi·∫øn c·ª• th·ªÉ.</p>

<p>N·∫øu ph√¢n b·ªë c√°c gi√° tr·ªã c·ªßa bi·∫øn l√† ph√¢n b·ªë chu·∫©n th√¨ bi·∫øn n√™n ƒë∆∞·ª£c standardization, n·∫øu kh√¥ng d·ªØ li·ªáu n√™n ƒë∆∞·ª£c normalization. ƒêi·ªÅu n√†y √°p d·ª•ng khi ph·∫°m vi gi√° tr·ªã l·ªõn (10, 100‚Ä¶) ho·∫∑c nh·ªè (0.01, 0.0001).</p>

<p>N·∫øu gi√° tr·ªã c·ªßa bi·∫øn nh·ªè (g·∫ßn trong kho·∫£ng 0-1) v√† ph√¢n ph·ªëi b·ªã gi·ªõi h·∫°n (v√≠ d·ª• ƒë·ªô l·ªách chu·∫©n g·∫ßn v·ªõi 1) th√¨ ch√∫ng ta kh√¥ng c·∫ßn ph·∫£i scale d·ªØ li·ªáu.</p>

<p>C√°c b√†i to√°n c√≥ th·ªÉ ph·ª©c t·∫°p ho·∫∑c kh√¥ng r√µ r√†ng n√™n ta kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c vi·ªác s·ª≠ d·ª•ng k·ªπ thu·∫≠t n√†o ƒë·ªÉ scale d·ªØ li·ªáu l√† t·ªët nh·∫•t. V√¨ th·∫ø n√™n th∆∞·ªùng th√¨ m√¨nh hay th·ª≠ nghi·ªám scale d·ªØ li·ªáu v√† kh√¥ng scale c√≥ kh√°c bi·ªát nhau th·∫ø n√†o b·∫±ng vi·ªác cho m√¥ h√¨nh ch·∫°y r·ªìi ti·∫øn h√†nh ƒë√°nh gi√°.</p>

<h1 id="scale-bi·∫øn-ƒë·∫ßu-ra">Scale bi·∫øn ƒë·∫ßu ra</h1>

<p>Bi·∫øn ƒë·∫ßu ra Y l√† bi·∫øn ƒë∆∞·ª£c d·ª± ƒëo√°n b·ªüi m√¥ h√¨nh.</p>

<p>Ch√∫ng ta c·∫ßn ƒë·∫£m b·∫£o l√† gi√° tr·ªã c·ªßa Y ph·∫£i kh·ªõp v·ªõi ph·∫°m vi bi·ªÉu di·ªÖn c·ªßa h√†m k√≠ch ho·∫°t (activation function) trong l·ªõp output c·ªßa m√¥ h√¨nh m·∫°ng n∆°-ron.</p>

<p>N·∫øu ƒë·∫ßu ra c·ªßa activation function thu·ªôc v√†o mi·ªÅn [0, 1] th√¨ gi√° tr·ªã bi·∫øn ƒë·∫ßu ra Y c≈©ng ph·∫£i n·∫±m trong mi·ªÅn gi√° tr·ªã n√†y. Tuy nhi√™n ch√∫ng ta n√™n ch·ªçn h√†m k√≠ch ho·∫°t ph√π h·ª£p v·ªõi ph√¢n b·ªë c·ªßa ƒë·∫ßu ra Y h∆°n l√† ƒë∆∞a Y v·ªÅ mi·ªÅn gi√° tr·ªã c·ªßa h√†m k√≠ch ho·∫°t.</p>

<p>V√≠ d·ª• n·∫øu b√†i to√°n c·ªßa b·∫°n l√† regression th√¨ ƒë·∫ßu ra s·∫Ω l√† m·ªôt gi√° tr·ªã s·ªë th·ª±c. M√¥ h√¨nh t·ªët nh·∫•t cho b√†i to√°n n√†y ƒë√≥ l√† l·ª±a ch·ªçn h√†m k√≠ch ho·∫°t tuy·∫øn t√≠nh (linear activation). N·∫øu ƒë·∫ßu ra c√≥ ph√¢n b·ªë chu·∫©n th√¨ ch√∫ng ta c√≥ th·ªÉ standardize bi·∫øn ƒë·∫ßu ra. N·∫øu kh√¥ng th√¨ ƒë·∫ßu ra Y c√≥ th·ªÉ ƒë∆∞·ª£c normalize.</p>

<h1 id="c√°c-ph∆∞∆°ng-ph√°p-data-scaling">C√°c ph∆∞∆°ng ph√°p data scaling</h1>

<p>C√≥ 2 c√°ch ƒë·ªÉ scale d·ªØ li·ªáu ƒë√≥ l√† normalization v√† standardization t·∫°m d·ªãch l√† B√¨nh th∆∞·ªùng h√≥a d·ªØ li·ªáu v√† Chu·∫©n h√≥a d·ªØ li·ªáu</p>

<p>C·∫£ 2 c√°ch n√†y ƒë·ªÅu ƒë∆∞·ª£c cung c·∫•p trong th∆∞ vi·ªán scikit-learn</p>

<h2 id="data-normalization">Data Normalization</h2>

<p>Normalization l√† ph∆∞∆°ng ph√°p scale d·ªØ li·ªáu t·ª´ mi·ªÅn gi√° tr·ªã b·∫•t k√¨ sang mi·ªÅn gi√° tr·ªã n·∫±m trong kho·∫£ng 0 ƒë·∫øn 1.</p>

<p>Ph∆∞∆°ng ph√°p n√†y y√™u c·∫ßu ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh ƒë∆∞·ª£c gi√° tr·ªã l·ªõn nh·∫•t (max) v√† gi√° tr·ªã nh·ªè nh·∫•t (min) c·ªßa d·ªØ li·ªáu.</p>

<p>Gi√° tr·ªã ƒë∆∞·ª£c normalize theo c√¥ng th·ª©c sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre>y = (x - min) / (max - min)
</pre></td></tr></tbody></table></code></pre></div></div>
<p>y l√† bi·∫øn sau normalize, x l√† bi·∫øn tr∆∞·ªõc normalize.</p>

<p>ƒê·ªÉ normalize d·ªØ li·ªáu, ta c·∫ßn normalize t·ª´ng thu·ªôc t√≠nh (feature) c·ªßa d·ªØ li·ªáu. C√¥ng th·ª©c tr√™n √°p d·ª•ng ƒë·ªëi v·ªõi t·ª´ng feature.</p>

<p>Trong ƒë√≥ x l√† gi√° tr·ªã c·∫ßn ƒë∆∞·ª£c normalize, maximum v√† minium l√† gi√° tr·ªã l·ªõn nh·∫•t v√† nh·ªè nh·∫•t c·ªßa trong t·∫•t c·∫£ c√°c quan s√°t c·ªßa feature trong t·∫≠p d·ªØ li·ªáu.</p>

<p>V√≠ d·ª• v·ªõi m·ªôt t·∫≠p d·ªØ li·ªáu b·∫•t k·ª≥, ch√∫ng ta x√°c ƒë·ªãnh ƒë∆∞·ª£c gi√° tr·ªã l·ªõn nh·∫•t c·ªßa 1 feature l√† 30, gi√° tr·ªã nh·ªè nh·∫•t l√† -10. Nh∆∞ v·∫≠y, v·ªõi 1 gi√° tr·ªã b·∫•t k·ª≥ l√† 18.8, ta c√≥ th·ªÉ normalize nh∆∞ sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td> --><td class="rouge-code"><pre>y = (x - min) / (max - min)
y = (18.8 - (-10)) / (30 - (-10))
y = 28.8 / 40
y = 0.72
</pre></td></tr></tbody></table></code></pre></div></div>

<p>B·∫°n c√≥ th·ªÉ th·∫•y n·∫øu gi√° tr·ªã x n·∫±m ngo√†i gi·ªõi h·∫°n c·ªßa gi√° tr·ªã minimum v√† maximum, gi√° tr·ªã k·∫øt qu·∫£ s·∫Ω kh√¥ng n·∫±m trong ph·∫°m vi 0 v√† 1.
N·∫øu ƒë√£ x√°c ƒë·ªãnh gi√° tr·ªã max v√† min cho tr∆∞·ªõc, m·ªôt ƒëi·ªÉm d·ªØ li·ªáu n√†o ƒë√≥ n·∫±m ngo√†i kho·∫£ng max v√† min ƒë√≥ ta c√≥ th·ªÉ lo·∫°i b·ªè kh·ªèi t·∫≠p d·ªØ li·ªáu.</p>

<p>B·∫°n c√≥ th·ªÉ th·ª±c hi·ªán normalize d·ªØ li·ªáu s·ª≠ d·ª•ng th∆∞ vi·ªán scikit-learn v·ªõi MinMaxScaler.</p>

<p>C√°c b∆∞·ªõc nh∆∞ sau:</p>

<ul>
  <li>Fit bi·∫øn scaler s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán. ƒê·ªÉ normalize th√¨ d·ªØ li·ªáu hu·∫•n luy·ªán c·∫ßn ph·∫£i ƒë∆∞·ª£c x√°c ƒë·ªãnh gi√° tr·ªã max v√† min. ƒê·ªÉ th·ª±c hi·ªán ch√∫ng ta g·ªçi h√†m fit().</li>
  <li>Ti·∫øn h√†nh scale d·ªØ li·ªáu b·∫±ng c√°ch g·ªçi h√†m transform().</li>
  <li>√Åp d·ª•ng l·∫°i b·ªô scaler ƒë·ªÉ s·ª≠ d·ª•ng cho vi·ªác d·ª± ƒëo√°n v·ªÅ sau.</li>
</ul>

<p>B·ªô scaler MinMaxScaler s·∫Ω ƒë∆∞a c√°c bi·∫øn v·ªÅ mi·ªÅn gi√° tr·ªã [0, 1], s·ª≠ d·ª•ng tham s·ªë <code class="language-plaintext highlighter-rouge">feature_range</code> ƒë·ªÉ ƒë∆∞a v√†o gi√° tr·ªã min v√† max n·∫øu b·∫°n mu·ªën.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td> --><td class="rouge-code"><pre><span class="c1"># create scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>ƒê·ªÉ ƒë·∫£o ng∆∞·ª£c mi·ªÅn gi√° tr·ªã sau khi scale v·ªÅ mi·ªÅn gi√° tr·ªã g·ªëc gi√∫p thu·∫≠n ti·ªán cho vi·ªác b√°o c√°o hay v·∫Ω bi·ªÉu ƒë·ªì, b·∫°n c√≥ th·ªÉ g·ªçi h√†m <code class="language-plaintext highlighter-rouge">inverse_transform</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td> --><td class="rouge-code"><pre><span class="c1"># V√≠ d·ª• v·ªÅ scale s·ª≠ d·ª•ng MinMaxScaler
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1"># Load d·ªØ li·ªáu
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># t·∫°o b·ªô scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="c1"># fit scaler v√†o data
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># Th·ª±c hi·ªán scale
</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># quay l·∫°i mi·ªÅn gi√° tr·ªã c≈©
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">normalized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>B·∫°n c≈©ng c√≥ th·ªÉ th·ª±c hi·ªán trong m·ªôt b∆∞·ªõc duy nh·∫•t b·∫±ng c√°ch s·ª≠ d·ª•ng h√†m fit_transform (); v√≠ d·ª•:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td> --><td class="rouge-code"><pre><span class="c1"># V√≠ d·ª• v·ªÅ scale s·ª≠ d·ª•ng MinMaxScaler
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># t·∫°o b·ªô scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="c1"># fit v√† transform ƒë·ªìng th·ªùi
</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># quay l·∫°i mi·ªÅn gi√° tr·ªã c≈©
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">normalized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="data-standardization">Data Standardization</h2>

<p>Chu·∫©n h√≥a d·ªØ li·ªáu l√† vi·ªác scale d·ªØ li·ªáu v·ªÅ m·ªôt ph√¢n b·ªë trong ƒë√≥ gi√° tr·ªã trung b√¨nh c·ªßa c√°c quan s√°t b·∫±ng 0 v√† ƒë·ªô l·ªách chu·∫©n = 1. K·ªπ thu·∫≠t n√†y c√≤n ƒë∆∞·ª£c g·ªçi l√† ‚Äúwhitening.‚Äù.
Nh·ªù vi·ªác chu·∫©n h√≥a, c√°c thu·∫≠t to√°n nh∆∞ linear regression, logistic regression ƒë∆∞·ª£c c·∫£i thi·ªán.</p>

<p>C√¥ng th·ª©c chu·∫©n h√≥a nh∆∞ sau:</p>

<p>[x‚Äô = \frac{x - \bar{x}}{\sigma}]</p>

<p>v·ªõi $\bar{x}$ v√† $\sigma$ l·∫ßn l∆∞·ª£t l√† k·ª≥ v·ªçng v√† ph∆∞∆°ng sai (standard deviation) c·ªßa th√†nh ph·∫ßn ƒë√≥ tr√™n to√†n b·ªô training data.</p>

<p>(theo https://machinelearningcoban.com/general/2017/02/06/featureengineering/)</p>

<p>Gi·ªëng nh∆∞ normalization, standardization c√≥ th·ªÉ c√≥ hi·ªáu qu·∫£ v√† th·∫≠m ch√≠ b·∫Øt bu·ªôc n·∫øu gi√° tr·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o thu·ªôc v√†o c√°c mi·ªÅn gi√° tr·ªã kh√°c nhau.</p>

<p>Standardization gi·∫£ ƒë·ªãnh c√°c quan s√°t c√≥ ph√¢n ph·ªëi Gaussian (d·∫°ng h√¨nh chu√¥ng). N·∫øu ph√¢n ph·ªëi d·ªØ li·ªáu kh√¥ng c√≥ d·∫°ng ph√¢n ph·ªëi chu·∫©n th√¨ vi·ªác √°p d·ª•ng standardize c≈©ng kh√¥ng hi·ªáu qu·∫£.</p>

<p>ƒê·ªÉ th·ª±c hi·ªán standardize d·ªØ li·ªáu, ch√∫ng ta c·∫ßn t√≠nh ƒë∆∞·ª£c gi√° tr·ªã trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n d·ª±a tr√™n c√°c quan s√°t.</p>

<p>C√¥ng th·ª©c chu·∫©n h√≥a:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre>y = (x - mean) / standard_deviation
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Trong ƒë√≥ mean ƒë∆∞·ª£c t√≠nh nh∆∞ sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre>mean = sum(x) / count(x)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>ƒê·ªÉ t√≠nh ƒë·ªô l·ªách chu·∫©n (standard_deviation):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre><span class="n">standard_deviation</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span> <span class="nb">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="p">)</span> <span class="o">/</span> <span class="n">count</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Gi·∫£ s·ª≠ gi√° tr·ªã trung b√¨nh l√† 10, ƒë·ªô l·ªách chu·∫©n l√† 5, V·ªõi gi√° tr·ªã 20.7 s·∫Ω ƒë∆∞·ª£c chu·∫©n h√≥a nh∆∞ sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td> --><td class="rouge-code"><pre>y = (x - mean) / standard_deviation
y = (20.7 - 10) / 5
y = (10.7) / 5
y = 2.14
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ch√∫ng ta c√≥ th·ªÉ chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng th∆∞ vi·ªán scikit-learn v·ªõi StandardScaler:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td> --><td class="rouge-code"><pre><span class="c1"># demonstrate data standardization with sklearn
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># create scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit scaler on data
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># apply transform
</span><span class="n">standardized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># inverse transform
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">standardized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ho·∫∑c s·ª≠ d·ª•ng h√†m <code class="language-plaintext highlighter-rouge">fit_transform</code> nh∆∞ sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td> --><td class="rouge-code"><pre><span class="c1"># demonstrate data standardization with sklearn
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># create scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit and transform in one step
</span><span class="n">standardized</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># inverse transform
</span><span class="n">inverse</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">standardized</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="th·ª≠-nghi·ªám-v·ªõi-b√†i-to√°n-s·ª≠-d·ª•ng-m√¥-h√¨nh-h·ªìi-quy">Th·ª≠ nghi·ªám v·ªõi b√†i to√°n s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy</h1>

<p>M·ªôt b√†i to√°n s·ª≠ d·ª•ng m√¥ h√¨nh d·ª± b√°o h·ªìi quy th∆∞·ªùng li√™n quan ƒë·∫øn vi·ªác d·ª± ƒëo√°n m·ªôt ƒë·∫°i l∆∞·ª£ng c√≥ gi√° tr·ªã th·ª±c. V√≠ d·ª• b√†i to√°n d·ª± ƒëo√°n gi√° nh√†, d·ª± ƒëo√°n gi√° c·ªï phi·∫øu‚Ä¶</p>

<p>Trong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω kh·∫£o s√°t c√°c loss function ph√π h·ª£p cho c√°c b√†i to√°n regression.</p>

<p>ƒê·ªÉ t·∫°o d·ªØ li·ªáu demo cho b√†i to√°n regression, m√¨nh s·∫Ω s·ª≠ d·ª•ng h√†m make_regression() c√≥ s·∫µn trong th∆∞ vi·ªán c·ªßa scikit-learn. H√†m n√†y s·∫Ω t·∫°o d·ªØ li·ªáu m·∫´u v·ªõi c√°c bi·∫øn ƒë·∫ßu v√†o, nhi·ªÖu v√† c√°c thu·ªôc t√≠nh kh√°c‚Ä¶</p>

<p>Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng h√†m n√†y ƒë·ªÉ t·∫°o ra d·ªØ li·ªáu g·ªìm 20 features, 10 features c√≥ √Ω nghƒ©a v·ªÅ m·∫∑t d·ªØ li·ªáu v√† 10 features kh√¥ng c√≥ √Ω nghƒ©a. M√¨nh s·∫Ω t·∫°o 1,000 ƒëi·ªÉm d·ªØ li·ªáu ng·∫´u nhi√™n cho b√†i to√°n. Tham s·ªë random_state s·∫Ω ƒë·∫£m b·∫£o cho ch√∫ng ta c√°c d·ªØ li·ªáu l√† nh∆∞ nhau m·ªói l·∫ßn ch·∫°y.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td> --><td class="rouge-code"><pre><span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>C√°c bi·∫øn ƒë·∫ßu v√†o ƒë·ªÅu d∆∞·ªõi d·∫°ng ph√¢n ph·ªëi Gaussian. T∆∞∆°ng t·ª± v·ªõi bi·∫øn ƒë·∫ßu ra.</p>

<p>M√¨nh s·∫Ω v·∫Ω th·ª≠ bi·ªÉu ƒë·ªì c√°c bi·∫øn ƒë·∫ßu v√†o:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td> --><td class="rouge-code"><pre><span class="c1"># regression predictive modeling problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># histograms of input variables
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># histogram of target variable
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ch·∫°y th·ª≠ ƒëo·∫°n code tr√™n s·∫Ω cho ch√∫ng ta 2 k·∫øt qu·∫£ nh∆∞ sau:</p>

<ul>
  <li>ƒê·∫ßu ti√™n l√† ph√¢n b·ªë c·ªßa 2 bi·∫øn trong s·ªë 12 bi·∫øn:</li>
</ul>

<p><img src="/assets/img/blog/Histograms-of-Two-of-the-Twenty-Input-Variables-for-the-Regression-Problem.webp" alt="Ph√¢n b·ªë c·ªßa 2 bi·∫øn trong s·ªë 12 bi·∫øn" />
<em>Ph√¢n b·ªë c·ªßa 2 bi·∫øn trong s·ªë 12 bi·∫øn</em></p>

<ul>
  <li>Th·ª© 2 l√† ph√¢n b·ªë c·ªßa bi·∫øn m·ª•c ti√™u. M·∫∑c d√π mi·ªÅn gi√° tr·ªã r·ªông h∆°n nh∆∞ng ph√¢n b·ªë v·∫´n d∆∞·ªõi d·∫°ng ph√¢n b·ªë chu·∫©n.</li>
</ul>

<p><img src="/assets/img/blog/Histogram-of-the-Target-Variable-for-the-Regression-Problem.webp" alt="Ph√¢n b·ªë c·ªßa bi·∫øn m·ª•c ti√™u" />
<em>Ph√¢n b·ªë c·ªßa bi·∫øn m·ª•c ti√™u</em></p>

<p>Nh∆∞ v·∫≠y ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ ti·∫øn h√†nh c√°c th·ª≠ nghi·ªám v√† ƒë√°nh gi√°.</p>

<h2 id="mlp-v·ªõi-d·ªØ-li·ªáu-ch∆∞a-ƒë∆∞·ª£c-rescale">MLP v·ªõi d·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c rescale</h2>

<p>ƒê·ªÉ demo vi·ªác t√¨m hi·ªÉu v·ªÅ s·ª± ·∫£nh h∆∞·ªüng c·ªßa scaling, m√¨nh s·∫Ω s·ª≠ d·ª•ng m·ªôt model ƒë∆°n gi·∫£n ƒë√≥ l√† Multilayer Perceptron (MLP).</p>

<p>Model s·∫Ω g·ªìm ƒë·∫ßu v√†o l√† 20 features, m√¥ h√¨nh s·∫Ω c√≥ 1 l·ªõp ·∫©n v·ªõi 25 nodes, sau ƒë√≥ s·ª≠ d·ª•ng h√†m k√≠ch ho·∫°t ReLU.
ƒê·∫ßu ra s·∫Ω g·ªìm 1 node t∆∞∆°ng ·ª©ng v·ªõi gi√° tr·ªã ƒë·∫ßu ra mu·ªën d·ª± ƒëo√°n, cu·ªëi c√πng s·∫Ω l√† m·ªôt h√†m k√≠ch ho·∫°t tuy·∫øn t√≠nh .</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td> --><td class="rouge-code"><pre><span class="c1"># define model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>M√¨nh s·∫Ω fit m√¥ h√¨nh n√†y v·ªõi thu·∫≠t to√°n t·ªëi ∆∞u stochastic gradient descent v√† s·ª≠ d·ª•ng learning rate l√† 0.01, momentum  0.9</p>

<p>Vi·ªác hu·∫•n luy·ªán s·∫Ω th·ª±c hi·ªán qua 100 epochs v√† s·ª≠ d·ª•ng t·∫≠p testing ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh sau m·ªói epoch. Cu·ªëi c√πng ta c√≥ th·ªÉ v·∫Ω l·∫°i ƒë∆∞·ª£c learning curves sau khi th·ª±c hi·ªán xong.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td> --><td class="rouge-code"><pre><span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span><span class="c1"># fit model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>H√†m l·ªói MSE (mean squared error) ƒë∆∞·ª£c t√≠nh to√°n tr√™n t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra ƒë·ªÉ x√°c ƒë·ªãnh xem m√¥ h√¨nh h·ªçc th·∫ø n√†o.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td> --><td class="rouge-code"><pre><span class="c1"># ƒë√°nh gi√° m√¥ h√¨nh
</span><span class="n">train_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau ƒë√≥ m√¨nh s·∫Ω ti·∫øn h√†nh v·∫Ω l·∫°i bi·ªÉu ƒë·ªì th·ªÉ hi·ªán l·ªói MSE trong qu√° tr√¨nh hu·∫•n luy·ªán d·ª±a tr√™n t·∫≠p train v√† t·∫≠p test th√¥ng qua m·ªói epoch.
Vi·ªác ƒë√°nh gi√° k·∫øt qu·∫£ hu·∫•n luy·ªán d·ª±a tr√™n bi·ªÉu ƒë·ªì s·∫Ω gi√∫p ch√∫ng ta d·ªÖ d√†ng t√¨m hi·ªÅu h∆°n v·ªÅ c√°c th·ª≠ nghi·ªám.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td> --><td class="rouge-code"><pre><span class="c1"># plot loss during training
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Mean Squared Error'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Code ho√†n ch·ªânh nh∆∞ sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td> --><td class="rouge-code"><pre><span class="c1"># mlp with unscaled data for the regression problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># split into train and test
</span><span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
<span class="c1"># define model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
<span class="c1"># compile model
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
<span class="c1"># fit model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># evaluate the model
</span><span class="n">train_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Train: %.3f, Test: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_mse</span><span class="p">,</span> <span class="n">test_mse</span><span class="p">))</span>
<span class="c1"># plot loss during training
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Mean Squared Error'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau khi ch·∫°y code, ch√∫ng ta s·∫Ω c√≥ gi√° tr·ªã MSE tr√™n t·∫≠p train v√† t·∫≠p test.</p>

<p>Trong tr∆∞·ªùng h·ª£p n√†y, m√¥ h√¨nh kh√¥ng h·ªçc ƒë∆∞·ª£c g√¨ c·∫£, d·∫´n ƒë·∫øn gi√° tr·ªã d·ª± ƒëo√°n l√† NaN.
C√°c tr·ªçng s·ªë c·ªßa m√¥ h√¨nh b·ªã explode trong qu√° tr√¨nh hu·∫•n luy·ªán do gi√° tr·ªã m·∫•t m√°t l·ªõn ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác c·∫≠p nh·∫≠t tr·ªçng b·∫±ng Gradient descent.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre>Train: nan, Test: nan
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Nh∆∞ v·∫≠y vi·ªác scale d·ªØ li·ªáu l√† ho√†n to√†n c·∫ßn thi·∫øt khi x√¢y d·ª±ng m√¥ h√¨nh.</p>

<p>Do gi√° tr·ªã l·ªói l√† NaN n√™n trong tr∆∞·ªùng h·ª£p n√†y ta kh√¥ng th·ªÉ v·∫Ω ƒë∆∞·ª£c ƒë·ªì th·ªã h√†m l·ªói.</p>

<h2 id="mlp-v·ªõi-vi·ªác-scale-bi·∫øn-m·ª•c-ti√™u">MLP v·ªõi vi·ªác scale bi·∫øn m·ª•c ti√™u</h2>

<p>Ch√∫ng ta s·∫Ω ti·∫øn h√†nh c·∫≠p nh·∫≠t l·∫°i m√¥ h√¨nh b·∫±ng c√°ch scale l·∫°i bi·∫øn ƒë·∫ßu ra y c·ªßa t·∫≠p d·ªØ li·ªáu.</p>

<p>Khi ƒë∆∞a bi·∫øn m·ª•c ti√™u v·ªÅ c√πng mi·ªÅn gi√° tr·ªã s·∫Ω l√†m gi·∫£m k√≠ch th∆∞·ªõc gradient ƒë·ªÉ c·∫≠p nh·∫≠t l·∫°i tr·ªçng s·ªë. ƒêi·ªÅu n√†y s·∫Ω l√†m m√¥ h√¨nh v√† qu√° tr√¨nh hu·∫•n luy·ªán ·ªïn ƒë·ªãnh h∆°n.</p>

<p>V·ªõi bi·∫øn m·ª•c ti√™u c√≥ ph√¢n ph·ªëi Gausian, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p thay ƒë·ªïi t·ªâ l·ªá gi√° tr·ªã c·ªßa bi·∫øn b·∫±ng k·ªπ thu·∫≠t standardize.
Ch√∫ng ta c·∫ßn t√≠nh gi√° tr·ªã trung b√¨nh (mean) v√† ƒë·ªô l·ªách chu·∫©n (std) c·ªßa bi·∫øn ƒë·ªÉ √°p d·ª•ng ph∆∞∆°ng ph√°p n√†y.</p>

<p>Th∆∞ vi·ªán scikit-learn c·∫ßn ƒë·∫ßu v√†o d·ªØ li·ªáu l√† 1 ma tr·∫≠n 2 chi·ªÅu g·ªìm c√°c d√≤ng v√† c√°c c·ªôt. V√¨ v·∫≠y bi·∫øn m·ª•c ti√™u Y t·ª´ ma tr·∫≠n 1D ph·∫£i ƒë∆∞·ª£c reshape v·ªÅ 2D.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td> --><td class="rouge-code"><pre><span class="c1"># reshape 1d arrays to 2d arrays
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau ƒë√≥ √°p d·ª•ng StandardScaler v√†o ƒë·ªÉ scale l·∫°i bi·∫øn:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td> --><td class="rouge-code"><pre><span class="c1"># created scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit scaler on training dataset
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform training dataset
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform test dataset
</span><span class="n">testy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau ƒë√≥ t∆∞∆°ng t·ª± nh∆∞ ph·∫ßn tr√™n, ch√∫ng ta s·∫Ω ti·∫øn h√†nh ph√¢n t√≠ch l·ªói MSE th√¥ng qua ƒë·ªì th·ªã bi·ªÉu di·ªÖn l·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán</p>

<p>Code th·ª±c hi·ªán nh∆∞ sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre></td> --><td class="rouge-code"><pre><span class="c1"># mlp with scaled outputs on the regression problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="c1"># generate regression dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># split into train and test
</span><span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
<span class="c1"># reshape 1d arrays to 2d arrays
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># created scaler
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="c1"># fit scaler on training dataset
</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform training dataset
</span><span class="n">trainy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
<span class="c1"># transform test dataset
</span><span class="n">testy</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
<span class="c1"># define model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
<span class="c1"># compile model
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
<span class="c1"># fit model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># evaluate the model
</span><span class="n">train_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Train: %.3f, Test: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_mse</span><span class="p">,</span> <span class="n">test_mse</span><span class="p">))</span>
<span class="c1"># plot loss during training
</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Loss / Mean Squared Error'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau khi ch·∫°y, k·∫øt qu·∫£ s·∫Ω in ra gi√° tr·ªã MSE tr√™n t·∫≠p train v√† t·∫≠p test</p>

<blockquote>
  <p>Ch√∫ √Ω khi ch·∫°y, k·∫øt qu·∫£ c√≥ th·ªÉ kh√°c nhau do thu·∫≠t to√°n kh·ªüi t·∫°o ng·∫´u nhi√™n. Ch√∫ng ta n√™n ch·∫°y nhi·ªÅu l·∫ßn v√† l·∫•y gi√° tr·ªã trung b√¨nh</p>
</blockquote>

<p>K·∫øt qu·∫£ in ra s·∫Ω l√†:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre>Train: 0.003, Test: 0.007
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng th·ªÉ hi·ªán gi√° tr·ªã MSE trong qu√° tr√¨nh hu·∫•n luy·ªán c·ªßa t·∫≠p train (m√†u xanh) v√† t·∫≠p test (m√†u cam)</p>

<p>Trong tr∆∞·ªùng h·ª£p n√†y ch√∫ng ta c√≥ th·ªÉ th·∫•y m√¥ h√¨nh nhanh ch√≥ng h·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu.
K·∫øt qu·∫£ ƒë·ªô l·ªói tr√™n t·∫≠p test v√† t·∫≠p train kh√° t·ªët v√† g·∫ßn nhau ch·ª©ng t·ªè m√¥ h√¨nh kh√¥ng b·ªã underfit hay overfit.</p>

<p><img src="/assets/img/blog/Line-Plot-of-Mean-Squared-Error-on-the-Train-a-Test-Datasets-For-Each-Training-Epoch.webp" alt="Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng Mean Squared Error d·ª±a tr√™n t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra" />
<em>Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng Mean Squared Error d·ª±a tr√™n t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra</em></p>

<h2 id="perceptron-nhi·ªÅu-l·ªõp-v·ªõi-vi·ªác-scale-bi·∫øn-ƒë·∫ßu-v√†o">Perceptron nhi·ªÅu l·ªõp v·ªõi vi·ªác scale bi·∫øn ƒë·∫ßu v√†o</h2>

<p>Ch√∫ng ta nh·∫≠n th·∫•y vi·ªác scale d·ªØ li·ªáu l√†m ·ªïn ƒë·ªãnh qu√° tr√¨nh hu·∫•n luy·ªán v√† kh·ªõp v·ªõi m√¥ h√¨nh sau khi scale bi·∫øn m·ª•c ti√™u sang mi·ªÅn gi√° tr·ªã 0-1.</p>

<p>Ngo√†i ra ch√∫ng ta c√≥ th·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng m√¥ h√¨nh b·∫±ng c√°ch scale l·∫°i c√°c bi·∫øn ƒë·∫ßu v√†o.</p>

<p>M√¨nh s·∫Ω so s√°nh hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh ƒë·ªëi v·ªõi vi·ªác kh√¥ng scale d·ªØ li·ªáu v√† scale d·ªØ li·ªáu b·∫±ng l·∫ßn l∆∞·ª£t 2 ph∆∞∆°ng ph√°p standardize and normalize c√°c bi·∫øn ƒë·∫ßu v√†o</p>

<p>H√†m get_dataset() d∆∞·ªõi ƒë√¢y s·∫Ω ti·∫øn h√†nh t·∫°o d·ªØ li·ªáu, scale v√† chia th√†nh 2 t·∫≠p d√†nh cho testing v√† training:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td> --><td class="rouge-code"><pre>
<span class="c1"># prepare dataset with input and output scalers, can be none
</span><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">):</span>
	<span class="c1"># generate dataset
</span>	<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
	<span class="c1"># split into train and test
</span>	<span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
	<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
	<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
	<span class="c1"># scale inputs
</span>	<span class="k">if</span> <span class="n">input_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># fit scaler
</span>		<span class="n">input_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">output_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># reshape 1d arrays to 2d arrays
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="c1"># fit scaler on training dataset
</span>		<span class="n">output_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ti·∫øp theo m√¨nh s·∫Ω ƒë·ªãnh nghƒ©a h√†m ƒë·ªÉ fit MLP model v√†o t·∫≠p d·ªØ li·ªáu t∆∞∆°ng ·ª©ng v√† tr·∫£ v·ªÅ gi√° tr·ªã MSE tr√™n t·∫≠p test.</p>

<p>H√†m evaluate_model() ƒë∆∞·ª£c vi·∫øt nh∆∞ sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td> --><td class="rouge-code"><pre><span class="c1"># fit and evaluate mse of model on test set
</span><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">):</span>
	<span class="c1"># define model
</span>	<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
	<span class="c1"># compile model
</span>	<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
	<span class="c1"># fit model
</span>	<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="c1"># evaluate the model
</span>	<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">test_mse</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Neural network ƒë∆∞·ª£c hu·∫•n luy·ªán d·ª±a tr√™n thu·∫≠t to√°n stochastic. V√¨ v·∫≠y  n√™n v·ªõi c√πng 1 d·ªØ li·ªáu, k·∫øt qu·∫£ th·ª±c hi·ªán c√≥ th·ªÉ kh√°c nhau. Nh∆∞ v·∫≠y ƒë·ªÉ ƒë√°nh gi√° ch√≠nh x√°c ch√∫ng ta c·∫ßn l·∫∑p l·∫°i nhi·ªÅu l·∫ßn sau ƒë√≥ l·∫•y gi√° tr·ªã trung b√¨nh.</p>

<p>H√†m repeated_evaluation() s·∫Ω th·ª±c hi·ªán 30 l·∫ßn sau ƒë√≥ tr·∫£ v·ªÅ danh s√°ch c√°c gi√° tr·ªã MSE c·ªßa m·ªói l·∫ßn ch·∫°y</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td> --><td class="rouge-code"><pre><span class="c1"># evaluate model multiple times with given input and output scalers
</span><span class="k">def</span> <span class="nf">repeated_evaluation</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
	<span class="c1"># get dataset
</span>	<span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">)</span>
	<span class="c1"># repeated evaluation of model
</span>	<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
	<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
		<span class="n">test_mse</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">)</span>
		<span class="k">print</span><span class="p">(</span><span class="s">'&gt;%.3f'</span> <span class="o">%</span> <span class="n">test_mse</span><span class="p">)</span>
		<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">results</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Cu·ªëi c√πng ch√∫ng ta c√≥ th·ªÉ th·ª±c nghi·ªám v√† ƒë√°nh gi√° v·ªõi c√πng 1 model d·ª±a tr√™n 3 c√°ch</p>

<ul>
  <li>Kh√¥ng th·ª±c hi·ªán scale ƒë·∫ßu v√†o, chu·∫©n h√≥a bi·∫øn ƒë·∫ßu ra.</li>
  <li>Normalize ƒë·∫ßu v√†o, chu·∫©n h√≥a bi·∫øn ƒë·∫ßu ra.</li>
  <li>Chu·∫©n h√≥a ƒë·∫ßu v√†o, chu·∫©n h√≥a bi·∫øn ƒë·∫ßu ra.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td> --><td class="rouge-code"><pre><span class="c1"># unscaled inputs
</span><span class="n">results_unscaled_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># normalized inputs
</span><span class="n">results_normalized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># standardized inputs
</span><span class="n">results_standardized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># summarize results
</span><span class="k">print</span><span class="p">(</span><span class="s">'Unscaled: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Normalized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Standardized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">)))</span>
<span class="c1"># plot results
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">results_unscaled_inputs</span><span class="p">,</span> <span class="n">results_normalized_inputs</span><span class="p">,</span> <span class="n">results_standardized_inputs</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'unscaled'</span><span class="p">,</span> <span class="s">'normalized'</span><span class="p">,</span> <span class="s">'standardized'</span><span class="p">]</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Code ho√†n ch·ªânh nh∆∞ sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
</pre></td> --><td class="rouge-code"><pre><span class="c1"># compare scaling methods for mlp inputs on regression problem
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">mean</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">std</span>

<span class="c1"># prepare dataset with input and output scalers, can be none
</span><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">):</span>
	<span class="c1"># generate dataset
</span>	<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
	<span class="c1"># split into train and test
</span>	<span class="n">n_train</span> <span class="o">=</span> <span class="mi">500</span>
	<span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:,</span> <span class="p">:]</span>
	<span class="n">trainy</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
	<span class="c1"># scale inputs
</span>	<span class="k">if</span> <span class="n">input_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># fit scaler
</span>		<span class="n">input_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainX</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testX</span> <span class="o">=</span> <span class="n">input_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">output_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
		<span class="c1"># reshape 1d arrays to 2d arrays
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">trainy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="n">testy</span> <span class="o">=</span> <span class="n">testy</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainy</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
		<span class="c1"># fit scaler on training dataset
</span>		<span class="n">output_scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform training dataset
</span>		<span class="n">trainy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">trainy</span><span class="p">)</span>
		<span class="c1"># transform test dataset
</span>		<span class="n">testy</span> <span class="o">=</span> <span class="n">output_scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span>

<span class="c1"># fit and evaluate mse of model on test set
</span><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">):</span>
	<span class="c1"># define model
</span>	<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_uniform'</span><span class="p">))</span>
	<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
	<span class="c1"># compile model
</span>	<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">))</span>
	<span class="c1"># fit model
</span>	<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="c1"># evaluate the model
</span>	<span class="n">test_mse</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">test_mse</span>

<span class="c1"># evaluate model multiple times with given input and output scalers
</span><span class="k">def</span> <span class="nf">repeated_evaluation</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
	<span class="c1"># get dataset
</span>	<span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">input_scaler</span><span class="p">,</span> <span class="n">output_scaler</span><span class="p">)</span>
	<span class="c1"># repeated evaluation of model
</span>	<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
	<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
		<span class="n">test_mse</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainy</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">)</span>
		<span class="k">print</span><span class="p">(</span><span class="s">'&gt;%.3f'</span> <span class="o">%</span> <span class="n">test_mse</span><span class="p">)</span>
		<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">results</span>

<span class="c1"># unscaled inputs
</span><span class="n">results_unscaled_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># normalized inputs
</span><span class="n">results_normalized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># standardized inputs
</span><span class="n">results_standardized_inputs</span> <span class="o">=</span> <span class="n">repeated_evaluation</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="c1"># summarize results
</span><span class="k">print</span><span class="p">(</span><span class="s">'Unscaled: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_unscaled_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Normalized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_normalized_inputs</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Standardized: %.3f (%.3f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">),</span> <span class="n">std</span><span class="p">(</span><span class="n">results_standardized_inputs</span><span class="p">)))</span>
<span class="c1"># plot results
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">results_unscaled_inputs</span><span class="p">,</span> <span class="n">results_normalized_inputs</span><span class="p">,</span> <span class="n">results_standardized_inputs</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'unscaled'</span><span class="p">,</span> <span class="s">'normalized'</span><span class="p">,</span> <span class="s">'standardized'</span><span class="p">]</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Sau khi ch·∫°y, code s·∫Ω in ra gi√° tr·ªã l·ªói MSE qua m·ªói l·∫ßn ch·∫°y.</p>

<p>Sau khi m·ªôt trong s·ªë ba b·ªô tham s·ªë ƒë∆∞·ª£c ƒë√°nh gi√° 30 l·∫ßn, c√°c l·ªói trung b√¨nh cho m·ªói c·∫•u h√¨nh ƒë∆∞·ª£c in ra.</p>

<blockquote>
  <p>Ch√∫ √Ω khi ch·∫°y, k·∫øt qu·∫£ c√≥ th·ªÉ kh√°c nhau do thu·∫≠t to√°n kh·ªüi t·∫°o ng·∫´u nhi√™n. Ch√∫ng ta n√™n ch·∫°y nhi·ªÅu l·∫ßn v√† l·∫•y gi√° tr·ªã trung b√¨nh</p>
</blockquote>

<p>Trong tr∆∞·ªùng h·ª£p n√†y ch√∫ng ta c√≥ th·ªÉ th·∫•y r·∫±ng vi·ªác scale bi·∫øn ƒë·∫ßu v√†o s·∫Ω l√†m m√¥ h√¨nh t·ªët h∆°n. H∆°n n·ªØa vi·ªác normalize c√°c bi·∫øn ƒë·∫ßu v√†o cho k·∫øt qu·∫£ t·ªët h∆°n standardize. ƒêi·ªÅu n√†y c√≥ th·ªÉ do vi·ªác l·ª±a ch·ªçn activation function l√† linear</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td> --><td class="rouge-code"><pre><span class="p">...</span>
<span class="o">&gt;</span><span class="mf">0.010</span>
<span class="o">&gt;</span><span class="mf">0.012</span>
<span class="o">&gt;</span><span class="mf">0.005</span>
<span class="o">&gt;</span><span class="mf">0.008</span>
<span class="o">&gt;</span><span class="mf">0.008</span>
<span class="n">Unscaled</span><span class="p">:</span> <span class="mf">0.007</span> <span class="p">(</span><span class="mf">0.004</span><span class="p">)</span>
<span class="n">Normalized</span><span class="p">:</span> <span class="mf">0.001</span> <span class="p">(</span><span class="mf">0.000</span><span class="p">)</span>
<span class="n">Standardized</span><span class="p">:</span> <span class="mf">0.008</span> <span class="p">(</span><span class="mf">0.004</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="further-reading">Further Reading</h1>

<h3 id="posts">Posts</h3>

<ul>
  <li><a href="https://machinelearningmastery.com/how-to-scale-data-for-long-short-term-memory-networks-in-python/">How to Scale Data for Long Short-Term Memory Networks in Python</a></li>
  <li><a href="https://machinelearningmastery.com/scale-machine-learning-data-scratch-python/">How to Scale Machine Learning Data From Scratch With Python</a></li>
  <li><a href="https://machinelearningmastery.com/normalize-standardize-time-series-data-python/">How to Normalize and Standardize Time Series Data in Python</a></li>
  <li><a href="https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/">How to Prepare Your Data for Machine Learning in Python with Scikit-Learn</a></li>
</ul>

<h3 id="books">Books</h3>

<ul>
  <li>Section 8.2 Input normalization and encoding,¬†<a href="https://amzn.to/2S8qdwt">Neural Networks for Pattern Recognition</a>, 1995.</li>
</ul>

<h3 id="api">API</h3>

<ul>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html">sklearn.datasets.make_regression API</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">sklearn.preprocessing.MinMaxScaler API</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">sklearn.preprocessing.StandardScaler API</a></li>
</ul>

<h3 id="articles">Articles</h3>

<ul>
  <li><a href="ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std">Should I normalize/standardize/rescale the data? Neural Nets FAQ</a></li>
</ul>

:ET