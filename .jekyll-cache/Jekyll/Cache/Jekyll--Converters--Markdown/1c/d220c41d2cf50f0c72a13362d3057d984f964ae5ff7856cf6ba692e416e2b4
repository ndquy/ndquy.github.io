I"¹ä<p>TÄƒng cÆ°á»ng dá»¯ liá»‡u (Data Augmentation) lÃ  má»™t khÃ¡i niá»‡m khÃ¡ phá»• biáº¿n trong deep learning mÃ  cháº¯c háº³n ai Ä‘ang nghiÃªn cá»©u cÅ©ng Ä‘Ã£ tá»«ng nghe hoáº·c sá»­ dá»¥ng Ä‘áº¿n.
NÃ³i Ä‘Æ¡n giáº£n hÆ¡n, Data Augmentation lÃ  ká»¹ thuáº­t táº¡o ra thÃªm dá»¯ liá»‡u Ä‘á»ƒ bá»• sung cho táº­p dá»¯ liá»‡u Ä‘á»ƒ giÃºp mÃ´ hÃ¬nh khÃ¡i quÃ¡t tá»‘t hÆ¡n.
CÃ¡c ká»¹ thuáº­t data augmentation Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u trong thá»‹ giÃ¡c mÃ¡y tÃ­nh, thuáº­t toÃ¡n supervised learningâ€¦ Tuy nhiÃªn trong NLP thÃ¬ cÃ¡ nhÃ¢n mÃ¬nh tháº¥y Ã­t Ä‘Æ°á»£c sá»­ dá»¥ng vÃ  vá»›i Tiáº¿ng Viá»‡t thÃ¬ chÆ°a tháº¥y bÃ i viáº¿t nÃ o Ä‘á» cáº­p Ä‘áº¿n.</p>

<h1 id="giá»›i-thiá»‡u">Giá»›i thiá»‡u</h1>

<p>â€œDeep learning is a data-hungry frameworkâ€. Táº¡m dá»‹ch cÃ¢u nÃ y lÃ  Há»c sÃ¢u lÃ  1 framework luÃ´n â€œÄ‘Ã³i dá»¯ liá»‡uâ€. CÃ¢u nÃ y cÃ³ Ã½ nghÄ©a lÃ  dá»¯ liá»‡u lÃ  má»™t pháº§n quan trá»ng trong há»c sÃ¢u nÃ³i riÃªng vÃ  trong há»c mÃ¡y nÃ³i chung.
VÃ  bá»Ÿi vÃ¬ deep learning lÃ  thuáº­t toÃ¡n dá»±a trÃªn data (data-driven approach), vÃ  cÃ ng nhiá»u data thÃ¬ cÃ ng dá»… dáº«n Ä‘áº¿n cháº¥t lÆ°á»£ng cÃ¡c á»©ng dá»¥ng há»c mÃ¡y Ä‘Æ°á»£c cáº£i thiá»‡n.</p>

<p>Váº­y náº¿u giá» chÃºng ta pháº£i xá»­ lÃ½ bÃ i toÃ¡n cÃ³ giá»¯ liá»‡u giá»›i háº¡n thÃ¬ pháº£i lÃ m sao? KhÃ´ng Ä‘á»§ dá»¯ liá»‡u sáº½ dáº«n tá»›i váº¥n Ä‘á» nhÆ°</p>

<ul>
  <li>Thiáº¿u tÃ­nh generalization: Over-fitting hay nhÆ° má»™t kiá»ƒu há»c váº¹t, Train thÃ¬ cháº¥t lÆ°á»£ng rÃµ cao cÃ²n test thÃ¬ láº¹t Ä‘áº¹t.</li>
  <li>KhÃ³ huáº¥n luyá»‡n: Máº¡ng DL nháº¡y cáº£m vá»›i giÃ¡ trá»‹ khá»Ÿi táº¡o, khÃ³ há»™i tá»¥</li>
  <li>
    <p>Cháº¥t lÆ°á»£ng dá»± Ä‘oÃ¡n sáº½ khÃ´ng á»•n Ä‘á»‹nh:</p>

    <ul>
      <li>Outlier - má»™t sá»‘ trÆ°á»ng há»£p káº¿t quáº£ sai khÃ¡c ráº¥t nhiá»u,</li>
      <li>Nhiá»…u vá»›i Ä‘áº§u vÃ o áº£nh hÆ°á»Ÿng lá»›n tá»›i cháº¥t lÆ°á»£ng dá»± Ä‘oÃ¡n</li>
    </ul>
  </li>
</ul>

<p>â€¦ vÃ¢n vÃ¢n vÃ  mÃ¢y mÃ¢y. [1]</p>

<h1 id="bÃ i-toÃ¡n">BÃ i toÃ¡n</h1>

<p>Trong thá»‹ giÃ¡c mÃ¡y tÃ­nh báº¡n cÃ³ thá»ƒ dá»… dÃ ng tÃ¬m Ä‘Æ°á»£c cÃ¡c ká»¹ thuáº­t tÄƒng cÆ°á»ng dá»¯ liá»‡u, tuy nhiÃªn trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn thÃ¬ ká»¹ thuáº­t nÃ y cÃ²n gáº·p nhiá»u khÃ³ khÄƒn do domain cá»§a cÃ¡c bÃ i toÃ¡n NLP lÃ  khÃ¡c nhau.</p>

<p>Trong blog nÃ y mÃ¬nh sáº½ bÃ n luáº­n chá»§ yáº¿u vá» ká»¹ thuáº­t data augmentation trong NLP vÃ  cá»¥ thá»ƒ lÃ  bÃ i toÃ¡n phÃ¢n lá»›p vÄƒn báº£n (text classification).</p>

<h2 id="giá»›i-thiá»‡u-vá»-bÃ i-toÃ¡n">Giá»›i thiá»‡u vá» bÃ i toÃ¡n</h2>

<p>BÃ i toÃ¡n mÃ¬nh Ä‘Æ°a ra Ä‘Æ°á»£c Ã¡p dá»¥ng trong há»‡ thá»‘ng há»i Ä‘Ã¡p sá»­ dá»¥ng vá»›i chatbot. ÄÃ³ lÃ  module xÃ¡c Ä‘á»‹nh Ã½ Ä‘á»‹nh cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i cho chatbot.
Vá» cÆ¡ báº£n viá»‡c xÃ¡c Ä‘á»‹nh Ã½ Ä‘á»‹nh cá»§a cÃ¢u há»i sáº½ Ä‘Æ°á»£c chÃºng ta Ä‘Æ°a vá» bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n, vá»›i cÃ¡c Ã½ Ä‘á»‹nh lÃ  cÃ¡c class (lá»›p) tÆ°Æ¡ng á»©ng.</p>

<p>Cá»¥ thá»ƒ hÆ¡n, mÃ¬nh Ä‘ang thá»±c hiá»‡n xÃ¢y dá»±ng há»‡ thá»‘ng há»i Ä‘Ã¡p dÃ nh cho sinh viÃªn trÆ°á»ng Äáº¡i há»c XÃ¢y dá»±ng. Ã tÆ°á»Ÿng lÃ  sinh viÃªn sáº½ Ä‘áº·t cÃ¢u há»i cho há»‡ thá»‘ng, sau Ä‘Ã³ há»‡ thá»‘ng sáº½ tÃ¬m ra nhá»¯ng cÃ¢u tráº£ lá»i phÃ¹ há»£p báº±ng cÃ¡ch tÃ¬m kiáº¿m cÃ¢u há»i trong táº­p dá»¯ liá»‡u cÃ¢u há»i - cÃ¢u tráº£ lá»i Ä‘á»ƒ xem cÃ¢u há»i Ä‘Ã³ gáº§n vá»›i cÃ¢u há»i nÃ o nháº¥t Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i tÆ°Æ¡ng á»©ng.
VÃ  Ä‘á»ƒ Ä‘Æ°a ra Ä‘Æ°á»£c cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c thÃ¬ chÃºng ta cáº§n pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c Ã½ Ä‘á»‹nh cá»§a cÃ¢u há»i mÃ  ngÆ°á»i dÃ¹ng muá»‘n há»i lÃ  gÃ¬. VÃ  pháº§n nÃ y sáº½ táº­p trung chÃ­nh vÃ o ká»¹ thuáº­t sinh cÃ¢u há»i tÆ°Æ¡ng á»©ng vá»›i Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ bá»• sung thÃªm dá»¯ liá»‡u vÃ o táº­p dá»¯ liá»‡u huáº¥n luyá»‡n.</p>

<p>Táº¥t cáº£ cÃ¡c cÃ¢u há»i cá»§a sinh viÃªn trong trÆ°á»ng Ä‘Æ°á»£c chia ra thÃ nh cÃ¡c class nhÆ° sau, má»—i class tÆ°Æ¡ng á»©ng vá»›i Ã½ Ä‘á»‹nh há»i cá»§a ngÆ°á»i dÃ¹ng. NhÆ° váº­y viá»‡c xÃ¡c Ä‘á»‹nh Ã½ Ä‘á»‹nh chÃ­nh lÃ  viá»‡c phÃ¢n lá»›p 1 cÃ¢u há»i thuá»™c vÃ o class nÃ o:</p>

<p><img src="/assets/img/blog/Screen Shot 2021-04-15 at 23.05.49.png" alt="Sá»‘ lÆ°á»£ng cÃ¡c cÃ¢u há»i trong cÃ¡c class" />
<em>Sá»‘ lÆ°á»£ng cÃ¡c cÃ¢u há»i trong cÃ¡c class</em></p>

<p>NhÆ° hÃ¬nh trÃªn cÃ¡c báº¡n cÃ³ thá»ƒ tháº¥y sá»‘ lÆ°á»£ng cÃ¡c cÃ¢u há»i trong cÃ¡c class lÃ  khÃ´ng Ä‘á»u nhau, cÃ¡c cÃ¢u há»i thuá»™c class <code class="language-plaintext highlighter-rouge">TOEIC</code> chá»‰ khoáº£ng 50 cÃ¢u há»i, trong khi cÃ¡c cÃ¢u há»i trong class <code class="language-plaintext highlighter-rouge">DKMH</code> láº¡i lÃ  gáº§n 480 cÃ¢u há»i. Viá»‡c máº¥t cÃ¢n báº±ng dá»¯ liá»‡u nÃ y sáº½ áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n cháº¥t lÆ°á»£ng cá»§a mÃ´ hÃ¬nh. CÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ xá»­ lÃ½ máº¥t cÃ¢n báº±ng dá»¯ liá»‡u, tuy nhiÃªn cÃ¡c phÆ°Æ¡ng phÃ¡p chá»§ yáº¿u táº­p trung vÃ o viá»‡c phÃ¢n chia táº­p dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra chá»© khÃ´ng táº­p trung vÃ o viá»‡c bá»• sung thÃªm dá»¯ liá»‡u. Viá»‡c bá»• sung dá»¯ liá»‡u sáº½ giÃºp cáº£i thiá»‡n mÃ´ hÃ¬nh má»™t cÃ¡ch tá»‘t hÆ¡n.</p>

<h2 id="phÆ°Æ¡ng-phÃ¡p-thÃªm-dá»¯-liá»‡u">PhÆ°Æ¡ng phÃ¡p thÃªm dá»¯ liá»‡u</h2>

<p>Má»™t sá»‘ phÆ°Æ¡ng phÃ¡p thÃªm dá»¯ liá»‡u:</p>

<ol>
  <li>Collect more data. ÄÃºng nghÄ©a Ä‘en xÃ¬ lÃ  láº¥y thÃªm dá»¯ liá»‡u. Tráº£ tiá»n, láº¥y dá»¯ liá»‡u trÃªn máº¡ng, .v.v.</li>
  <li>Data synthesis: Táº¡o dá»¯ liá»‡u giáº£. Äá»‘i vá»›i má»™t sá»‘ bÃ i toÃ¡n dá»¯ liá»‡u cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ phá»ng qua computer graphic. NhÆ° áº£nh depth, áº£nh á»Ÿ chiá»u gÃ³c nhÃ¬n khÃ¡c nhau, .v.v.</li>
  <li>Data Augmentation. LÃ  ká»¹ thuáº­t Ä‘Æ¡n giáº£n nháº¥t báº±ng viá»‡c xá»­ lÃ½ Ä‘Æ¡n giáº£n dá»¯ liá»‡u sáºµn cÃ³ báº±ng cÃ¡c phÃ©p tuyáº¿n tÃ­nh hay phi tuyáº¿n (nhÆ° táº¡o dá»¯ liá»‡u qua máº¡ng GAN)</li>
</ol>

<p>PhÆ°Æ¡ng phÃ¡p <code class="language-plaintext highlighter-rouge">1</code> thÃ¬ quÃ¡ tá»‘t náº¿u thá»±c hiá»‡n Ä‘Æ°á»£c, tuy nhiÃªn vÃ¬ nhiá»u lÃ½ do vÃ  Ä‘iá»u kiá»‡n ta khÃ´ng thá»ƒ thu tháº­p thÃªm Ä‘Æ°á»£c dá»¯ liá»‡u vÃ¬ viá»‡c nÃ y tá»‘n thá»i gian, cÃ´ng sá»©c vÃ  cáº£ tiá»n ná»¯a.</p>

<p>PhÆ°Æ¡ng phÃ¡p sá»‘ <code class="language-plaintext highlighter-rouge">2</code> thÃ¬ khÃ³ cÃ³ thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c cho bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn NLP.</p>

<p>PhÆ°Æ¡ng phÃ¡p sá»‘ <code class="language-plaintext highlighter-rouge">3</code> sáº½ phÃ¹ há»£p hÆ¡n trong bÃ i toÃ¡n nÃ y vÃ  mÃ¬nh sáº½ Ä‘á» cáº­p trong pháº§n tiáº¿p theo.</p>

<h1 id="bert">BERT</h1>

<p>BERT Ä‘Æ°á»£c coi lÃ  bÆ°á»›c Ä‘á»™t phÃ¡ trong cÃ´ng nghá»‡ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cá»§a Google. NÄƒm 2018 Google giá»›i thiá»‡u BERT, BERT lÃ  viáº¿t táº¯t cá»§a Bidirectional Encoder Representations from Transformers Ä‘Æ°á»£c hiá»ƒu lÃ  má»™t mÃ´ hÃ¬nh há»c sáºµn hay cÃ²n gá»i lÃ  pre-train model, há»c ra cÃ¡c vector Ä‘áº¡i diá»‡n theo ngá»¯ cáº£nh 2 chiá»u cá»§a tá»«, Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ transfer sang cÃ¡c bÃ i toÃ¡n khÃ¡c trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. BERT Ä‘Ã£ thÃ nh cÃ´ng trong viá»‡c cáº£i thiá»‡n nhá»¯ng cÃ´ng viá»‡c gáº§n Ä‘Ã¢y trong viá»‡c tÃ¬m ra Ä‘áº¡i diá»‡n cá»§a tá»« trong khÃ´ng gian sá»‘ (khÃ´ng gian mÃ  mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c) thÃ´ng qua ngá»¯ cáº£nh cá»§a nÃ³. [2]</p>

<p>NhÆ° chÃºng ta Ä‘Ã£ biáº¿t, xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn luÃ´n gáº·p pháº£i váº¥n Ä‘á» vá» thiáº¿u há»¥t dá»¯ liá»‡u, háº§u háº¿t cÃ¡c táº­p dá»¯ liá»‡u chá»‰ Ä‘áº·c thÃ¹ cho tá»«ng domain cá»¥ thá»ƒ. Äá»ƒ giáº£i quyáº¿t thÃ¡ch thá»©c nÃ y, cÃ¡c mÃ´ hÃ¬nh xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn sá»­ dá»¥ng má»™t cÆ¡ cháº¿ tiá»n xá»­ lÃ½ dá»¯ liá»‡u huáº¥n luyá»‡n báº±ng viá»‡c transfer tá»« má»™t mÃ´ hÃ¬nh chung Ä‘Æ°á»£c Ä‘Ã o táº¡o tá»« má»™t lÆ°á»£ng lá»›n cÃ¡c dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c gÃ¡n nhÃ£n. [2]</p>

<p>#BERT trong Tiáº¿ng Viá»‡t - phoBERT</p>

<p>Khi google Ä‘Æ°a ra mÃ£ nguá»“n má»Ÿ cá»§a BERT, cÃ³ ráº¥t nhiá»u dá»± Ã¡n dá»±a trÃªn BERT Ä‘Æ°á»£c chia sáº». Äá»‘i vá»›i Tiáº¿ng Viá»‡t chÃºng ta cÃ³ <a href="https://github.com/VinAIResearch/PhoBERT">phoBert</a> do VinAI public.</p>

<p>PhoBert Ä‘Æ°á»£c huáº¥n luyá»‡n dá»±a trÃªn táº­p dá»¯ liá»‡u Tiáº¿ng Viá»‡t khÃ¡ lá»›n nÃªn khi sá»­ dá»¥ng phoBERT nhÃ¬n chung cáº£i thiá»‡n khÃ¡ tá»‘t cÃ¡c bÃ i toÃ¡n NLP vá»›i Tiáº¿ng Viá»‡t.
CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng</p>

<p>Äá»ƒ sá»­ dá»¥ng phoBERT, báº¡n cÃ i Ä‘áº·t cÃ¡c gÃ³i sau:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="o">!</span>pip3 <span class="nb">install </span>fairseq
<span class="o">!</span>pip3 <span class="nb">install </span>fastbpe
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="download-pretrained-bert-model">Download pretrained bert model</h2>

<p>Äáº§u tiÃªn chÃºng ta cáº§n download toÃ n bá»™ pretrain cá»§a model báº±ng lá»‡nh sau:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="o">!</span>wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz
<span class="o">!</span><span class="nb">tar</span> <span class="nt">-xzvf</span> PhoBERT_base_fairseq.tar.gz
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Trong thÆ° má»¥c táº£i vá» sáº½ cÃ³ 3 file sau:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">bpe.codes</code>: BPE token dÃ¹ng Ä‘á»ƒ mÃ£ hÃ³a báº±ng bpe.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">dict.txt</code>:   Tá»« Ä‘iá»ƒn cá»§a táº­p dá»¯ liá»‡u dÃ¹ng huáº¥n luyá»‡n mÃ´ hÃ¬nh.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">model.pt</code>: File pretrain chÃ­nh cá»§a model.</p>
  </li>
</ul>

<h2 id="load-model-báº±ng-python">Load model báº±ng python</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="c1"># Load the model in fairseq
</span><span class="kn">from</span> <span class="nn">fairseq.models.roberta</span> <span class="kn">import</span> <span class="n">RobertaModel</span>
<span class="n">phoBERT</span> <span class="o">=</span> <span class="n">RobertaModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'PhoBERT_base_fairseq'</span><span class="p">,</span> <span class="n">checkpoint_file</span><span class="o">=</span><span class="s">'model.pt'</span><span class="p">)</span>
<span class="n">phoBERT</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>  <span class="c1"># disable dropout (or leave in train mode to finetune
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>á» Ä‘Ã¢y chÃºng ta sá»­ dá»¥ng RobertaModel, Ä‘Ã¢y lÃ  má»™t mÃ´ hÃ¬nh dá»±a trÃªn BERT nhÆ°ng cÃ³ nhiá»u cáº£i tiáº¿n vÃ  Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ lÃ  tá»‘t hÆ¡n so vá»›i BERT.</p>

<h1 id="fine-tune-phobert">Fine-tune phoBERT</h1>

<p>MÃ¬nh sáº½ tÃ¬m cÃ¡ch finetune láº¡i model vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a mÃ¬nh Ä‘á»ƒ phÃ¹ há»£p vá»›i bÃ i toÃ¡n mÃ¬nh cáº§n thá»±c hiá»‡n.</p>

<p>TrÆ°á»›c tiÃªn báº¡n cáº§n download mÃ£ nguá»“n cá»§a fairseq:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="o">!</span>wget https://public.vinai.io/PhoBERT_large_fairseq.tar.gz
<span class="o">!</span><span class="nb">tar</span> <span class="nt">-xzvf</span> PhoBERT_large_fairseq.tar.gz
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau Ä‘Ã³ switch vÃ o thÆ° má»¥c vá»«a download</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>import os

os.chdir<span class="o">(</span><span class="s2">"fairseq"</span><span class="o">)</span>
<span class="o">!</span><span class="nb">ls</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Thá»±c hiá»‡n cÃ i Ä‘áº·t cÃ¡c gÃ³i vÃ  thÆ° viá»‡n cáº§n thiáº¿t:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="o">!</span>pip <span class="nb">install</span> <span class="nt">--editable</span> ./
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Káº¿t quáº£:</p>
<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>Installing collected packages: fairseq
  Found existing installation: fairseq 0.10.2
    Uninstalling fairseq-0.10.2:
      Successfully uninstalled fairseq-0.10.2
  Running setup.py develop for fairseq
Successfully installed fairseq

</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau Ä‘Ã¢y lÃ  cÃ¡c bÆ°á»›c thá»±c hiá»‡n finetune phoBERT</p>

<h2 id="dá»¯-liá»‡u-huáº¥n-luyá»‡n">Dá»¯ liá»‡u huáº¥n luyá»‡n</h2>

<p>Dá»¯ liá»‡u trong bÃ i toÃ¡n nÃ y cá»§a mÃ¬nh lÃ  cÃ¡c cÃ¢u há»i trong táº­p dá»¯ liá»‡u cÃ¢u há»i cá»§a sinh viÃªn trÆ°á»ng Äáº¡i há»c XÃ¢y dá»±ng mÃ  mÃ¬nh Ä‘ang xÃ¢y dá»±ng há»‡ thá»‘ng há»i Ä‘Ã¡p tá»± Ä‘á»™ng. Má»—i cÃ¢u há»i sáº½ Ä‘Æ°á»£c gÃ¡n nhÃ£n tÆ°Æ¡ng á»©ng vá»›i Ã½ Ä‘á»‹nh cá»§a cÃ¢u há»i. MÃ¬nh sáº½ sá»­ dá»¥ng nhÃ£n nÃ y Ä‘á»ƒ sinh thÃªm cÃ¢u há»i tÆ°Æ¡ng á»©ng vá»›i nhÃ£n mong muá»‘n.</p>

<p>VÃ­ dá»¥ má»™t cÃ¢u há»i nhÆ° sau: â€œCÃ´ Æ¡i cho e há»i vá» viá»‡c Ä‘Äƒng kÃ­ vÃ  há»§y mÃ´n há»c , mÃ´n e Ä‘Äƒng kÃ­ vá»«a má»›i cÃ³ Ä‘iá»ƒm vÃ  e muá»‘n há»§y Ä‘Äƒng kÃ­ mÃ´n Ä‘Ã³ vÃ o kÃ¬ 3 cÃ³ Ä‘c khÃ´ng áº¡â€ cÃ³ nhÃ£n lÃ  <code class="language-plaintext highlighter-rouge">ÄÄƒng kÃ½ mÃ´n há»c</code> vÃ¬ ngÆ°á»i há»i cÃ³ Ã½ Ä‘á»‹nh há»i vá» viá»‡c Ä‘Äƒng kÃ½ mÃ´n há»c.</p>

<p>Dá»¯ liá»‡u huáº¥n luyá»‡n sáº½ cáº§n pháº£i Ä‘Æ°á»£c encode vá» dáº¡ng bpe (Byte Pair Encoding) trÆ°á»›c khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh.</p>

<h3 id="tÃ¬m-hiá»ƒu-vá»-mÃ£-hÃ³a-bpe">TÃ¬m hiá»ƒu vá» mÃ£ hÃ³a BPE</h3>

<p>BPE (Byte Pair Encoding) lÃ  má»™t ká»¹ thuáº­t nÃ©n tá»« cÆ¡ báº£n giÃºp chÃºng ta index Ä‘Æ°á»£c toÃ n bá»™ cÃ¡c tá»« ká»ƒ cáº£ trÆ°á»ng há»£p tá»« má»Ÿ (khÃ´ng xuáº¥t hiá»‡n trong tá»« Ä‘iá»ƒn) nhá» mÃ£ hÃ³a cÃ¡c tá»« báº±ng chuá»—i cÃ¡c tá»« phá»¥ (subwords). NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng cá»§a BPE dá»±a trÃªn phÃ¢n tÃ­ch trá»±c quan ráº±ng háº§u háº¿t cÃ¡c tá»« Ä‘á»u cÃ³ thá»ƒ phÃ¢n tÃ­ch thÃ nh cÃ¡c thÃ nh pháº§n con.</p>

<p>Cháº³ng háº¡n nhÆ° tá»«: low, lower, lowest Ä‘á»u lÃ  há»£p thÃ nh bá»Ÿi low vÃ  nhá»¯ng Ä‘uÃ´i phá»¥ er, est. Nhá»¯ng Ä‘uÃ´i nÃ y ráº¥t thÆ°á»ng xuyÃªn xuáº¥t hiá»‡n á»Ÿ cÃ¡c tá»«. NhÆ° váº­y khi biá»ƒu diá»…n tá»« lower chÃºng ta cÃ³ thá»ƒ mÃ£ hÃ³a chÃºng thÃ nh hai thÃ nh pháº§n tá»« phá»¥ (subwords) tÃ¡ch biá»‡t lÃ  low vÃ  er. Theo cÃ¡ch biá»ƒu diá»…n nÃ y sáº½ khÃ´ng phÃ¡t sinh thÃªm má»™t index má»›i cho tá»« lower vÃ  Ä‘á»“ng thá»i tÃ¬m Ä‘Æ°á»£c má»‘i liÃªn há»‡ giá»¯a lower, lowest vÃ  low nhá» cÃ³ chung thÃ nh pháº§n tá»« phá»¥ lÃ  low.</p>

<p>PhÆ°Æ¡ng phÃ¡p BPE sáº½ thá»‘ng kÃª táº§n suáº¥t xuáº¥t hiá»‡n cá»§a cÃ¡c tá»« phá»¥ cÃ¹ng nhau vÃ  tÃ¬m cÃ¡ch gá»™p chÃºng láº¡i náº¿u táº§n suáº¥t xuáº¥t hiá»‡n cá»§a chÃºng lÃ  lá»›n nháº¥t. Cá»© tiáº¿p tá»¥c quÃ¡ trÃ¬nh gá»™p tá»« phá»¥ cho tá»›i khi khÃ´ng tá»“n táº¡i cÃ¡c subword Ä‘á»ƒ gá»™p ná»¯a, ta sáº½ thu Ä‘Æ°á»£c táº­p subwords cho toÃ n bá»™ bá»™ vÄƒn báº£n mÃ  má»i tá»« Ä‘á»u cÃ³ thá»ƒ biá»ƒu diá»…n Ä‘Æ°á»£c thÃ´ng qua subwords.</p>

<p>Code cá»§a thuáº­t toÃ¡n BPE Ä‘Ã£ Ä‘Æ°á»£c tÃ¡c giáº£ chia sáº» táº¡i subword-nmt.</p>

<p>QÃºa trÃ¬nh nÃ y gá»“m cÃ¡c bÆ°á»›c nhÆ° sau:</p>

<p>BÆ°á»›c 1: Khá»Ÿi táº¡o tá»« Ä‘iá»ƒn (vocabulary).</p>

<p>BÆ°á»›c 2: Biá»ƒu diá»…n má»—i tá»« trong bá»™ vÄƒn báº£n báº±ng káº¿t há»£p cá»§a cÃ¡c kÃ½ tá»± vá»›i token &lt;\w&gt; á»Ÿ cuá»‘i cÃ¹ng Ä‘Ã¡nh dáº¥u káº¿t thÃºc má»™t tá»« (lÃ½ do thÃªm token sáº½ Ä‘Æ°á»£c giáº£i thÃ­ch bÃªn dÆ°á»›i).</p>

<p>BÆ°á»›c 3: Thá»‘ng kÃª táº§n suáº¥t xuáº¥t hiá»‡n theo cáº·p cá»§a toÃ n bá»™ token trong tá»« Ä‘iá»ƒn.</p>

<p>BÆ°á»›c 4: Gá»™p cÃ¡c cáº·p cÃ³ táº§n suáº¥t xuáº¥t hiá»‡n lá»›n nháº¥t Ä‘á»ƒ táº¡o thÃ nh má»™t n-gram theo level character má»›i cho tá»« Ä‘iá»ƒn.</p>

<p>BÆ°á»›c 5: Láº·p láº¡i bÆ°á»›c 3 vÃ  bÆ°á»›c 4 cho tá»›i khi sá»‘ bÆ°á»›c triá»ƒn khai merge Ä‘áº¡t Ä‘á»‰nh hoáº·c kÃ­ch thÆ°á»›c ká»³ vá»ng cá»§a tá»« Ä‘iá»ƒn Ä‘áº¡t Ä‘Æ°á»£c.</p>

<p>(theo https://phamdinhkhanh.github.io/2020/06/04/PhoBERT_Fairseq.html)</p>

<h3 id="bpe-tokenize-trong-bert">BPE tokenize trong BERT</h3>

<p>Äá»ƒ thá»±c hiá»‡n tokenize, chÃºng ta lÃ m nhÆ° sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">fairseq.data.encoders.fastbpe</span> <span class="kn">import</span> <span class="n">fastBPE</span>

<span class="c1"># Khá»Ÿi táº¡o Byte Pair Encoding cho PhoBERT
</span><span class="k">class</span> <span class="nc">BPE</span><span class="p">():</span>
  <span class="n">bpe_codes</span> <span class="o">=</span> <span class="s">'PhoBERT_base_fairseq/bpe.codes'</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">BPE</span><span class="p">()</span>
<span class="n">phoBERT</span><span class="p">.</span><span class="n">bpe</span> <span class="o">=</span> <span class="n">fastBPE</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="c1">#Incorporate the BPE encoder into PhoBERT
</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">phoBERT</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'Hello world!'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'tokens list : '</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
<span class="c1"># Decode ngÆ°á»£c láº¡i thÃ nh cÃ¢u tá»« chuá»—i index token
</span><span class="n">phoBERT</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># 'Hello world!'
</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Káº¿t quáº£</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>tokens list :  tensor([    0, 11623, 31433, 1232, 2])
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Hello world!
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="cÃ¡c-bÆ°á»›c-thá»±c-hiá»‡n">CÃ¡c bÆ°á»›c thá»±c hiá»‡n</h1>

<h2 id="khai-bÃ¡o-cÃ¡c-hÃ m-tiá»n-xá»­-lÃ½-vÄƒn-báº£n-tiáº¿ng-viá»‡t">Khai bÃ¡o cÃ¡c hÃ m tiá»n xá»­ lÃ½ vÄƒn báº£n tiáº¿ng viá»‡t</h2>

<p>ChÃºng ta sáº½ sá»­ dá»¥ng thÆ° viá»‡n vncorenlp Ä‘á»ƒ tiáº¿n hÃ nh tÃ¡ch tá»« tiáº¿ng viá»‡t vÃ  sá»­ dá»¥ng tá»« Ä‘iá»ƒn cÃ¡c tá»« dá»«ng Ä‘á»ƒ loáº¡i bá» cÃ¡c stopword.</p>

<h3 id="download-thÆ°-viá»‡n-tÃ¡ch-tá»«">Download thÆ° viá»‡n tÃ¡ch tá»«</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="o">!</span><span class="nb">mkdir</span> <span class="nt">-p</span> vncorenlp/models/wordsegmenter
<span class="o">!</span>wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar
<span class="o">!</span>wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab
<span class="o">!</span>wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr
<span class="o">!</span><span class="nb">mv </span>VnCoreNLP-1.1.1.jar vncorenlp/
<span class="o">!</span><span class="nb">mv </span>vi-vocab vncorenlp/models/wordsegmenter/
<span class="o">!</span><span class="nb">mv </span>wordsegmenter.rdr vncorenlp/models/wordsegmenter/
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="khai-bÃ¡o-thÆ°-viá»‡n-tÃ¡ch-tá»«">Khai bÃ¡o thÆ° viá»‡n tÃ¡ch tá»«</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="n">filename</span> <span class="o">=</span> <span class="s">'/Ä‘Æ°á»ng_dáº«n/Ä‘áº¿n/stopwords.csv'</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>
<span class="n">list_stopwords</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'stopwords'</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">remove_stopword</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">pre_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">list_stopwords</span><span class="p">:</span>
            <span class="n">pre_text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">text2</span> <span class="o">=</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">pre_text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text2</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>CÃ¡c báº¡n thay <code class="language-plaintext highlighter-rouge">filename</code> báº±ng tÃªn Ä‘Æ°á»ng dáº«n file chá»©a cÃ¡c stopword.</p>

<h3 id="tiá»n-xá»­-lÃ½-vÄƒn-báº£n">Tiá»n xá»­ lÃ½ vÄƒn báº£n</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'&lt;.*?&gt;'</span><span class="p">,</span> <span class="s">''</span><span class="p">,</span> <span class="n">text</span><span class="p">).</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'(\s)+'</span><span class="p">,</span> <span class="sa">r</span><span class="s">'\1'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">remove_numbers</span><span class="p">(</span><span class="n">text_in</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">text_in</span><span class="p">.</span><span class="n">split</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">ele</span><span class="p">.</span><span class="n">isdigit</span><span class="p">():</span>
        <span class="n">text_in</span> <span class="o">=</span> <span class="n">text_in</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="n">ele</span><span class="p">,</span> <span class="s">"@"</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">text_in</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">character</span><span class="p">.</span><span class="n">isdigit</span><span class="p">():</span>
        <span class="n">text_in</span> <span class="o">=</span> <span class="n">text_in</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="n">character</span><span class="p">,</span> <span class="s">"@"</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">text_in</span>


<span class="k">def</span> <span class="nf">remove_special_characters</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
  <span class="n">chars</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">escape</span><span class="p">(</span><span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">'['</span><span class="o">+</span><span class="n">chars</span><span class="o">+</span><span class="s">']'</span><span class="p">,</span> <span class="s">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">word_segment</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
  <span class="n">sent</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">rdrsegmenter</span><span class="p">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">" "</span><span class="p">).</span><span class="n">lower</span><span class="p">())[</span><span class="mi">0</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">sent</span>


<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">text_in</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">clean_text</span><span class="p">(</span><span class="n">text_in</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">remove_special_characters</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">remove_numbers</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">word_segment</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="Ä‘á»c-dá»¯-liá»‡u">Äá»c dá»¯ liá»‡u:</h2>

<p>Sau khi khai bÃ¡o cÃ¡c hÃ m tiá»n xá»­ lÃ½, chÃºng ta sáº½ tiáº¿n hÃ nh Ä‘á»c dá»¯ liá»‡u tá»« file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">json</span>

<span class="n">qa_data_path</span> <span class="o">=</span> <span class="s">'/content/drive/MyDrive/NUCE/NLP/QA/intent_db_v2.json'</span>

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">traindata</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">qa_data_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
        <span class="n">qa_data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_file</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">qa_data</span><span class="p">:</span>
            <span class="k">if</span> <span class="s">'content'</span> <span class="ow">in</span> <span class="n">question</span> <span class="p">:</span>
              <span class="n">content</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">question</span><span class="p">[</span><span class="s">'content'</span><span class="p">])</span>
              <span class="n">traindata</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">content</span><span class="p">.</span><span class="n">split</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Dataset loaded"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">qa_data</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">qa_data</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">wiki_data_path</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="chuáº©n-hÃ³a-dá»¯-liá»‡u">Chuáº©n hÃ³a dá»¯ liá»‡u</h2>

<p>Äá»ƒ táº¡o ra cÃ¡c cÃ¢u vá»›i class tÆ°Æ¡ng á»©ng, dá»¯ liá»‡u huáº¥n luyá»‡n sáº½ cÃ³ dáº¡ng nhÆ° sau:</p>

<p><code class="language-plaintext highlighter-rouge">&lt;s&gt; CLASS_NAME &lt;/s&gt; content &lt;/s&gt;</code></p>

<p>LÃ½ do vÃ¬ sao sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm paper <a href="https://arxiv.org/pdf/2004.01881.pdf">CG-BERT: Conditional Text Generation with BERT for Generalized Few-shot Intent Detection</a>:</p>

<p><img src="/assets/img/blog/05/dataaugument.png" alt="Data" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">json</span>
<span class="n">sents_output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">intents_output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">qa_data</span><span class="p">:</span>
<span class="k">if</span> <span class="s">'content'</span> <span class="ow">in</span> <span class="n">question</span> <span class="ow">and</span> <span class="s">'intent'</span> <span class="ow">in</span> <span class="n">question</span><span class="p">:</span>
  <span class="n">sents_output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">"&lt;s&gt; "</span> <span class="o">+</span> <span class="n">question</span><span class="p">[</span><span class="s">'intent'</span><span class="p">]</span> <span class="o">+</span> <span class="s">" &lt;/s&gt; "</span> <span class="o">+</span>  <span class="n">preprocess</span><span class="p">(</span><span class="n">question</span><span class="p">[</span><span class="s">'content'</span><span class="p">]).</span><span class="n">replace</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">" "</span><span class="p">)</span>  <span class="o">+</span> <span class="s">" &lt;/s&gt;"</span><span class="p">)</span>
  <span class="n">intents_output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">question</span><span class="p">[</span><span class="s">'intent'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">sents_output</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Káº¿t quáº£ sau khi chuáº©n hÃ³a sáº½ lÃ :</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre> ['&lt;s&gt; DIEM &lt;/s&gt; cho em há»i em cÃ³_thá»ƒ chuyá»ƒn_Ä‘á»•i káº¿t_quáº£ @ mÃ´n_há»c cÃ¹ng tÃªn nhÆ°ng khÃ¡c mÃ£ Ä‘Æ°á»£c khÃ´ng áº¡ &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; em má»›i lÃ m Ä‘Æ¡n phÃºc_kháº£o gáº§n Ä‘Ã¢y áº¡ mÃ  @ @ ngÃ y rá»“i tháº¥y mÃ£i Ä‘iá»ƒm chÆ°a thay_Ä‘á»•i em cÃ³_thá»ƒ xin phÃ©p Ä‘c xem bÃ i thi cá»§a mÃ¬nh Ä‘c k áº¡ náº¿u em thá»±c_sá»± sai em chá»‰ muá»‘n xem_láº¡i bÃ i thi cá»§a mÃ¬nh &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; cho em há»i lÃ  lÃ m_sao Ä‘á»ƒ biáº¿t káº¿t_quáº£ Ä‘iá»ƒm phÃºc_kháº£o mÃ´n_há»c sau khi Ä‘Ã£ lÃ m Ä‘Æ¡n phÃºc_kháº£o áº¡ &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; thÆ°a tháº§y muá»‘n phÃºc_kháº£o Ä‘iá»ƒm mÃ´n_há»c thÃ¬ lÃ m tháº¿_nÃ o áº¡ &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; tháº§y_cÃ´ cho em há»i lÃ  cÃ²n thá»i_gian phÃºc_tra Ä‘iá»ƒm cá»§a kÃ¬ há»c vá»«a_rá»“i khÃ´ng áº¡ vÃ¬ dá»‹ch_bá»‡nh khÃ´ng lÃªn trÆ°á»ng Ä‘Æ°á»£c nÃªn em Ä‘Ã£ khÃ´ng phÃºc_tra Ä‘Æ°á»£c bÃ i áº¡ &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; cho em há»i lÃ  muá»‘n phÃºc_tra Ä‘iá»ƒm thÃ¬ lÃ m tháº¿_nÃ o áº¡ &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; cho em há»i lÃ  thá»i_háº¡n phÃºc_kháº£o mÃ´n_há»c lÃ  bao_giá» áº¡ em cáº§n lÃ m Ä‘Æ¡n hay liÃªn_há»‡ vá»›i ai Ä‘á»ƒ tiáº¿n_hÃ nh phÃºc_tra Ä‘Æ°á»£c áº¡ &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; mong tháº§y_cÃ´ xem giÃºp e Ä‘iá»ƒm trÃªn trang Ä‘ao táº¡o vá»›i áº¡ hiá»‡n_táº¡i Ä‘iá»ƒm Ä‘á»“_Ã¡n tá»‘t_nghiá»‡p cá»§a e Ä‘Ã£ Ä‘Æ°á»£c cáº­p_nháº­t lÃªn nhÆ°ng cÃ³_láº½ do lá»—i mÃ  chÆ°a Ä‘Æ°á»£c cá»™ng tá»•ng Ä‘iá»ƒm trung_bÃ¬nh tÃ­ch_luá»¹ vÃ  sá»‘ tÃ­n_chá»‰ cá»§a Ä‘á»“_Ã¡n tá»‘t_nghiá»‡p &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; em cÃ³ tháº¯c_máº¯c muá»‘n há»i lÃ  @ tÃ­n_Ä‘á»“ Ã¡n tá»‘t_nghiá»‡p Ä‘atn cÃ³ tÃ­nh vÃ o sá»‘ tÃ­n_chá»‰ tÃ­ch_luá»¹ hay khÃ´ng\xa0lÃ­ do vÃ¬ em tháº¥y trÃªn trang Ä‘Ã o_táº¡o sau khi Ä‘Ã£ up Ä‘iá»ƒm Ä‘atn cá»§a em lÃªn láº¡i khÃ´ng tháº¥y tÃ­nh @ tÃ­n_chá»‰ nÃ y vÃ o sá»‘ tÃ­nh chá»‰ tÃ­ch_luá»¹ áº£nh chá»¥p kÃ¨m theo lÃ  Ä‘iá»ƒm cá»§a em &lt;/s&gt;',
  '&lt;s&gt; DIEM &lt;/s&gt; dáº¡ em chÃ o tháº§y_cÃ´ thÆ°a tháº§y_cÃ´ lÃ  Ä‘iá»ƒm cá»§a em trÃªn trang Ä‘Ã o_táº¡o tháº§y vÃ o Ä‘iá»ƒm sai cho em vÃ  em Ä‘Ã£ há»i tháº§y tháº§y cÃ³ nÃ³i Ä‘Ã£ sá»­a láº¡i Ä‘iá»ƒm tháº¿ nÃªn cho em há»i bao_giá» Ä‘Ã o_táº¡o cáº­p_nháº­t láº¡i Ä‘iá»ƒm áº¡ e xin cáº£m_Æ¡n tháº§y_cÃ´ áº¡ &lt;/s&gt;']
</pre></td></tr></tbody></table></code></pre></div></div>

<p>á» Ä‘Ã¢y mÃ¬nh sá»­ dá»¥ng token <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> nhÆ° lÃ  token báº¯t Ä‘áº§u cá»§a cÃ¢u, <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> lÃ  token phÃ¢n cÃ¡ch cÃ¢u.</p>

<h2 id="phÃ¢n-chia-dá»¯-liá»‡u-huáº¥n-luyá»‡n">PhÃ¢n chia dá»¯ liá»‡u huáº¥n luyá»‡n</h2>

<p>MÃ¬nh tiáº¿n hÃ nh phÃ¢n chia dá»¯ liá»‡u thÃ nh 3 táº­p train, test vÃ  valid. VÃ¬ dá»¯ liá»‡u hÆ¡i Ã­t nÃªn mÃ¬nh sáº½ Ä‘á»ƒ táº­p test vÃ  valid má»—i táº­p 50 Ä‘iá»ƒm dá»¯ liá»‡u</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">random</span>

<span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">sents_output</span><span class="p">)</span>

<span class="n">valid_data</span> <span class="o">=</span> <span class="n">sents_output</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">sents_output</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">sents_output</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="mÃ£-hÃ³a-dá»¯-liá»‡u-huáº¥n-luyá»‡n-theo-bpe">MÃ£ hÃ³a dá»¯ liá»‡u huáº¥n luyá»‡n theo bpe</h2>

<p>Dá»¯ liá»‡u huáº¥n luyá»‡n cáº§n Ä‘Æ°á»£c mÃ£ hÃ³a thÃ nh cÃ¡c token bpe Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng cho cÃ¡c language model. Náº¿u báº¡n nÃ o lÃ m nhiá»u vá»›i NLP cháº¯c háº³n Ä‘Ã£ quen vá»›i phÆ°Æ¡ng phÃ¡p nÃ y.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre>
<span class="k">def</span> <span class="nf">encode_bpe</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">target_dir</span><span class="p">):</span>
  <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">target_dir</span> <span class="o">+</span> <span class="s">"finetune."</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s">".bpe"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">bpe_enc</span> <span class="o">=</span> <span class="s">""</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">phoBERT</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
      <span class="n">bpe_enc</span> <span class="o">=</span> <span class="n">bpe_enc</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">token</span><span class="p">.</span><span class="n">item</span><span class="p">())</span> <span class="o">+</span> <span class="s">" "</span>
    <span class="n">bpe_enc</span> <span class="o">=</span> <span class="n">bpe_enc</span> <span class="o">+</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">bpe_enc</span><span class="p">)</span>

  <span class="n">f</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau khi mÃ£ hÃ³a bpe, dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh trong <code class="language-plaintext highlighter-rouge">target_dir</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">save_path</span> <span class="o">=</span> <span class="s">"fintune_data"</span>
<span class="n">encode_bpe</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="s">"valid"</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
<span class="n">encode_bpe</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="s">"test"</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
<span class="n">encode_bpe</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="s">"train"</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="Ä‘Æ°a-dá»¯-liá»‡u-vÃ o-pha-tiá»n-xá»­-lÃ½-Ä‘á»ƒ-táº¡o-Ä‘áº§u-vÃ o-cho-bert">ÄÆ°a dá»¯ liá»‡u vÃ o pha tiá»n xá»­ lÃ½ Ä‘á»ƒ táº¡o Ä‘áº§u vÃ o cho BERT</h2>

<p>á» Ä‘Ã¢y chÃºng ta sáº½ thá»±c hiá»‡n thÃ´ng qua thÆ° viá»‡n qua command line nhÆ° sau:</p>

<p>(cÃ¡c báº¡n nhá»› thay <code class="language-plaintext highlighter-rouge">/path/to/save_path</code> thÃ nh Ä‘Æ°á»ng dáº«n lÆ°u cÃ¡c file bpe trong bÆ°á»›c trÃªn)</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="o">!</span> fairseq-preprocess <span class="nt">--only-source</span>   <span class="nt">--srcdict</span> /path/to/save_path <span class="nt">--workers</span> 60
</pre></td></tr></tbody></table></code></pre></div></div>

<p>BÆ°á»›c nÃ y xá»­ lÃ½ khÃ¡ nhanh, chá»‰ vÃ i giÃ¢y lÃ  xong do táº­p dá»¯ liá»‡u cá»§a mÃ¬nh hÆ¡i Ã­t. Sau khi cháº¡y xong, dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre>2021-05-08 15:37:31 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/data-bin/finetune_data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict='/content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/PhoBERT_base_fairseq/dict.txt', suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref='/content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/fintune_data/finetune.test.bpe', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/fintune_data/finetune.train.bpe', use_plasma_view=False, user_dir=None, validpref='/content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/fintune_data/finetune.valid.bpe', wandb_project=None, workers=60)
2021-05-08 15:37:32 | INFO | fairseq_cli.preprocess | [None] Dictionary: 64000 types
2021-05-08 15:37:40 | INFO | fairseq_cli.preprocess | [None] /content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/fintune_data/finetune.train.bpe: 2769 sents, 173535 tokens, 54.6% replaced by &lt;unk&gt;
2021-05-08 15:37:40 | INFO | fairseq_cli.preprocess | [None] Dictionary: 64000 types
2021-05-08 15:37:45 | INFO | fairseq_cli.preprocess | [None] /content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/fintune_data/finetune.valid.bpe: 50 sents, 2951 tokens, 58.1% replaced by &lt;unk&gt;
2021-05-08 15:37:45 | INFO | fairseq_cli.preprocess | [None] Dictionary: 64000 types
2021-05-08 15:37:51 | INFO | fairseq_cli.preprocess | [None] /content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/fintune_data/finetune.test.bpe: 50 sents, 3150 tokens, 53.1% replaced by &lt;unk&gt;
2021-05-08 15:37:51 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/data-bin/finetune_data
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="mÃ£-hÃ³a-dataset-thÃ nh-file-binary-Ä‘á»ƒ-huáº¥n-luyá»‡n-model">MÃ£ hÃ³a dataset thÃ nh file binary Ä‘á»ƒ huáº¥n luyá»‡n model</h3>

<p>Sau khi thá»±c hiá»‡n preprocess, chÃºng ta cáº§n chuyá»ƒn data sang dáº¡ng binary theo yÃªu cáº§u cá»§a thÆ° viá»‡n:
Trong bÆ°á»›c nÃ y sáº½ yÃªu cáº§u cÃ¡c báº¡n cung cáº¥p file tá»« Ä‘iá»ƒn <code class="language-plaintext highlighter-rouge">dict.txt</code> Ä‘Æ°á»£c cho kÃ¨m theo phoBERT</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="o">!</span> fairseq-preprocess <span class="nt">--only-source</span>   <span class="nt">--srcdict</span> PhoBERT_base_fairseq/dict.txt <span class="nt">--trainpref</span> data-bin/fintune_data/finetune.train.bpe  <span class="nt">--validpref</span> finetune.valid.bpe  <span class="nt">--testpref</span> data-bin/finetune_data/finetune.test.bpe <span class="nt">--workers</span> 60
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Sau khi xÃ¢y dá»±ng Ä‘Æ°á»£c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n, bÆ°á»›c cuá»‘i cÃ¹ng Ä‘Ã³ lÃ  thá»±c hiá»‡n fine-tune thÃ´i nÃ o.</p>

<h2 id="tiáº¿n-hÃ nh-fine-tune">Tiáº¿n hÃ nh fine-tune</h2>

<p>ChÃºng ta cháº¡y lá»‡nh sau:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="o">!</span>fairseq-train <span class="nt">--fp16</span> data-bin/finetune_data <span class="se">\</span>
 <span class="nt">--task</span> masked_lm <span class="nt">--lr</span> 2e-05 <span class="nt">--criterion</span> masked_lm <span class="se">\</span>
<span class="nt">--arch</span> roberta_base <span class="nt">--sample-break-mode</span> <span class="nb">complete</span> <span class="se">\</span>
<span class="nt">--tokens-per-sample</span> 256 <span class="nt">--optimizer</span> adam <span class="nt">--adam-betas</span> <span class="s1">'(0.9,0.98)'</span> <span class="se">\</span>
<span class="nt">--adam-eps</span> 1e-6 <span class="nt">--clip-norm</span> 0.0 <span class="se">\</span>
<span class="nt">--lr-scheduler</span> polynomial_decay <span class="se">\</span>
<span class="nt">--warmup-updates</span> 10000 <span class="nt">--total-num-update</span> 12000  <span class="se">\</span>
<span class="nt">--dropout</span> 0.1 <span class="nt">--attention-dropout</span> 0.1 <span class="nt">--weight-decay</span> 0.01   <span class="se">\</span>
<span class="nt">--batch-size</span> 20 <span class="nt">--update-freq</span> 1  <span class="nt">--log-format</span> simple <span class="se">\</span>
<span class="nt">--log-interval</span> 1  <span class="nt">--reset-optimizer</span> <span class="nt">--reset-dataloader</span> <span class="se">\</span>
<span class="nt">--reset-meters</span>  <span class="nt">--sample-break-mode</span> <span class="nb">complete</span> <span class="se">\</span>
<span class="nt">--restore-file</span> PhoBERT_base_fairseq/model.pt  <span class="se">\</span>
<span class="nt">--skip-invalid-size-inputs-valid-test</span>  <span class="se">\</span>
<span class="nt">--max-epoch</span> 500 <span class="nt">--no-epoch-checkpoints</span> <span class="se">\</span>
<span class="nt">--no-last-checkpoints</span> <span class="nt">--no-save-optimizer-state</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>MÃ¬nh sáº½ huáº¥n luyá»‡n thÃ´ng qua 500 epochs, cÃ³ sá»­ dá»¥ng learning rate scheduler vÃ  khá»Ÿi táº¡o ban Ä‘áº§u lr lá»›n 2e-05.</p>

<p>Trong cÃ¢u lá»‡nh trÃªn chÃºng ta sáº½ Ä‘Æ°a vÃ o pretrain cá»§a phoBERT bá»Ÿi tham sá»‘ <code class="language-plaintext highlighter-rouge">--restore-file</code></p>

<p>Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ¬nh sáº½ lÆ°u láº¡i cÃ¡c checkpoint cÃ³ loss tháº¥p nháº¥t Ä‘á»ƒ sá»­ dá»¥ng vá» sau. Sau khi huáº¥n luyá»‡n, káº¿t quáº£ tá»‘t nháº¥t cá»§a mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c lÆ°u vÃ o file `checkpoint_best.ptâ€™</p>

<p>QuÃ¡ trÃ¬nh huáº¥n luyá»‡n khÃ¡ lÃ¢u, mÃ¬nh khuyÃªn cÃ¡c báº¡n náº¿u mÃ¡y tÃ­nh khÃ´ng cÃ³ GPU thÃ¬ nÃªn sá»­ dá»¥ng google colab cÃ³ GPU Ä‘á»ƒ Ä‘á»¡ máº¥t cÃ´ng chá» Ä‘á»£i.</p>

<h2 id="sinh-vÄƒn-báº£n-báº±ng-phobert-Ä‘Ã£-fine-tune">Sinh vÄƒn báº£n báº±ng phoBERT Ä‘Ã£ fine-tune</h2>

<p>Trong bÃ i toÃ¡n nÃ y chÃºng ta sáº½ sinh ra cÃ¡c cÃ¢u má»›i báº±ng cÃ¡ch Ä‘iá»n cÃ¡c tá»« há»£p lÃ½ vÃ o cÃ¡c vá»‹ trÃ­ cÃ²n trá»‘ng cá»§a cÃ¢u.</p>

<p>MÃ´ hÃ¬nh BERT táº¡o ra cÃ¡c biá»ƒu diá»…n tá»« tá»« quÃ¡ trÃ¬nh áº©n cÃ¡c vá»‹ trÃ­ token má»™t cÃ¡ch ngáº«u nhiÃªn trong cÃ¢u input vÃ  dá»± bÃ¡o chÃ­nh chÃ­nh tá»« Ä‘Ã³ á»Ÿ output dá»±a trÃªn bá»‘i cáº£nh lÃ  cÃ¡c tá»« xung quanh.</p>

<p>NhÆ° váº­y khi Ä‘Ã£ biáº¿t cÃ¡c tá»« xung quanh, chÃºng ta hoÃ n toÃ n cÃ³ thá»ƒ dá»± bÃ¡o Ä‘Æ°á»£c tá»« phÃ¹ há»£p nháº¥t vá»›i vá»‹ trÃ­ Ä‘Ã£ Ä‘Æ°á»£c masking.</p>

<p>Ã tÆ°á»Ÿng cá»§a viá»‡c sinh vÄƒn báº£n Ä‘Ã³ lÃ  mÃ¬nh sáº½ tiáº¿n hÃ nh che láº§n lÆ°á»£t cÃ¡c tá»« trong cÃ¢u vÃ  tÃ¬m ra cÃ¡c tá»« bá»‹ che, sau Ä‘Ã³ ghÃ©p láº¡i cÃ¡c tá»­ bá»‹ che thÃ nh cÃ¢u má»›i.</p>

<p>CÃ¡c bÆ°á»›c thá»±c hiá»‡n nhÆ° sau:</p>

<h3 id="load-láº¡i-model-vá»›i-weight-má»›i">Load láº¡i model vá»›i weight má»›i</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c1"># Load the model in fairseq
</span><span class="kn">from</span> <span class="nn">fairseq.data.encoders.fastbpe</span> <span class="kn">import</span> <span class="n">fastBPE</span>
<span class="kn">from</span> <span class="nn">fairseq.models.roberta</span> <span class="kn">import</span> <span class="n">RobertaModel</span>
<span class="n">phoBERT</span> <span class="o">=</span> <span class="n">RobertaModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'/path/to/checkpoints'</span><span class="p">,</span> <span class="n">checkpoint_file</span><span class="o">=</span><span class="s">"checkpoint_best.pt"</span><span class="p">)</span>

<span class="c1"># Khá»Ÿi táº¡o Byte Pair Encoding cho PhoBERT
</span><span class="k">class</span> <span class="nc">BPE</span><span class="p">():</span>
  <span class="n">bpe_codes</span> <span class="o">=</span> <span class="s">'/content/drive/MyDrive/NUCE/NLP/QA/BERT/fairseq/checkpoints/bpe.codes'</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">BPE</span><span class="p">()</span>
<span class="n">phoBERT</span><span class="p">.</span><span class="n">bpe</span> <span class="o">=</span> <span class="n">fastBPE</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="c1">#Incorporate the BPE encoder into PhoBERT
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Thá»±c hiá»‡n sinh vÄƒn báº£n má»›i</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">seed</span> <span class="o">=</span> <span class="s">"Cho em há»i bao giá» thÃ¬ cÃ³ báº±ng tá»‘t nghiá»‡p áº¡"</span>
<span class="n">intent</span> <span class="o">=</span> <span class="s">"TN"</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">seed</span><span class="p">).</span><span class="n">split</span><span class="p">()</span>

<span class="n">seed</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="n">gen_sentence</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s">"&lt;mask&gt;"</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="s">"&lt;s&gt;'+intent+'&lt;/s&gt; "</span> <span class="o">+</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">+</span> <span class="s">"&lt;/s&gt;"</span>
    <span class="k">print</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">topk_filled_outputs</span> <span class="o">=</span> <span class="n">phoBERT</span><span class="p">.</span><span class="n">fill_mask</span><span class="p">(</span><span class="n">mask</span> <span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
    <span class="n">gen_sentence</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">topk_filled_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">gen_sentence</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Káº¿t quáº£ in ra sáº½ lÃ :</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Xin tÃ´i há»i khi_nÃ o sáº½ cÃ³ giáº¥y_chá»©ng_nháº­n tá»‘t_nghiá»‡p
</pre></td></tr></tbody></table></code></pre></div></div>

<p>NhÆ° váº­y lÃ  cÃ¢u Ä‘Æ°á»£c sinh ra khÃ¡ lÃ  giá»‘ng vá»›i cÃ¢u seed, ngoÃ i ra <code class="language-plaintext highlighter-rouge">&lt;mask&gt;</code> thay vÃ¬ dá»‹ch tá»« trÃ¡i qua pháº£i, cÃ¡c báº¡n cÅ©ng cÃ³ thá»ƒ thá»­ dá»‹ch tá»« pháº£i qua trÃ¡i.</p>

<h1 id="tá»•ng-káº¿t">Tá»•ng káº¿t</h1>

<p>NhÆ° váº­y trong bÃ i nÃ y mÃ¬nh Ä‘Ã£ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡ch finetune láº¡i model phoBERT vÃ  thá»±c hiá»‡n dÃ¹ng model sau khi fine-tune Ä‘á»ƒ sinh vÄƒn báº£n má»›i. Ká»¹ thuáº­t nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong viá»‡c táº¡o thÃªm dá»¯ liá»‡u trong cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘á»ƒ tÄƒng thÃªm Ä‘á»™ chÃ­nh xÃ¡c cho mÃ´ hÃ¬nh.</p>

<p>Hi vá»ng bÃ i nÃ y giÃºp Ã­ch Ä‘Æ°á»£c cho má»i ngÆ°á»i!</p>

<h1 id="tÃ i-liá»‡u-tham-kháº£o">TÃ i liá»‡u tham kháº£o</h1>

<ul>
  <li>
    <p>https://arxiv.org/pdf/2004.01881.pdf</p>
  </li>
  <li>
    <p>https://phamdinhkhanh.github.io/2020/06/04/PhoBERT_Fairseq.html</p>
  </li>
  <li>
    <p>https://viblo.asia/p/bert-roberta-phobert-bertweet-ung-dung-state-of-the-art-pre-trained-model-cho-bai-toan-phan-loai-van-ban-4P856PEWZY3</p>
  </li>
  <li>
    <p>https://medium.com/intel-student-ambassadors/natural-language-generation-using-bert-df6d863c3f52</p>
  </li>
</ul>
:ET