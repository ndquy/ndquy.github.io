I"%.<p>Như chúng ta đã thảo luận từ các bài trước, một vài thuật toán hồi quy có thể được sử dụng để phân lớp (và ngược lại) đều cho kết quả khá tốt. Logistic Regression (hay còn gọi là Logit Regression) được sử dụng phổ biến để ước lượng xác suất 1 điểm dữ liệu có thể thuộc về 1 lớp nào đó (ví dụ tính xác suất để 1 email là spam). Nếu xác suất &gt; 50% thì mô hình dự đoán có thể khẳng định được điểm dữ liệu đó thuộc về lớp 1 (nhãn là 1) hoặc ngược lại (nhãn là 0). Việc này được gọi là phân loại nhị phân (chỉ có 0 với 1)</p>

<h1 id="ước-lượng-xác-suất">Ước lượng xác suất</h1>

<p>Làm thế nào để ước lượng được xác suất 1 điểm dữ liệu thuộc vào lớp nào? giống như mô hình hồi quy tuyến tính, mô hình hồi quy Logistic sẽ tính tổng các tích trọng số (weighted sum) với features đầu vào (có cộng thêm bias). Nhưng thay vì trả kết quả trực tiếp giống mô hình Linear Regression thì nó sẽ đi qua 1 hàm logistic để cho kết quả.</p>

<p>[\hat p = h_θ(x) = σ(x^Tθ)  (\text{Hàm ước lượng xác suất})]</p>

<p>Trong đó σ(·) là hàm sigmoid, đầu ra của nó sẽ là khoảng giá trị từ 0 đến 1.</p>

<p>[\sigma(t) = \frac{1}{1 + exp(-t)}]</p>

<p>Chúng ta nhận xét đây là một hàm số đặc biệt, với mọi giá trị của t, hàm luôn nằm trong khoảng [0,1] và có đồ thị như sau:</p>

<p><img src="/assets/img/blog/1_a04iKNbchayCAJ7-0QlesA.png" alt="Đồ thị hàm sigmoid" />
<em>Đồ thị hàm sigmoid</em></p>

<p>Sau khi đã tính được xác suất $\hat p = h_\theta(x)$ ta sẽ dễ dàng xác định được x thuộc về lớp nào, hay  $\hat y$:</p>

<p>[\hat y =\begin{cases}0 &amp; \text{if $\hat p  &lt; 0.5 $} \1 &amp; \text{if $\hat p \ge 0.5 $}\end{cases}]</p>

<p>Để ý rằng $σ(t) &lt; 0.5$ khi $t&lt;0$ và $σ(t) \ge 0.5$ khi $t \ge 0$ vì vậy hồi quy Logistic sẽ dự đoán là 1 khi $x^T \theta$ là dương và 0 khi $x^T \theta$ âm.</p>

<h1 id="hàm-chi-phí-và-huấn-luyện-mô-hình">Hàm chi phí và huấn luyện mô hình</h1>

<p>Vì ta phân lớp dựa trên xác suất nên hàm chi phí sẽ được tính dựa trên xác suất xảy ra. Vì vậy mục tiêu của việc training sẽ là tìm ra vector tham số θ để mô hình ước lượng xác suất cao cho các điểm dữ liệu thuộc vào lớp 1 (positive) và xác suất thấp cho các điểm dữ liệu thuộc vào lớp 2 (negative) nên ta sẽ có hàm chi phí cho điểm dữ liệu x như sau:</p>

<p>[c(\theta) =\begin{cases}-log(\hat p) &amp; \text{if $ y = 1 $} \-log(1- \hat p) &amp; \text{if $ y = 0 $}\end{cases}]</p>

<p>Hàm chi phí rất “nhạy” bởi vì – log(t) sẽ tăng nhanh khi t xấp xỉ 0. Nếu ta dự đoán dữ liệu thuộc lớp 1 có xác xuất nhỏ thì chi phí sẽ lớn (trường hợp dự đoán sai) và nếu ta dữ đoán dữ liệu thuộc lớp 0 mà có xác suất nhỏ thì chi phí sẽ nhỏ và xấp xỉ dần về 0. Đây chính là mục tiêu của chúng ta khi huấn luyện mô hình.</p>

<p>Hàm chi phí trong toàn bộ tập huấn chỉ đơn giản là chi phí trung bình trên tất cả các điểm dữ liệu huấn luyện. Nên chúng ta có thể viết gộp lại thành biểu thức sau:</p>

<p>[J(\theta)=-\frac{1}{m}\sum_{i=1}{m}[y^{(i)} log(\hat p^{(i)}) + (1-y^{(i)})log(1-\hat p^{(i)})]]</p>

<p>Ở công thức này chúng ta không thể tính được tham số θ để tối thiểu hóa hàm chi phí một cách trực tiếp. Tuy nhiên thì hàm này là hàm lồi, vì vậy nên ta có thể sử dụng Gradient Descent  (hoặc bất kì thuật toán tối ưu nào) như ở bài trước để thực hiện tìm cực tiểu (nếu learning rate không quá lớn và bạn chờ đủ lâu). Đạo hàm từng phần của hàm chi phí $ \theta_j $ được tính như sau (tiến hành đạo hàm theo θ):</p>

<p>[\frac{\delta J(\theta) }{\delta \theta_j}= \frac{1}{m}\sum_{1}^{m}(\sigma (\theta^Tx^{(i)}) - y^{(i)})x_j^{(i)}]</p>

<p>Qua mỗi điểm dữ liệu, chúng ta sẽ tính toán lỗi của việc dự đoán và nhân nó với x thứ j rồi thực hiện tính trung bình trên toàn bộ tập huấn luyện.</p>

<p>Khi đó chúng ta có  gradient vector chứa tất cả các đạo hàm riêng để thực hiện thuật toán Batch Gradient Descent. Và theo công thức cập nhật θ  chúng ta sẽ có:</p>

<p>$ \theta = \theta - η\frac{\delta J(\theta)}{\delta \theta} $ Với η là learning rate</p>

<p>Và thay vì tính toán trên toàn bộ tập huấn luyện, bạn cũng có thể sử dụng Mini-batch GD hoặc Stochastic GD như mình giới thiệu ở bài trước.</p>

<h1 id="lập-trình">Lập trình</h1>
<p>Mình sẽ thử lập trình với BGD, tập dữ liệu được sử dụng ở đây là dữ liệu bài tập trong khoá học ML của giáo sư Andrew Ng.</p>

<p>Mã nguồn các bạn có thể xem tại đây, dataset thì tại đây (https://github.com/dinhquy94/codecamp.vn/blob/master/ex2.ipynb)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td> --><td class="rouge-code"><pre><span class="c1"># gradient descent max step
</span><span class="n">INTERATIONS</span> <span class="o">=</span> <span class="mi">200000</span>
<span class="c1"># learning rate
</span><span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># calc sigmoid function
</span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="c1"># calc J function
</span><span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="c1"># number of training examples
</span>    <span class="n">m</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span>
    <span class="c1"># activation
</span>    <span class="n">h</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">theta</span><span class="p">))</span>
    <span class="c1"># cost
</span>    <span class="n">j</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span>  <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="n">m</span>
    <span class="k">return</span> <span class="n">j</span>

<span class="c1"># implement BGD
</span><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">num_inters</span><span class="p">):</span>
    <span class="c1"># number of training examples
</span>    <span class="n">m</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span>
    <span class="n">jHistory</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_inters</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_inters</span><span class="p">):</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">theta</span><span class="p">))</span><span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
        <span class="n">theta</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>
        <span class="n">jHistory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">theta</span><span class="p">,</span> <span class="n">jHistory</span>

<span class="c1"># train
</span><span class="n">theta</span><span class="p">,</span> <span class="n">jHistory</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">ALPHA</span><span class="p">,</span> <span class="n">INTERATIONS</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="c1"># theta: [-7.45017822  0.06550395  0.05898701]
</span></pre></td></tr></tbody></table></code></pre></div></div>
<p>Kết quả</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre># theta: [-7.45017822  0.06550395  0.05898701]
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Nguồn tham khảo: Blog Do Minh Hai</p>

:ET