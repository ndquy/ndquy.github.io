I"“1<p>Trong cÃ¡c bÃ i trÆ°á»›c chÃºng ta Ä‘Ã£ xá»­ lÃ½ má»™t sá»‘ bÃ i toÃ¡n machine learning báº±ng 1 sá»‘ thuáº­t toÃ¡n, tuy nhiÃªn chÃºng ta má»›i chá»‰ coi chÃºng nhÆ° cÃ¡c há»™p Ä‘en. Tháº­m chÃ­ chÃºng ta khÃ´ng biáº¿t gÃ¬ vá» cÃ¡ch thá»±c hiá»‡n cá»§a cÃ¡c thuáº­t toÃ¡n Ä‘Ã³ nhÆ°ng váº«n cÃ³ thá»ƒ  Ã¡p dá»¥ng, tháº­m chÃ­ tá»‘i Æ°u vÃ  cáº£i thiá»‡n.</p>

<p>Tuy nhiÃªn náº¿u biáº¿t Ä‘Æ°á»£c chÃ­nh xÃ¡c nhá»¯ng gÃ¬ thuáº­t toÃ¡n lÃ m viá»‡c sáº½ giÃºp chÃºng ta tÃ¬m Ä‘Æ°á»£c ra mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i cÃ¡c bá»™ siÃªu tham sá»‘ Ä‘á»§ tá»‘t. Biáº¿t Ä‘Æ°á»£c báº£n cháº¥t sáº½ giÃºp chÃºng ta xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c váº¥n Ä‘á» gáº·p pháº£i vÃ  phÃ¢n tÃ­ch lá»—i hiá»‡u quáº£ hÆ¡n. Trong pháº§n nÃ y mÃ¬nh sáº½ Ä‘i sÃ¢u vÃ o thuáº­t toÃ¡n há»“i quy tuyáº¿n tÃ­nh (Linear Regression), má»™t trong nhá»¯ng thuáº­t toÃ¡n Ä‘Æ¡n giáº£n nháº¥t. ChÃºng ta sáº½ nghiÃªn cá»©u 2 phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ huáº¥n luyá»‡n:</p>

<ul>
  <li>Sá»­ dá»¥ng cÃ´ng thá»©c Ä‘á»ƒ tÃ¬m ra cÃ¡c tham sá»‘ cho mÃ´ hÃ¬nh mÃ  nÃ³ khá»›p vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n nháº¥t (nghÄ©a lÃ  cÃ¡c tham sá»‘ mÃ´ hÃ¬nh sáº½ tá»‘i thiá»ƒu hÃ³a hÃ m chi phÃ­ (cost function) thÃ´ng qua táº­p huáº¥n luyá»‡n)</li>
  <li>Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u láº·p Ä‘i láº·p láº¡i, phÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c gá»i lÃ  Gradient Descent (xin phÃ©p khÃ´ng dá»‹ch), nÃ³ sáº½ tá»‘i thiá»ƒu hÃ³a dáº§n dáº§n hÃ m chi phÃ­  thÃ´ng qua quÃ¡ trÃ¬nh huáº¥n luyá»‡n, sau 1 sá»‘ bÆ°á»›c láº·p há»¯u háº¡n, mÃ´ hÃ¬nh sáº½ há»™i tá»¥ vÃ  ta Ä‘Æ°á»£c bá»™ tham sá»‘ giá»‘ng vá»›i phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn. ChÃºng ta sáº½ nghiÃªn cá»©u 1 sá»‘ thuáº­t toÃ¡n Gradient Descent: Batch GD, Mini-batch GD vÃ  Stochastic GD.</li>
</ul>

<p>#MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh (Linear Regression)</p>

<p>Má»¥c tiÃªu cá»§a giáº£i thuáº­t há»“i quy tuyáº¿n tÃ­nh lÃ  dá»± Ä‘oÃ¡n giÃ¡ trá»‹ cá»§a má»™t hoáº·c nhiá»u biáº¿n má»¥c tiÃªu liÃªn tá»¥c (continuous target variable) y dá»±a trÃªn má»™t vÃ©c-tÆ¡ Ä‘áº§u vÃ o X</p>

<h2 id="Ä‘á»‹nh-nghÄ©a-mÃ´-hÃ¬nh">Äá»‹nh nghÄ©a mÃ´ hÃ¬nh</h2>

<p>Vá»›i Ä‘áº§u vÃ o x, Ä‘áº§u ra lÃ  y. Ta cÃ³ mÃ´ hÃ¬nh nhÆ° sau:</p>

<p>[\hat y = \theta_0 + \theta_1x_1 + \theta_2x_2 + â€¦ + \theta_nx_n]</p>

<p>Trong Ä‘Ã³</p>
<ul>
  <li>
    <p>$( \hat y )$ lÃ  giÃ¡ trá»‹ Ä‘áº§u ra cáº§n dá»± Ä‘oÃ¡n</p>
  </li>
  <li>
    <p>$n$ lÃ  sá»‘ lÆ°á»£ng features (sá»‘ chiá»u cá»§a vector Ä‘áº§u vÃ o X)</p>
  </li>
  <li>
    <p>$( x_i )$ lÃ  feature thá»© i.</p>
  </li>
  <li>
    <p>$( \theta )$ lÃ  tham sá»‘ cá»§a mÃ´ hÃ¬nh (bao gá»“m $( \theta_0 )$ lÃ  bias vÃ  cÃ¡c  tham sá»‘ $( \theta_1, \theta_2 ),â€¦)$</p>
  </li>
</ul>

<p>PhÆ°Æ¡ng trÃ¬nh nÃ y cÃ³ thá»ƒ viáº¿t ngáº¯n gá»n láº¡i thÃ nh:</p>

<p>[\hat y = h_\theta(x) = \theta . x]</p>

<p>Trong Ä‘Ã³:</p>

<ul>
  <li>
    <p>$( \theta  )$ lÃ  vector tham sá»‘ mÃ´ hÃ¬nh bao gá»“m bias $( \theta_0  )$ vÃ  cÃ¡c feature weights $( \theta_1 â€¦ \theta_n)$</p>
  </li>
  <li>
    <p>X lÃ  vector Ä‘áº§u vÃ o cá»§a mÃ´ hÃ¬nh, trong Ä‘Ã³ $( x_0)$ cÃ³ giÃ¡ trá»‹ báº±ng 1 (Ä‘Æ°á»£c thÃªm vÃ o)</p>
  </li>
  <li>
    <p>$Î¸ Â· x$ lÃ  tÃ­ch cÃ³ hÆ°á»›ng cá»§a vector Ä‘áº§u vÃ o vÃ  trá»ng sá»‘</p>
  </li>
</ul>

<p>Trong Machine learning, cÃ¡c vector thÆ°á»ng Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng cÃ¡c vector cá»™t, dáº¡ng máº£ng 2 chiá»u vá»›i 1 cá»™t. Náº¿u $Î¸$ vÃ  $x$ lÃ  cÃ¡c vector cá»™t thÃ¬ $( \hat y = \theta^Tx )$  trong Ä‘Ã³ $( \theta^T )$ lÃ  chuyá»ƒn vá»‹ cá»§a $Î¸$</p>

<h2 id="huáº¥n-luyá»‡n-mÃ´-hÃ¬nh">Huáº¥n luyá»‡n mÃ´ hÃ¬nh</h2>

<p>Sau khi Ä‘Ã£ cÃ³ mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh, giá» lÃ m cÃ¡ch nÃ o Ä‘á»ƒ huáº¥n luyá»‡n chÃºng? MÃ¬nh nháº¯c láº¡i 1 chÃºt, Ä‘Ã³ lÃ  viá»‡c huáº¥n luyá»‡n cho mÃ´ hÃ¬nh lÃ  viá»‡c tÃ¬m ra cÃ¡c tham sá»‘ tá»‘i Æ°u nháº¥t thÃ´ng qua bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n. Äá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y chÃºng ta phÃ¡i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c thÆ°á»›c Ä‘o Ä‘á»ƒ biáº¿t Ä‘Æ°á»£c mÃ´ hÃ¬nh tá»‘t hay khÃ´ng tá»‘t (tham sá»‘ cÃ³ tá»‘i Æ°u hay khÃ´ng). Sau Ä‘Ã¢y mÃ¬nh sáº½ giá»›i thiá»‡u 1 cÃ¡ch Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Ã³ lÃ  dÃ¹ng biá»ƒu thá»©c Root Mean Square Error (RMSE). Hiá»ƒu nÃ´m na nÃ³ lÃ  BÃ¬nh phÆ°Æ¡ng lá»—i trung bÃ¬nh. VÃ  má»¥c tiÃªu cá»§a viá»‡c huáº¥n luyá»‡n Ä‘Ã³ lÃ  giáº£m thiá»ƒu giÃ¡ trá»‹ cá»§a Mean Square Error (MSE).</p>

<p>MSE cá»§a mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh $( h_\theta )$ trÃªn táº­p huáº¥n luyá»‡n X Ä‘Æ°á»£c tÃ­nh nhÆ° sau:</p>

<p>[MSE(X, h_\theta) = \frac{1}{m}\sum_{i=1}^m(\theta^Tx^{(i)} -y^{(i)})^2]</p>

<p>ChÃºng ta viáº¿t $( h_\theta )$ thay vÃ¬ h Ä‘á»ƒ lÃ m rÃµ viá»‡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi vector $Î¸$ (phá»¥ thuá»™c vÃ o  $Î¸$). Äá»ƒ Ä‘Æ¡n giáº£n cÃ´ng thá»©c, chÃºng ta sáº½ chá»‰ viáº¿t $MSE(Î¸)$ thay vÃ¬  $MSE(X, hÎ¸)$</p>

<h2 id="phÆ°Æ¡ng-trÃ¬nh-chuáº©n">PhÆ°Æ¡ng trÃ¬nh chuáº©n</h2>

<p>Äá»ƒ tÃ¬m giÃ¡ trá»‹ Î¸ Ä‘á»ƒ phÆ°Æ¡ng trÃ¬nh $MSE(Î¸)$  Ä‘áº¡t cá»±c tiá»ƒu cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c nhá» cÃ´ng thá»©c sau:
\(\hat\theta = (X^TX)^{-1}  X^T  y\)</p>

<p>PhÆ°Æ¡ng trÃ¬nh (5.2)</p>

<p>Trong Ä‘Ã³:</p>

<p>$(\hat\theta)$ lÃ  giÃ¡ trá»‹ cá»§a Î¸ mÃ  táº¡i Ä‘Ã³ $MSE(Î¸)$ Ä‘áº¡t cá»±c tiá»ƒu
$y$ lÃ  vector giÃ¡ trá»‹ cáº§n tÃ¬m bao gá»“m $( y^1â€¦y^m )$</p>

<h1 id="implement-báº±ng-python">Implement báº±ng python</h1>

<p>Khá»Ÿi táº¡o dá»¯ liá»‡u</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td> --><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Tiáº¿p theo chÃºng ta sáº½ tÃ­nh Î¸ dá»±a vÃ o cÃ´ng thá»©c 5.2. ChÃºng ta sáº½ sá»­ dá»¥ng hÃ m inv() trong thÆ° viá»‡n Linear Algebra  cá»§a numpy Ä‘á»ƒ tÃ­nh nghá»‹ch Ä‘áº£o cá»§a ma tráº­n vÃ  hÃ m dot() Ä‘á»ƒ nhÃ¢n ma tráº­n:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td> --><td class="rouge-code"><pre><span class="n">X_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">]</span> <span class="c1"># thÃªm x0 = 1 cho má»—i giÃ¡ trá»‹ cá»§a vector X
</span><span class="n">theta_best</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X_b</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_b</span><span class="p">)).</span><span class="n">dot</span><span class="p">(</span><span class="n">X_b</span><span class="p">.</span><span class="n">T</span><span class="p">).</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>CÃ¹ng xem káº¿t quáº£:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td> --><td class="rouge-code"><pre>&gt;&gt;&gt; theta_best
array([[4.21509616],
[2.77011339]])
</pre></td></tr></tbody></table></code></pre></div></div>

<p>ChÃºng ta sáº½ ká»³ vá»ng lÃ  $( \theta_0 = 4 vÃ  \theta_1 = 3 )$ thay vÃ¬ $( \theta_0 = 4.215 vÃ  \theta_1 = 2.770 )$. Tuy nhiÃªn khi khá»Ÿi táº¡o dá»¯ liá»‡u chÃºng ta Ä‘Ã£ thÃªm vÃ o 1 Ã­t noise nÃªn khÃ´ng thá»ƒ Ä‘Æ°a nÃ³ vá» dáº¡ng phÆ°Æ¡ng trÃ¬nh gá»‘c Ä‘Æ°á»£c.</p>

<p>Sau khi Ä‘Ã£ cÃ³ $( \hat\theta )$, chÃºng ta cÃ³ thá»ƒ dá»± Ä‘oÃ¡n káº¿t quáº£ vá»›i Ä‘áº§u vÃ o má»›i:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td> --><td class="rouge-code"><pre><span class="o">&gt;&gt;&gt;</span> X_new <span class="o">=</span> np.array<span class="o">([[</span>0], <span class="o">[</span>2]]<span class="o">)</span>
<span class="o">&gt;&gt;&gt;</span> X_new_b <span class="o">=</span> np.c_[np.ones<span class="o">((</span>2, 1<span class="o">))</span>, X_new] <span class="c"># add x0 = 1 to each instance &gt;&gt;&gt; y_predict = X_new_b.dot(theta_best)</span>
<span class="o">&gt;&gt;&gt;</span> y_predict
array<span class="o">([[</span>4.21509616],
<span class="o">[</span>9.75532293]]<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Giá» chÃºng ta sáº½ váº½ Ä‘Æ°á»ng tháº³ng cho cÃ¡c dá»± Ä‘oÃ¡n</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td> --><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="s">"r-"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">"b."</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Kiá»ƒm tra láº¡i báº±ng thÆ° viá»‡n trong Scikit-Learn</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td> --><td class="rouge-code"><pre><span class="o">&gt;&gt;&gt;</span> from sklearn.linear_model
import LinearRegression
<span class="o">&gt;&gt;&gt;</span> lin_reg <span class="o">=</span> LinearRegression<span class="o">()</span>
<span class="o">&gt;&gt;&gt;</span> lin_reg.fit<span class="o">(</span>X, y<span class="o">)</span>
<span class="o">&gt;&gt;&gt;</span> lin_reg.intercept_, lin_reg.coef_ <span class="o">(</span>array<span class="o">([</span>4.21509616]<span class="o">)</span>, array<span class="o">([[</span>2.77011339]]<span class="o">))</span>
<span class="o">&gt;&gt;&gt;</span> lin_reg.predict<span class="o">(</span>X_new<span class="o">)</span> array<span class="o">([[</span>4.21509616],
<span class="o">[</span>9.75532293]]<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="tá»•ng-káº¿t">Tá»•ng káº¿t</h1>
<p>Váº­y lÃ  bÃ i nÃ y mÃ¬nh Ä‘Ã£ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ¡ch huáº¥n luyá»‡n thuáº­t toÃ¡n há»“i quy tuyáº¿n tÃ­nh. Chá»‘t láº¡i vá» cÆ¡ báº£n, Ä‘á»ƒ huáº¥n luyá»‡n 1 thuáº­t toÃ¡n cáº§n:</p>
<ul>
  <li>Äá»‹nh nghÄ©a Ä‘Æ°á»£c mÃ´ hÃ¬nh</li>
  <li>Äá»‹nh nghÄ©a hÃ m chi phÃ­ (hoáº·c hÃ m máº¥t mÃ¡t)</li>
  <li>Tá»‘i Æ°u hÃ m chi phÃ­ báº±ng dá»¯ liá»‡u huáº¥n luyá»‡n</li>
  <li>TÃ¬m ra cÃ¡c trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh mÃ  táº¡i Ä‘Ã³ hÃ m chi phÃ­ cÃ³ giÃ¡ trá»‹ nhá» nháº¥t</li>
</ul>
:ET